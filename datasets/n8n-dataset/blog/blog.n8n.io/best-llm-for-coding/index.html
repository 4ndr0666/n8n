<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta http-equiv="X-UA-Compatible" content="IE=edge">
			<title>The 20 best LLMs for coding (+ free workflow templates) – n8n Blog</title>
		<meta name="HandheldFriendly" content="True">
		<meta name="viewport" content="width=device-width, initial-scale=1">
		<!-- <link rel="preconnect" href="https://fonts.googleapis.com"> 
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=Nunito:ital,wght@0,400;0,800;0,900;1,400;1,800;1,900&display=swap">
<link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Nunito:ital,wght@0,400;0,800;0,900;1,400;1,800;1,900&display=swap"> -->
		<link rel="stylesheet" type="text/css" href="../assets/css/screen.css%3Fv=4801f6d1f9.css">
		<style>hr{background-image:url("data:image/svg+xml;utf8,<svg role='img' viewBox='0 0 136 24' xmlns='http://www.w3.org/2000/svg'><path d='M1.525 1.525a3.5 3.5 0 014.95 0L20 15.05 33.525 1.525a3.5 3.5 0 014.95 0L52 15.05 65.525 1.525a3.5 3.5 0 014.95 0L84 15.05 97.525 1.525a3.5 3.5 0 014.95 0L116 15.05l13.525-13.525a3.5 3.5 0 014.95 4.95l-16 16a3.5 3.5 0 01-4.95 0L100 8.95 86.475 22.475a3.5 3.5 0 01-4.95 0L68 8.95 54.475 22.475a3.5 3.5 0 01-4.95 0L36 8.95 22.475 22.475a3.5 3.5 0 01-4.95 0l-16-16a3.5 3.5 0 010-4.95z'/></svg>")}</style>

		<meta name="description" content="Explore the top 20 LLMs for coding and get free n8n workflow templates to integrate AI into your development process. Optimize automation, debugging, and code generation.">
    <link rel="icon" href="../favicon.png" type="image/png">
    <link rel="canonical" href="index.html">
    <meta name="referrer" content="no-referrer-when-downgrade">
    
    <meta property="og:site_name" content="n8n Blog">
    <meta property="og:type" content="article">
    <meta property="og:title" content="The 20 best LLMs for coding (+ free workflow templates)">
    <meta property="og:description" content="Explore the top 20 LLMs for coding and get free n8n workflow templates to integrate AI into your development process. Optimize automation, debugging, and code generation.">
    <meta property="og:url" content="https://blog.n8n.io/best-llm-for-coding/">
    <meta property="og:image" content="https://blog.n8n.io/content/images/size/w1200/2025/02/11-ai-tools-coding--1-.png">
    <meta property="article:published_time" content="2025-02-11T11:34:46.000Z">
    <meta property="article:modified_time" content="2025-02-11T11:34:46.000Z">
    <meta property="article:tag" content="AI">
    <meta property="article:tag" content="Guide">
    
    <meta property="article:publisher" content="https://www.facebook.com/n8nio">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="The 20 best LLMs for coding (+ free workflow templates)">
    <meta name="twitter:description" content="Explore the top 20 LLMs for coding and get free n8n workflow templates to integrate AI into your development process. Optimize automation, debugging, and code generation.">
    <meta name="twitter:url" content="https://blog.n8n.io/best-llm-for-coding/">
    <meta name="twitter:image" content="https://blog.n8n.io/content/images/size/w1200/2025/02/11-ai-tools-coding--1-.png">
    <meta name="twitter:label1" content="Written by">
    <meta name="twitter:data1" content="Federico Trotta">
    <meta name="twitter:label2" content="Filed under">
    <meta name="twitter:data2" content="AI, Guide">
    <meta name="twitter:site" content="@n8n_io">
    <meta property="og:image:width" content="1200">
    <meta property="og:image:height" content="675">
    
    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Article",
    "publisher": {
        "@type": "Organization",
        "name": "n8n Blog",
        "url": "https://blog.n8n.io/",
        "logo": {
            "@type": "ImageObject",
            "url": "https://blog.n8n.io/content/images/2022/06/n8n-blog.png"
        }
    },
    "author": {
        "@type": "Person",
        "name": "Federico Trotta",
        "image": {
            "@type": "ImageObject",
            "url": "//www.gravatar.com/avatar/0aa650cf22fc8bbc1f1ff0114abbeefd?s=250&d=mm&r=x",
            "width": 250,
            "height": 250
        },
        "url": "https://blog.n8n.io/author/federico/",
        "sameAs": [
            "https://federicotrotta.com/"
        ]
    },
    "headline": "The 20 best LLMs for coding (+ free workflow templates)",
    "url": "https://blog.n8n.io/best-llm-for-coding/",
    "datePublished": "2025-02-11T11:34:46.000Z",
    "dateModified": "2025-02-11T11:34:46.000Z",
    "image": {
        "@type": "ImageObject",
        "url": "https://blog.n8n.io/content/images/size/w1200/2025/02/11-ai-tools-coding--1-.png",
        "width": 1200,
        "height": 675
    },
    "keywords": "AI, Guide",
    "description": "Explore the top 20 LLMs for coding and get free n8n workflow templates to integrate AI into your development process. Optimize automation, debugging, and code generation.",
    "mainEntityOfPage": "https://blog.n8n.io/best-llm-for-coding/"
}
    </script>

    <meta name="generator" content="Ghost 5.119">
    <link rel="alternate" type="application/rss+xml" title="n8n Blog" href="../rss/index.html">
    <script defer src="https://cdn.jsdelivr.net/ghost/portal@~2.50/umd/portal.min.js" data-i18n="true" data-ghost="https://blog.n8n.io/" data-key="8626993d9b363277120ea42164" data-api="https://n8n-cloud-blog.ghost.io/ghost/api/content/" data-locale="en" crossorigin="anonymous"></script><style id="gh-members-styles">.gh-post-upgrade-cta-content,
.gh-post-upgrade-cta {
    display: flex;
    flex-direction: column;
    align-items: center;
    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Open Sans', 'Helvetica Neue', sans-serif;
    text-align: center;
    width: 100%;
    color: #ffffff;
    font-size: 16px;
}

.gh-post-upgrade-cta-content {
    border-radius: 8px;
    padding: 40px 4vw;
}

.gh-post-upgrade-cta h2 {
    color: #ffffff;
    font-size: 28px;
    letter-spacing: -0.2px;
    margin: 0;
    padding: 0;
}

.gh-post-upgrade-cta p {
    margin: 20px 0 0;
    padding: 0;
}

.gh-post-upgrade-cta small {
    font-size: 16px;
    letter-spacing: -0.2px;
}

.gh-post-upgrade-cta a {
    color: #ffffff;
    cursor: pointer;
    font-weight: 500;
    box-shadow: none;
    text-decoration: underline;
}

.gh-post-upgrade-cta a:hover {
    color: #ffffff;
    opacity: 0.8;
    box-shadow: none;
    text-decoration: underline;
}

.gh-post-upgrade-cta a.gh-btn {
    display: block;
    background: #ffffff;
    text-decoration: none;
    margin: 28px 0 0;
    padding: 8px 18px;
    border-radius: 4px;
    font-size: 16px;
    font-weight: 600;
}

.gh-post-upgrade-cta a.gh-btn:hover {
    opacity: 0.92;
}</style>
    <script defer src="https://cdn.jsdelivr.net/ghost/sodo-search@~1.5/umd/sodo-search.min.js" data-key="8626993d9b363277120ea42164" data-styles="https://cdn.jsdelivr.net/ghost/sodo-search@~1.5/umd/main.css" data-sodo-search="https://n8n-cloud-blog.ghost.io/" data-locale="en" crossorigin="anonymous"></script>
    
    <link href="https://blog.n8n.io/webmentions/receive/" rel="webmention">
    <script defer src="../public/cards.min.js%3Fv=4801f6d1f9"></script>
    <link rel="stylesheet" type="text/css" href="../public/cards.min.css%3Fv=4801f6d1f9.css">
    <script defer src="../public/member-attribution.min.js%3Fv=4801f6d1f9"></script><style>:root {--ghost-accent-color: #FD8925;}</style>
    <script src="https://www.google.com/recaptcha/api.js" async defer></script>
<style>
    .content-banner {
        display: flex;
        align-items: center;
        padding: 25px 30px 29px 120px;
        gap: 20px;
        background: url(../content/images/2023/05/banner.svg) no-repeat 0 0;
        position: relative;
        overflow: hidden;
        border-radius: 32px;
        margin-bottom: 40px;
    }
    .content-banner:before {
        content: '';
        width: 97px;
        height: 97px;
        background: #8287eb;
        filter: blur(66.7196px);
        position: absolute;
        top: -41px;
        left: -70px;
    }
    .content-banner div {
        flex: 1 1 0%;
    }
    .content-banner h3 {
        font-size: 28px;
        line-height: 36px;
        margin: 0;
    }
    .content-banner a {
        flex-shrink: 0;
    }
    .content-banner p {
        margin-bottom: 0;
        line-height: 24px;
    }
    .content-banner .global-button {
        text-decoration: none;
        padding: 9px 20px;
        font-size: 16px;
        line-height: 22px;
    }
</style>
<!-- cookie consent benner injection-->  
    <div id="n8n-consent-modal" class="consent-modal consent-modal--hidden">
      <p class="consent-modal-header">We use analytics</p>
      <p class="consent-modal-description">
        We use cookies and other tracking technologies to improve your browsing experience, to analyze our website
        traffic, assist our marketing efforts and to understand where our visitors are coming from.
      </p>
      <a href="https://n8n.io/legal#privacy" class="consent-modal-link">Privacy Policy</a>
      <div>
        <button class="consent-modal-button consent-modal-button--decline" onclick="acceptConsent(false)">
          Decline
        </button>
        <button class="consent-modal-button consent-modal-button--agree" onclick="acceptConsent(true)">Agree</button>
      </div>
    </div>
<style>
      .consent-modal {
        display: block;
        padding: 32px 16px;
        background: #101330;
        box-shadow: 0px 4px 40px rgba(153, 155, 175, 0.17);
        width: 100%;
        position: fixed;
        z-index: 1000;
        right: 0;
        left: 0;
        bottom: 0;
        box-sizing: border-box;
      }

      .consent-modal--hidden {
        display: none;
      }

      .consent-modal-link {
        font-family: 'moderat', sans-serif;
        font-size: 16px;
        line-height: 22px;
        font-style: normal;
        font-weight: 700;
        text-decoration-line: underline;
        color: #e4e6ec;
        margin-bottom: 16px;
        display: block;
      }

      .consent-modal-header,
      .consent-modal-description {
        padding: 0;
        margin: 0 0 16px;
        font-style: normal;
      }

      .consent-modal-header {
        font-family: 'sunset-gothic', 'Sunset Gothic Pro', sans-serif;
        font-weight: 700;
        font-size: 24px;
        line-height: 32px;
        color: #ffffff;
      }

      .consent-modal-description {
        font-family: 'moderat', sans-serif;
        font-weight: 400;
        font-size: 16px;
        line-height: 22px;
        color: #e4e6ec;
      }

      .consent-modal-button {
        padding: 9px 20px;
        border-radius: 6px;
        font-style: normal;
        font-weight: 700;
        text-align: center;
        color: #ffffff;
        cursor: pointer;
        border: none;
        font-family: 'moderat', sans-serif;
        font-size: 16px;
        line-height: 22px;
      }

      .consent-modal-button--decline {
        margin-right: 10px;
        background: #40425e;
      }

      .consent-modal-button--agree {
        background: #20b69e;
      }

      @media screen and (min-width: 992px) {
        .consent-modal {
          border-radius: 30px;
          left: unset;
          right: 14px;
          bottom: 14px;
          padding: 48px;
          max-width: 621px;
        }

        .consent-modal-header {
          font-size: 28px;
          line-height: 36px;
        }

        .consent-modal-link,
        .consent-modal-button,
        .consent-modal-description {
          font-size: 18px;
          line-height: 24px;
        }
      }
    </style>
    <script>
      ;(function () {
        const GDPR_COUNTRIES = ['AT', 'BE', 'BG', 'HR', 'CY', 'CZ', 'DK', 'EE', 'FI', 'FR', 'DE', 'GR', 'HU', 'IE', 'IT', 'LV', 'LT', 'LU', 'MT', 'NL', 'PL', 'PT', 'RO', 'SK', 'SI', 'ES', 'SE', 'GB'];
        const CONSENT_MODAL_ID = 'n8n-consent-modal';
        const CONSENT_MODAL_HIDDEN = 'consent-modal--hidden';
        window.acceptConsent = function (accepted) {
          const cookie = {
            consent: accepted
          };
          const d = new Date();
          d.setTime(d.getTime() + 5 * 24 * 60 * 60 * 1000);
          document.cookie = `n8n-consent=${JSON.stringify(cookie)}; expires=${d.toUTCString()}; path=/; domain=.n8n.io`;
          const modal = document.getElementById(CONSENT_MODAL_ID);
          if (modal) {
            modal.classList.add(CONSENT_MODAL_HIDDEN);
          }
        };
        async function checkCookie() {
          try {
            const res = await fetch('https://ipapi.co/json/');
            const ip = await res.json();
            const location = ip.country;
            if (GDPR_COUNTRIES.includes(location) || ip.country_code === 'US' && ip.region_code === 'CA') {
              var _document$cookie$matc;
              const cookie = ((_document$cookie$matc = document.cookie.match('(^|;)\\s*' + 'n8n-consent' + '\\s*=\\s*([^;]+)')) === null || _document$cookie$matc === void 0 ? void 0 : _document$cookie$matc.pop()) || '';
              if (cookie === '') {
                const modal = document.getElementById(CONSENT_MODAL_ID);
                if (modal) {
                  modal.classList.remove(CONSENT_MODAL_HIDDEN);
                }
              }
            } else {
              acceptConsent(true);
            }
          } catch (e) {}
        }
        window.addEventListener('DOMContentLoaded', checkCookie);
      })(window);
    </script>

<!-- Google Tag Manager (blog.n8n.io) -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-MQTZKBJ');</script>
<!-- End Google Tag Manager -->

<link
  rel="stylesheet"
  href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.3.0/css/fontawesome.min.css"
  crossorigin="anonymous"
  referrerpolicy="no-referrer"
/>
<link
  rel="stylesheet"
  href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.3.0/css/solid.min.css"
  crossorigin="anonymous"
  referrerpolicy="no-referrer"
/>
<script>
  !function(e,a,o){"object"==typeof exports?(module.exports=o(),module.exports.default=o()):"function"==typeof define&&define.amd?define(o):a.slugify=o()}(0,this,(function(){var e=JSON.parse('{"$":"dollar","%":"percent","&":"and","<":"less",">":"greater","|":"or","¢":"cent","£":"pound","¤":"currency","¥":"yen","©":"(c)","ª":"a","®":"(r)","º":"o","À":"A","Á":"A","Â":"A","Ã":"A","Ä":"A","Å":"A","Æ":"AE","Ç":"C","È":"E","É":"E","Ê":"E","Ë":"E","Ì":"I","Í":"I","Î":"I","Ï":"I","Ð":"D","Ñ":"N","Ò":"O","Ó":"O","Ô":"O","Õ":"O","Ö":"O","Ø":"O","Ù":"U","Ú":"U","Û":"U","Ü":"U","Ý":"Y","Þ":"TH","ß":"ss","à":"a","á":"a","â":"a","ã":"a","ä":"a","å":"a","æ":"ae","ç":"c","è":"e","é":"e","ê":"e","ë":"e","ì":"i","í":"i","î":"i","ï":"i","ð":"d","ñ":"n","ò":"o","ó":"o","ô":"o","õ":"o","ö":"o","ø":"o","ù":"u","ú":"u","û":"u","ü":"u","ý":"y","þ":"th","ÿ":"y","Ā":"A","ā":"a","Ă":"A","ă":"a","Ą":"A","ą":"a","Ć":"C","ć":"c","Č":"C","č":"c","Ď":"D","ď":"d","Đ":"DJ","đ":"dj","Ē":"E","ē":"e","Ė":"E","ė":"e","Ę":"e","ę":"e","Ě":"E","ě":"e","Ğ":"G","ğ":"g","Ģ":"G","ģ":"g","Ĩ":"I","ĩ":"i","Ī":"i","ī":"i","Į":"I","į":"i","İ":"I","ı":"i","Ķ":"k","ķ":"k","Ļ":"L","ļ":"l","Ľ":"L","ľ":"l","Ł":"L","ł":"l","Ń":"N","ń":"n","Ņ":"N","ņ":"n","Ň":"N","ň":"n","Ō":"O","ō":"o","Ő":"O","ő":"o","Œ":"OE","œ":"oe","Ŕ":"R","ŕ":"r","Ř":"R","ř":"r","Ś":"S","ś":"s","Ş":"S","ş":"s","Š":"S","š":"s","Ţ":"T","ţ":"t","Ť":"T","ť":"t","Ũ":"U","ũ":"u","Ū":"u","ū":"u","Ů":"U","ů":"u","Ű":"U","ű":"u","Ų":"U","ų":"u","Ŵ":"W","ŵ":"w","Ŷ":"Y","ŷ":"y","Ÿ":"Y","Ź":"Z","ź":"z","Ż":"Z","ż":"z","Ž":"Z","ž":"z","Ə":"E","ƒ":"f","Ơ":"O","ơ":"o","Ư":"U","ư":"u","ǈ":"LJ","ǉ":"lj","ǋ":"NJ","ǌ":"nj","Ș":"S","ș":"s","Ț":"T","ț":"t","ə":"e","˚":"o","Ά":"A","Έ":"E","Ή":"H","Ί":"I","Ό":"O","Ύ":"Y","Ώ":"W","ΐ":"i","Α":"A","Β":"B","Γ":"G","Δ":"D","Ε":"E","Ζ":"Z","Η":"H","Θ":"8","Ι":"I","Κ":"K","Λ":"L","Μ":"M","Ν":"N","Ξ":"3","Ο":"O","Π":"P","Ρ":"R","Σ":"S","Τ":"T","Υ":"Y","Φ":"F","Χ":"X","Ψ":"PS","Ω":"W","Ϊ":"I","Ϋ":"Y","ά":"a","έ":"e","ή":"h","ί":"i","ΰ":"y","α":"a","β":"b","γ":"g","δ":"d","ε":"e","ζ":"z","η":"h","θ":"8","ι":"i","κ":"k","λ":"l","μ":"m","ν":"n","ξ":"3","ο":"o","π":"p","ρ":"r","ς":"s","σ":"s","τ":"t","υ":"y","φ":"f","χ":"x","ψ":"ps","ω":"w","ϊ":"i","ϋ":"y","ό":"o","ύ":"y","ώ":"w","Ё":"Yo","Ђ":"DJ","Є":"Ye","І":"I","Ї":"Yi","Ј":"J","Љ":"LJ","Њ":"NJ","Ћ":"C","Џ":"DZ","А":"A","Б":"B","В":"V","Г":"G","Д":"D","Е":"E","Ж":"Zh","З":"Z","И":"I","Й":"J","К":"K","Л":"L","М":"M","Н":"N","О":"O","П":"P","Р":"R","С":"S","Т":"T","У":"U","Ф":"F","Х":"H","Ц":"C","Ч":"Ch","Ш":"Sh","Щ":"Sh","Ъ":"U","Ы":"Y","Ь":"","Э":"E","Ю":"Yu","Я":"Ya","а":"a","б":"b","в":"v","г":"g","д":"d","е":"e","ж":"zh","з":"z","и":"i","й":"j","к":"k","л":"l","м":"m","н":"n","о":"o","п":"p","р":"r","с":"s","т":"t","у":"u","ф":"f","х":"h","ц":"c","ч":"ch","ш":"sh","щ":"sh","ъ":"u","ы":"y","ь":"","э":"e","ю":"yu","я":"ya","ё":"yo","ђ":"dj","є":"ye","і":"i","ї":"yi","ј":"j","љ":"lj","њ":"nj","ћ":"c","ѝ":"u","џ":"dz","Ґ":"G","ґ":"g","Ғ":"GH","ғ":"gh","Қ":"KH","қ":"kh","Ң":"NG","ң":"ng","Ү":"UE","ү":"ue","Ұ":"U","ұ":"u","Һ":"H","һ":"h","Ә":"AE","ә":"ae","Ө":"OE","ө":"oe","Ա":"A","Բ":"B","Գ":"G","Դ":"D","Ե":"E","Զ":"Z","Է":"E\'","Ը":"Y\'","Թ":"T\'","Ժ":"JH","Ի":"I","Լ":"L","Խ":"X","Ծ":"C\'","Կ":"K","Հ":"H","Ձ":"D\'","Ղ":"GH","Ճ":"TW","Մ":"M","Յ":"Y","Ն":"N","Շ":"SH","Չ":"CH","Պ":"P","Ջ":"J","Ռ":"R\'","Ս":"S","Վ":"V","Տ":"T","Ր":"R","Ց":"C","Փ":"P\'","Ք":"Q\'","Օ":"O\'\'","Ֆ":"F","և":"EV","ء":"a","آ":"aa","أ":"a","ؤ":"u","إ":"i","ئ":"e","ا":"a","ب":"b","ة":"h","ت":"t","ث":"th","ج":"j","ح":"h","خ":"kh","د":"d","ذ":"th","ر":"r","ز":"z","س":"s","ش":"sh","ص":"s","ض":"dh","ط":"t","ظ":"z","ع":"a","غ":"gh","ف":"f","ق":"q","ك":"k","ل":"l","م":"m","ن":"n","ه":"h","و":"w","ى":"a","ي":"y","ً":"an","ٌ":"on","ٍ":"en","َ":"a","ُ":"u","ِ":"e","ْ":"","٠":"0","١":"1","٢":"2","٣":"3","٤":"4","٥":"5","٦":"6","٧":"7","٨":"8","٩":"9","پ":"p","چ":"ch","ژ":"zh","ک":"k","گ":"g","ی":"y","۰":"0","۱":"1","۲":"2","۳":"3","۴":"4","۵":"5","۶":"6","۷":"7","۸":"8","۹":"9","฿":"baht","ა":"a","ბ":"b","გ":"g","დ":"d","ე":"e","ვ":"v","ზ":"z","თ":"t","ი":"i","კ":"k","ლ":"l","მ":"m","ნ":"n","ო":"o","პ":"p","ჟ":"zh","რ":"r","ს":"s","ტ":"t","უ":"u","ფ":"f","ქ":"k","ღ":"gh","ყ":"q","შ":"sh","ჩ":"ch","ც":"ts","ძ":"dz","წ":"ts","ჭ":"ch","ხ":"kh","ჯ":"j","ჰ":"h","Ṣ":"S","ṣ":"s","Ẁ":"W","ẁ":"w","Ẃ":"W","ẃ":"w","Ẅ":"W","ẅ":"w","ẞ":"SS","Ạ":"A","ạ":"a","Ả":"A","ả":"a","Ấ":"A","ấ":"a","Ầ":"A","ầ":"a","Ẩ":"A","ẩ":"a","Ẫ":"A","ẫ":"a","Ậ":"A","ậ":"a","Ắ":"A","ắ":"a","Ằ":"A","ằ":"a","Ẳ":"A","ẳ":"a","Ẵ":"A","ẵ":"a","Ặ":"A","ặ":"a","Ẹ":"E","ẹ":"e","Ẻ":"E","ẻ":"e","Ẽ":"E","ẽ":"e","Ế":"E","ế":"e","Ề":"E","ề":"e","Ể":"E","ể":"e","Ễ":"E","ễ":"e","Ệ":"E","ệ":"e","Ỉ":"I","ỉ":"i","Ị":"I","ị":"i","Ọ":"O","ọ":"o","Ỏ":"O","ỏ":"o","Ố":"O","ố":"o","Ồ":"O","ồ":"o","Ổ":"O","ổ":"o","Ỗ":"O","ỗ":"o","Ộ":"O","ộ":"o","Ớ":"O","ớ":"o","Ờ":"O","ờ":"o","Ở":"O","ở":"o","Ỡ":"O","ỡ":"o","Ợ":"O","ợ":"o","Ụ":"U","ụ":"u","Ủ":"U","ủ":"u","Ứ":"U","ứ":"u","Ừ":"U","ừ":"u","Ử":"U","ử":"u","Ữ":"U","ữ":"u","Ự":"U","ự":"u","Ỳ":"Y","ỳ":"y","Ỵ":"Y","ỵ":"y","Ỷ":"Y","ỷ":"y","Ỹ":"Y","ỹ":"y","–":"-","‘":"\'","’":"\'","“":"\\"","”":"\\"","„":"\\"","†":"+","•":"*","…":"...","₠":"ecu","₢":"cruzeiro","₣":"french franc","₤":"lira","₥":"mill","₦":"naira","₧":"peseta","₨":"rupee","₩":"won","₪":"new shequel","₫":"dong","€":"euro","₭":"kip","₮":"tugrik","₯":"drachma","₰":"penny","₱":"peso","₲":"guarani","₳":"austral","₴":"hryvnia","₵":"cedi","₸":"kazakhstani tenge","₹":"indian rupee","₺":"turkish lira","₽":"russian ruble","₿":"bitcoin","℠":"sm","™":"tm","∂":"d","∆":"delta","∑":"sum","∞":"infinity","♥":"love","元":"yuan","円":"yen","﷼":"rial","ﻵ":"laa","ﻷ":"laa","ﻹ":"lai","ﻻ":"la"}'),a=JSON.parse('{"bg":{"Й":"Y","Ц":"Ts","Щ":"Sht","Ъ":"A","Ь":"Y","й":"y","ц":"ts","щ":"sht","ъ":"a","ь":"y"},"de":{"Ä":"AE","ä":"ae","Ö":"OE","ö":"oe","Ü":"UE","ü":"ue","ß":"ss","%":"prozent","&":"und","|":"oder","∑":"summe","∞":"unendlich","♥":"liebe"},"es":{"%":"por ciento","&":"y","<":"menor que",">":"mayor que","|":"o","¢":"centavos","£":"libras","¤":"moneda","₣":"francos","∑":"suma","∞":"infinito","♥":"amor"},"fr":{"%":"pourcent","&":"et","<":"plus petit",">":"plus grand","|":"ou","¢":"centime","£":"livre","¤":"devise","₣":"franc","∑":"somme","∞":"infini","♥":"amour"},"pt":{"%":"porcento","&":"e","<":"menor",">":"maior","|":"ou","¢":"centavo","∑":"soma","£":"libra","∞":"infinito","♥":"amor"},"uk":{"И":"Y","и":"y","Й":"Y","й":"y","Ц":"Ts","ц":"ts","Х":"Kh","х":"kh","Щ":"Shch","щ":"shch","Г":"H","г":"h"},"vi":{"Đ":"D","đ":"d"},"da":{"Ø":"OE","ø":"oe","Å":"AA","å":"aa","%":"procent","&":"og","|":"eller","$":"dollar","<":"mindre end",">":"større end"},"nb":{"&":"og","Å":"AA","Æ":"AE","Ø":"OE","å":"aa","æ":"ae","ø":"oe"},"it":{"&":"e"},"nl":{"&":"en"},"sv":{"&":"och","Å":"AA","Ä":"AE","Ö":"OE","å":"aa","ä":"ae","ö":"oe"}}');function o(o,n){if("string"!=typeof o)throw new Error("slugify: string argument expected");var r=a[(n="string"==typeof n?{replacement:n}:n||{}).locale]||{},i=void 0===n.replacement?"-":n.replacement,t=void 0===n.trim||n.trim,u=o.normalize().split("").reduce((function(a,o){var t=r[o];return void 0===t&&(t=e[o]),void 0===t&&(t=o),t===i&&(t=" "),a+t.replace(n.remove||/[^\w\s$*_+~.()'"!\-:@]+/g,"")}),"");return n.strict&&(u=u.replace(/[^A-Za-z0-9\s]/g,"")),t&&(u=u.trim()),u=u.replace(/\s+/g,i),n.lower&&(u=u.toLowerCase()),u}return o.extend=function(a){Object.assign(e,a)},o}));
</script>

<style>
  .content-banner {
    display: flex;
    align-items: center;
    padding: 25px 30px 29px 120px;
    gap: 20px;
    background: url('data:image/svg+xml,<svg xmlns="http://www.w3.org/2000/svg" width="149" height="162" fill="none" viewBox="0 0 149 162"><path stroke="%23997D00" stroke-width="2.799" d="M103.712 197.478s52.843-38.509-53.147-47.372"/><path stroke="%23484C99" stroke-width="2.799" d="M55.914 42.86c-57.712 2.444-108.25 97.476-2.26 106.339M69.258 38.473C99.64 30.633 155 3.5 103.5-4"/><path stroke="%23DDBB1A" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.799" d="m73.595 134.165-5.161 28.726a4.864 4.864 0 0 1-5.648 3.928l-28.727-5.162a4.864 4.864 0 0 1-3.928-5.648l5.162-28.727a4.864 4.864 0 0 1 5.648-3.927l28.727 5.161a4.865 4.865 0 0 1 3.927 5.649Z"/><path stroke="%23DDBB1A" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.799" d="m34.059 161.657 27.13 4.875-.286 1.596a5.171 5.171 0 0 1-.182.692l-.087.256a3.396 3.396 0 0 1-.19.411l-.017.096-.19.328-.185.247-.09.132-.245.269-.064.079-.189.181-.158.144-.161.119a4.821 4.821 0 0 1-3.89.974l-28.727-5.162a4.878 4.878 0 0 1-3.15-2.041l7.53-5.236a4.856 4.856 0 0 0 3.15 2.04ZM31.042 128.751c.148-.048.298-.087.45-.117l.055.01c.137-.025.265-.052.408-.067.04.004.08.011.12.021.111.021.234-.023.35-.027.076.009.15.023.224.04.088.016.167.03.255.005.163.021.325.05.486.087l1.596.287-4.855 27.019a4.865 4.865 0 0 0 .777 3.608l-7.53 5.236a4.863 4.863 0 0 1-.777-3.607l5.161-28.727a4.866 4.866 0 0 1 2.04-3.151 5.08 5.08 0 0 1 1.237-.601l.003-.016Z"/><path stroke="%23DDBB1A" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.799" d="m62.935 133.896-29.525-5.304a4.863 4.863 0 0 0-3.607.777l7.598-5.291a4.87 4.87 0 0 1 3.54-.723l28.727 5.162c3.99.717-.35 6.527-6.733 5.379Z"/><path stroke="%23DDBB1A" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.799" d="M73.595 134.165c-.915 4.777-5.161 28.727-5.161 28.727a4.81 4.81 0 0 1-2.013 3.131l-7.53 5.236a4.806 4.806 0 0 0 2.012-3.131l5.305-29.525c1.147-6.383 8.248-9.226 7.387-4.438Z"/><rect width="38.918" height="38.918" fill="%23FAE166" stroke="%23DDBB1A" stroke-width="2.799" rx="5.599" transform="scale(1 -1) rotate(79.814 133.4 -50.56)"/><rect width="3.073" height="3.012" fill="%23DDBB1A" rx=".7" transform="matrix(-.571 -.821 -.821 .571 67.951 135.654)"/><rect width="1.621" height="3.243" fill="%23DDBB1A" rx=".7" transform="matrix(-.571 -.821 -.821 .571 35.667 127.491)"/><rect width="1.621" height="1.793" fill="%23DDBB1A" rx=".7" transform="matrix(-.571 -.821 -.821 .571 72.876 131.293)"/><path stroke="%236E72E0" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.799" d="m77.366 14.145 8.49 27.925a4.864 4.864 0 0 1-3.238 6.069l-27.925 8.49a4.865 4.865 0 0 1-6.07-3.239l-8.49-27.924a4.864 4.864 0 0 1 3.24-6.07l27.924-8.49a4.865 4.865 0 0 1 6.07 3.24Z"/><path stroke="%236E72E0" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.799" d="m54.693 56.63 26.373-8.02.472 1.552a5.2 5.2 0 0 1 .153.699l.04.268c.015.15.022.3.018.452l.028.093-.02.379-.052.303-.02.159-.096.351-.02.1-.087.246-.074.2-.09.18a4.815 4.815 0 0 1-3.02 2.638l-27.924 8.491a4.865 4.865 0 0 1-3.734-.381l4.319-8.092a4.866 4.866 0 0 0 3.734.381ZM37.018 28.71c.11-.11.225-.213.347-.31l.054-.016c.11-.084.212-.166.333-.245a.673.673 0 0 1 .116-.036c.108-.033.198-.128.3-.184.07-.026.143-.048.217-.066a.53.53 0 0 0 .229-.112 4.94 4.94 0 0 1 .473-.144l1.551-.471 7.986 26.264a4.864 4.864 0 0 0 2.335 2.858l-4.32 8.092a4.864 4.864 0 0 1-2.334-2.858l-8.49-27.924a4.866 4.866 0 0 1 .381-3.735c.224-.402.503-.771.827-1.098l-.005-.016Z"/><path stroke="%236E72E0" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.799" d="m67.754 18.762-28.7 8.727a4.865 4.865 0 0 0-2.858 2.335l4.354-8.171a4.865 4.865 0 0 1 2.822-2.256l27.925-8.49c3.879-1.18 2.662 5.968-3.543 7.855Z"/><path stroke="%236E72E0" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.799" d="M77.366 14.145c1.362 4.67 8.49 27.925 8.49 27.925a4.816 4.816 0 0 1-.364 3.704l-4.32 8.092a4.817 4.817 0 0 0 .366-3.704l-8.726-28.7c-1.887-6.206 3.14-11.97 4.554-7.317Z"/><rect width="38.918" height="38.918" fill="%238287EB" stroke="%236E72E0" stroke-width="2.799" rx="5.599" transform="scale(-1 1) rotate(-73.088 -4.498 83.371)"/><rect width="1.621" height="3.243" fill="%236E72E0" rx=".7" transform="matrix(-.8822 -.4708 -.4708 .8822 84.062 48.371)"/><rect width="3.073" height="3.012" fill="%236E72E0" rx=".7" transform="matrix(-.8822 -.4708 -.4708 .8822 73.02 18.042)"/><rect width="1.621" height="3.243" fill="%236E72E0" rx=".7" transform="matrix(-.8822 -.4708 -.4708 .8822 40.562 25.48)"/><rect width="1.621" height="1.793" fill="%236E72E0" rx=".7" transform="matrix(-.8822 -.4708 -.4708 .8822 75.418 11.917)"/><path stroke="%23484C99" stroke-width=".35" d="M88.94 52.813 75.834 9.709 32.73 22.814l13.106 43.104z"/></svg>')
      no-repeat 0 0;
    position: relative;
    overflow: hidden;
    border-radius: 32px;
    margin-bottom: 40px;
  }

  @media screen and (max-width: 1023px) {
    .content-banner {
      flex-direction: column;
      background: none;
      padding-left: 30px;
      text-align: center;
    }

    .content-banner:before {
      display: none;
    }
  }

  .content-banner:before {
    content: "";
    width: 97px;
    height: 97px;
    background: #8287eb;
    filter: blur(66.7196px);
    position: absolute;
    top: -41px;
    left: -70px;
  }
  .content-banner div {
    flex: 1 1 0%;
  }
  .content-banner h3 {
    font-size: 28px;
    line-height: 36px;
    margin: 0;
  }
  .content-banner a {
    flex-shrink: 0;
  }
  .content-banner p {
    margin-bottom: 0;
    line-height: 24px;
  }
  .content-banner .global-button {
    text-decoration: none;
    padding: 9px 20px;
    font-size: 16px;
    line-height: 22px;
  }

  .content-banner--centered {
    flex-direction: column;
    background: none;
    border-radius: 0;
    padding-left: 30px;
    padding-bottom: 40px;
    text-align: center;
  }
  .content-banner--centered:before {
    content: "";
    width: 168px;
    height: 168px;
    background: #20b69e;
    opacity: 0.7;
    filter: blur(62.4716px);
    position: absolute;
    top: 80%;
    left: 50%;
    transform: translateX(-50%);
  }
  .content-banner--centered .global-button {
    color: #101330 !important;
    border: 2px solid #20b69e;
  }
  .content-banner--centered .global-button:before,
  .content-banner--centered .global-button:after {
    background: #fff;
  }
  @media screen and (max-width: 1023px) {
    .content-banner--centered:before {
      display: block;
    }
  }
  .workflow {
    display: flex;
    align-items: center;
    margin-bottom: 40px;
  }
  .workflow-content {
    display: flex;
    flex: 1 1 0%;
  }
  .workflow-nodes {
    margin-right: 24px;
    display: flex;
    align-items: center;
    gap: 12px;
  }
  .workflow-nodes img {
    width: 24px;
    height: 24px;
    flex-shrink: 0;
  }
  .workflow-nodes .fa {
    font-size: 24px;
    flex-shrink: 0;
  }
  .workflow-nodes span {
    width: 24px;
    height: 24px;
    flex-shrink: 0;
    background: #e4e6ec;
    border-radius: 4px;
    font-weight: 400;
    font-size: 14px;
    line-height: 18px;
    display: flex;
    align-items: center;
    justify-content: center;
    color: #101330;
  }
  .workflow-details {
    margin-right: 18px;
  }
  .workflow-details p {
    margin: 0;
  }
  .workflow .workflow-details-name {
    color: #101330;
    font-size: 16px;
    font-weight: 700;
    line-height: 22px;
  }
  .workflow .workflow-details-name a {
    text-decoration: none;
  }
  .workflow .workflow-details-name a:hover {
    text-decoration: underline;
  }
  .workflow .workflow-details-stats {
    font-size: 14px;
    line-height: 18px;
    color: #707183;
  }
  .workflow .global-button {
    text-decoration: none;
    padding: 9px 20px;
    font-size: 16px;
    line-height: 22px;
  }
  .workflows h3 {
    margin-bottom: 30px;
    padding-left: 24px;
    padding-right: 24px;
  }
  .workflows .workflow {
    border-bottom: 1px solid #E0E0EB;
    padding-bottom: 20px;
    padding-left: 24px;
    padding-right: 24px;
    margin-bottom: 20px;
  }
  .workflows .workflow-content {
    flex-direction: column;
  }
  .workflows .workflow-nodes {
    margin-bottom: 12px;
  }
  .workflows .workflow-nodes span,
  .workflows .workflow-nodes img {
    width: 32px;
    height: 32px;
  }
  .workflows .workflow-nodes .fa {
    font-size: 32px;
  }
  .workflows .workflow .workflow-details-name {
    font-size: 18px;
    line-height: 24px;
    margin-bottom: 5px;
  }
  .workflows .workflow-details-stats span {
    margin: 0 4px;
    display: inline-block;
  }
  .workflows-button {
    display: flex;
    justify-content: center;
    margin-bottom: 40px;
  }
  .workflows-button .global-button {
    color: #101330 !important;
    border: 2px solid #20b69e;
    text-decoration: none;
    padding: 9px 20px;
    font-size: 16px;
    line-height: 22px;
  }
  .workflows-button .global-button:before,
  .workflows-button .global-button:after {
    background: #fff;
  }

  @media screen and (max-width: 670px) {
    .workflow-nodes {
      display: none;
    }
    .workflow {
      flex-direction: column;
      align-items: start;
    }
    .workflow .global-button {
      margin-top: 10px;
    }
  }

  @media screen and (max-width: 1024px) {
    .workflow-nodes {
      flex-wrap: wrap;
    }
  }
</style>
<style>
    .grecaptcha-badge { visibility: hidden !important; }
</style>
<script>
const timeSince = (date) => {
  const seconds = Math.floor((new Date() - new Date(date)) / 1000);
  let interval = seconds / 31536000;
  if (interval > 1) {
    const roundedInterval = Math.floor(interval);
    return roundedInterval === 1
      ? roundedInterval + " year"
      : roundedInterval + " years";
  }
  interval = seconds / 2592000;
  if (interval > 1) {
    const roundedInterval = Math.floor(interval);
    return roundedInterval === 1
      ? roundedInterval + " month"
      : roundedInterval + " months";
  }

  interval = seconds / 86400;
  if (interval > 1) {
    const roundedInterval = Math.floor(interval);
    return roundedInterval === 1
      ? roundedInterval + " day"
      : roundedInterval + " days";
  }
  interval = seconds / 3600;
  if (interval > 1) {
    const roundedInterval = Math.floor(interval);
    return roundedInterval === 1
      ? roundedInterval + " hour"
      : roundedInterval + " hours";
  }
  interval = seconds / 60;
  if (interval > 1) {
    const roundedInterval = Math.floor(interval);
    return roundedInterval === 1
      ? roundedInterval + " minute"
      : roundedInterval + " minutes";
  }

  const roundedInterval = Math.floor(interval);
  return roundedInterval === 1
    ? roundedInterval + " second"
    : roundedInterval + " seconds";
};
const getSingleWorkflowTemplate = (
  { name, user, nodes, url, views, createdAt },
  extended = false,
  texts
) => {
  if (name && user) {
    const IMAGES_PER_PAGE = 5;
    const workflowDiv = document.createElement("div");
    const images = [];

    nodes.forEach((node) => {
      const { icon, name, color } = node;

      if (icon.type === "icon") {
        const styles = color ? `style="color:${color}"` : "";
        images.push(`
          <i class="fa fa-${icon.icon}" aria-hidden="true" ${styles}></i>
        `);
      }

      if (icon.type === "file") {
        images.push(
          `<img src="https://blog.n8n.io/best-llm-for-coding/${icon.fileBuffer}" alt="${name}" title="${name}" />`
        );
      }
    });

    const description = extended
      ? `<p class="workflow-details-stats">
          <svg xmlns="http://www.w3.org/2000/svg" width="12" height="10" fill="none" viewBox="0 0 12 10"><path fill="#707183" d="M4.94 6.06a1.5 1.5 0 1 1 2.121-2.12 1.5 1.5 0 0 1-2.12 2.12Z"/><path fill="#707183" fill-rule="evenodd" d="M.462 6.143C1.38 7.135 3.294 9.2 6 9.2s4.62-2.065 5.539-3.057a1.703 1.703 0 0 0 0-2.332l-.001-.002C10.703 2.907 8.749.8 6 .8 3.256.8 1.304 2.903.466 3.806l-.004.005a1.703 1.703 0 0 0 0 2.332ZM3.77 3.305c.689-.38 1.447-.62 2.23-.705a5.88 5.88 0 0 1 3.972 2.17.301.301 0 0 1 0 .414A5.88 5.88 0 0 1 6 7.4 6.216 6.216 0 0 1 1.996 5.24a.3.3 0 0 1-.01-.423A5.937 5.937 0 0 1 3.77 3.305Z" clip-rule="evenodd"/></svg>
          ${
            views || 0
          } <span>•</span> <strong>by ${user}</strong> <span>•</span> ${timeSince(
          createdAt
        )}
        </p>`
      : `<p class="workflow-details-stats">by ${user}</p>`;

    workflowDiv.classList.add("workflow");
    workflowDiv.innerHTML = `
      <div class="workflow-content">
        <div class="workflow-nodes">
          ${images.slice(0, IMAGES_PER_PAGE).join("")}
          ${
            images.length - IMAGES_PER_PAGE > 0
              ? `<span>+${images.length - IMAGES_PER_PAGE}</span>`
              : ""
          }
        </div>
        <div class="workflow-details">
          <p class="workflow-details-name">
            <a href="https://blog.n8n.io/best-llm-for-coding/${url}" class="blog-banner-workflow">${name}</a>
          </p>
          ${description}
        </div>
      </div>
      <a href="https://blog.n8n.io/best-llm-for-coding/${url}" class="global-button blog-banner-workflow">
        ${texts.workflowButtonLabel}
      </a>
    `;
    return workflowDiv;
  }

  return null;
};

const getMultiWorkflowTemplate = (workflows, texts) => {
  const workflowsDiv = document.createElement("div");

  workflowsDiv.classList.add("workflows");
  workflowsDiv.innerHTML = `
    <h3>${texts.workflowsHeader}</h3>
  `;

  workflows.forEach((workflow) => {
    const template = getSingleWorkflowTemplate(workflow, true, texts);
    workflowsDiv.insertAdjacentElement("beforeend", template);
  });

  workflowsDiv.innerHTML = `
    ${workflowsDiv.innerHTML}
    <div class="workflows-button">
      <a href="https://blog.n8n.io/best-llm-for-coding/${texts.workflowsButtonUrl}" class="global-button blog-banner-signup">
        ${texts.workflowsButtonLabel}
      </a>
    </div>
  `;

  return workflowsDiv;
};

const parseWorkflowData = (workflowData) => {
  const { name, username, nodes, views, createdAt } = workflowData.attributes;

  return {
    name,
    views,
    createdAt,
    user: username,
    url: `https://n8n.io/workflows/${workflowData.id}-${slugify(name, {
      strict: true,
      lower: true,
    })}/`,
    nodes: nodes.data.map((node) => {
      return {
        icon: node.attributes.iconData,
        name: node.attributes.displayName,
        color: node.attributes.defaults.color,
      };
    }),
  };
};

const convertIdsToQuery = (workflowIds) => {
  const ids = Array.isArray(workflowIds) ? workflowIds : [workflowIds];
  return ids.map((id) => `{ id: { eq: ${id} } }`).join(",");
};
const fetchWorkflows = async (workflowId) => {
  try {
    const res = await fetch("https://api.n8n.io/graphql", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        query: `query {\n workflows(\n pagination: { start: 0, limit: 32 }\n filters: {\n status: { eq: "published" }\n or: [${convertIdsToQuery(
          workflowId
        )}]\n }\n ) {\n data {\n id\n attributes {\n name\n views\n createdAt\n username\n nodes {\n data {\n id\n attributes {\n defaults\n displayName\n name\n iconData\n}\n}\n}\n}\n}\n}\n}\n`,
      }),
    });
    const data = await res.json();

    return data.data.workflows.data.map((workflow) =>
      parseWorkflowData(workflow)
    );
  } catch (e) {}
};

const workflowBanner = async (workflowContainerId, scriptEl, texts) => {
  const workflows = await fetchWorkflows(workflowContainerId);
  const txts = Object.assign(
    {},
    {
      workflowButtonLabel: "Use this workflow",
      workflowsHeader: "Most popular workflows with these integrations",
      workflowsButtonLabel: "Get started",
      workflowsButtonUrl: "https://app.n8n.cloud/register",
    },
    texts
  );

  if (workflows.length === 1) {
    const template = getSingleWorkflowTemplate(workflows[0], false, txts);
    scriptEl.insertAdjacentElement("afterend", template);
  } else if (workflows.length > 1) {
    const template = getMultiWorkflowTemplate(workflows, txts);
    scriptEl.insertAdjacentElement("afterend", template);
  }
};

var submitSubscription = async function() {
        const token = await grecaptcha.getResponse()

        if (newSubscriptionData && newSubscriptionData.data) {
          newSubscriptionData.data.token = token
          const res = await fetch('https://n8n-website-backend-prod.internal.n8n.io/api/newsletter/subscribe', {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json'
            },
            body: JSON.stringify(newSubscriptionData.data)
          })

          if (newSubscriptionData.onSuccess && res.ok) {
            newSubscriptionData.onSuccess()
          } else if (newSubscriptionData.onError) {
            newSubscriptionData.onError()
          }

          window.newSubscriptionData = null
        }
      }

const subscribeNewsletter = async (e) => {
    e.preventDefault();

    const newsletterMailFormat = /^\w+([.-]?\w+)*@\w+([.-]?\w+)*(\.\w{2,3})+$/;
    const ERROR_CLASS = 'error';
    const SUCCESS_CLASS = 'success';
    const SHOW_MESSAGE_CLASS = 'show';

    const form = e.target;
    const emailField = form.querySelector('input[name=email]');
    const success = form.querySelector('.message--success');
    const error = form.querySelector('.message--error');

    emailField.setCustomValidity('Please insert a valid email address.');
    emailField.disabled = true;
    emailField.classList.remove(ERROR_CLASS);

    success.classList.remove(SHOW_MESSAGE_CLASS);
    error.classList.remove(SHOW_MESSAGE_CLASS);

    if (!emailField.value.match(newsletterMailFormat)) {
        emailField.reportValidity();
        emailField.classList.add(ERROR_CLASS);
    } else {
        try {
            await grecaptcha.execute()
            const url = new URL(window.location)
            const urlSource = `${url.origin}${url.pathname}`
            const utmParams = {
                utm_source: url.searchParams.get('utm_source') || null,
                utm_medium: url.searchParams.get('utm_medium') || null,
                utm_campaign: url.searchParams.get('utm_campaign') || null
            }
            const data = {
                email: emailField.value,
                created_at: Math.floor(new Date().getTime() / 1000),
                newsletter_subscriber: true,
                url_source: urlSource,
                ...Object.fromEntries(Object.entries(utmParams).filter(([_, v]) => v !== null))
            }

            window.newSubscriptionData = {
                data: data,
                onSuccess: () => {
                    success.classList.add(SHOW_MESSAGE_CLASS);
                    emailField.classList.add(SUCCESS_CLASS);
                    emailField.setCustomValidity('');
                    emailField.disabled = false;
                },
                onError: () => {
                    error.classList.add(SHOW_MESSAGE_CLASS);
                    emailField.classList.add(ERROR_CLASS);
                    emailField.disabled = false;
                }
            }
        } catch (e) {
            error.classList.add(SHOW_MESSAGE_CLASS);
            emailField.classList.add(ERROR_CLASS);
        }
    }

    emailField.disabled = false;
}
</script>
<script>
!function(){let e=function(e){let t=document.createElement("a");return t.href=e.url,t.innerText=e.tag,t},t=function(){let t=window.homePageTags||[],n=document.querySelector(".popular-tags");if(n&&t&&t.length){let r=n.querySelector(".popular-tags-listing");t.forEach(t=>{r.appendChild(e(t))}),n.classList.remove("hidden")}};window.addEventListener("DOMContentLoaded",t)}();

/*
  example:
  var homePageTags = [
    { tag: 'AI', url: '/tag/ai/' },
    { tag: 'Tutorial', url: '/tag/tutorial/' }
  ]
*/

var homePageTags = [
   { tag: 'AI', url: '/tag/ai/' },
    { tag: 'Database', url: '/tag/database/' },
    { tag: 'Marketing automation', url: '/tag/marketing-automation/' },
    { tag: 'Sales', url: '/tag/sales/' },
    { tag: 'SecOps', url: '/tag/secops/' },
    { tag: 'ITOps', url: '/tag/itops/' },
    { tag: 'Tools Alternatives', url: '/tag/tools-alternatives/' },
    { tag: 'Bot', url: '/tag/bot/' }
]
</script>
	</head>
	<body class="post-template tag-ai tag-guide">
		<!-- Google Tag Manager (noscript) -->
		<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-K7L9C6X"
		height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
		<!-- End Google Tag Manager (noscript) -->
		<div class="global-wrap">
			<div class="global-content">
				<header class="header-section">
	<div class="header-wrap">
		<div class="header-logo is-image">
			<a href="../index.html" class="is-image"><img src="../content/images/2022/06/n8n-blog.png" alt="n8n Blog"></a>
		</div>
		<div class="header-nav">
			<input id="toggle" class="header-checkbox" type="checkbox">
			<label class="header-toggle" for="toggle">
				<span>
					<span class="bar"></span>
					<span class="bar"></span>
					<span class="bar"></span>
				</span>
			</label>
			<nav >
				<ul>
<li><a href="https://n8n.io/" >n8n home</a></li>
<li><a href="../tag/tutorial/index.html" >Tutorials</a></li>
<li><a href="../tag/guide/index.html" >Guides</a></li>
<li><a href="../tag/tips/index.html" >Tips</a></li>
<li><a href="../tag/interview/index.html" >Interviews</a></li>
<li><a href="../tag/news/index.html" >News</a></li>
</ul>
				<ul>
					<!-- <li class="signin"><a href="https://blog.n8n.io/signin/">Sign in</a></li>
<li class="signup"><a href="https://blog.n8n.io/signup/" class="global-button">Sign up</a></li>
 -->

<li class="signin"><a href="https://app.n8n.cloud/">Sign in</a></li>
<li class="signup"><a href="https://app.n8n.cloud/register" class="global-button">Get started</a></li>
				</ul>
			</nav>
		</div>
	</div>
</header>				<main class="global-main">
					<progress class="post-progress"></progress>
<article class="post-section">
	<div class="post-header item is-hero">
	<div class="item-container">
		<div class="item-image global-image">
			<img srcset="../content/images/size/w400/2025/02/11-ai-tools-coding--1-.png 400w, 
			../content/images/size/w800/2025/02/11-ai-tools-coding--1-.pngg 800w,
		../content/images/size/w1200/2025/02/11-ai-tools-coding--1-.pngng 1200w,
	../content/images/size/w1600/2025/02/11-ai-tools-coding--1-.pngpng 1600w"
	 sizes="(max-width:480px) 350px, (max-width:1440px) 800px, 1200px"
	 src="../content/images/size/w1200/2025/02/11-ai-tools-coding--1-.png"
	 loading="lazy"
	 alt="The 20 best LLMs for coding (+ free workflow templates)">		</div>
		<div class="item-content">
			<div class="item-tags global-tags">
								<a href="../tag/ai/index.html">AI</a><a href="../tag/guide/index.html">Guide</a>
			</div>
			<h1 class="item-title">The 20 best LLMs for coding (+ free workflow templates)</h1>
			<p class="item-excerpt global-zigzag">
				<svg role='img' viewBox='0 0 136 24' xmlns='http://www.w3.org/2000/svg'><path d='M1.525 1.525a3.5 3.5 0 014.95 0L20 15.05 33.525 1.525a3.5 3.5 0 014.95 0L52 15.05 65.525 1.525a3.5 3.5 0 014.95 0L84 15.05 97.525 1.525a3.5 3.5 0 014.95 0L116 15.05l13.525-13.525a3.5 3.5 0 014.95 4.95l-16 16a3.5 3.5 0 01-4.95 0L100 8.95 86.475 22.475a3.5 3.5 0 01-4.95 0L68 8.95 54.475 22.475a3.5 3.5 0 01-4.95 0L36 8.95 22.475 22.475a3.5 3.5 0 01-4.95 0l-16-16a3.5 3.5 0 010-4.95z'/></svg>				Explore the top 20 LLMs for coding and get free n8n workflow templates to integrate AI into your development process. Optimize automation, debugging, and code generation.
			</p>
			<div class="item-meta global-meta">
				<div class="item-profile-image">
					<a href="../author/federico/index.html" class="global-image">
						<img src="https://www.gravatar.com/avatar/0aa650cf22fc8bbc1f1ff0114abbeefd?s=250&amp;d=mm&amp;r=x" loading="lazy" alt="Federico Trotta">					</a>
				</div>
				<div class="item-authors">
					<a href="../author/federico/index.html">Federico Trotta</a>
					<div class="item-time">
						<time datetime="2025-02-11">February 11, 2025</time> ∙ 25 minutes read
					</div>
				</div>
			</div>
		</div>
	</div>
</div>	<div class="post-content">
		<p>It’s not a secret that <a href="https://n8n.io/integrations/basic-llm-chain/?ref=blog.n8n.io" rel="noreferrer">LLMs</a> have attracted a lot of attention in the last two years. But let’s be honest: this happened for a good reason!</p><p>Today, LLMs are capable of processing vast codebases, supporting multi-language development, and even assisting in secure coding practices by identifying vulnerabilities and suggesting fixes.</p><p>For this reason, we classified the 20 best LLMs for coding to help you clarify the ideas around the best models, what they do, and why they’re interesting.</p><p>So, in this article, you’ll read the following:</p><ul><li>An overview of the current state of the LLMs landscape, with a bit of history;</li><li>The 20 best LLMs for coding;</li><li><a href="https://n8n.io/workflows/categories/ai/?ref=blog.n8n.io" rel="noreferrer">n8n workflows that leverage AI</a> and code to help you streamline your processes and how to set them up.</li></ul><p>Whether you're an IT manager who wants to improve operations or a DevOps engineer who wants to automate complex workflows, this guide will teach you everything you need to know about leveraging LLMs for coding in your enterprise environment.</p><p>Let’s dive in!</p><h2 id="llms-for-coding-landscape">LLMs for coding landscape </h2><figure class="kg-card kg-image-card kg-width-wide kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXcgfrWrS_ZI7h6Y4-5i096L9fYHqAUQ_EXTDNcpkl1leFyOs3TvVgJKjKeL43KMua0Y1AMv3kWRlB65gidWIY6zANXFHzSRBKpE4gvUsBUnIWO_7bxG9nxrQJgYEz5YCTKYfJ8Ipg?key=V2J9xv6PXC5DZeqc4AtWjfpF" class="kg-image" alt="The LLMs for coding landscape by Federico Trotta" loading="lazy" width="602" height="384"><figcaption><span style="white-space: pre-wrap;">The LLMs for coding landscape</span></figcaption></figure><p>The image shows that LLMs for coding can be subdivided based on the license – open-source or commercial. Between these categories, the models can be:</p><ul><li>general-purpose (they manage text, code, images, and more),</li><li>coding-specific (designed specifically for managing code),</li><li>specific for research and fine-tuning,</li><li>or designed for enterprises’ needs.&nbsp;</li></ul><p>For the classification we made, we subdivided the LLMs into families based on who developed them. What’s interesting to note is that some families provide open-source models and others that have proprietary licenses, depending on particular needs.</p><p>Other families, instead, provide both general-purpose and coding-specific models (Ollama is an example).</p><p>This tells a lot about the state-of-the-art of the LLMs for coding: companies and teams are probably trying to strike a balance between democratizing and expanding the use of LLMs–thus, providing open-source models–and the need to have the right business model to continue developing the models–thus, providing models with proprietary license.</p><h2 id="the-20-best-llms-for-coding">The 20 best LLMs for coding</h2><p>Yes, we know: this landscape is vast. This is why we’ve prepared a list of the 20 best LLMs for coding to help you clarify contexts, use cases, and peculiarities of the current state-of-the-art models.</p><p>Let’s discover them!</p><h3 id="the-claude-3-family">The Claude 3 family</h3><p><strong>Best for:</strong> Generating new software architecture.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXeOjwebV-O17LDaBNCMkn_9a_DYELtVOSwO7xnCzKsdkxNRG99cplJTaEbtW49OkoBt3zDEUi4ZxKybaQk7OiSwTPNct5xhHAmlfaUALw-UZkd0nkrOUtBG1R9BIUGgwl6L6bJW7g?key=V2J9xv6PXC5DZeqc4AtWjfpF" class="kg-image" alt="The Claude 3 UI - screenshot taken from the Claude 3 website" loading="lazy" width="602" height="407"><figcaption><span style="white-space: pre-wrap;">The Claude 3 UI - screenshot taken from the Claude 3 website</span></figcaption></figure><p><a href="https://www.anthropic.com/claude?ref=blog.n8n.io"><u>Claude 3</u></a>, developed by <a href="https://www.anthropic.com/?ref=blog.n8n.io"><u>Anthropic</u></a>, is a family of three AI models. Each has different performance capabilities, allowing users to have the right balance of cost, speed, and intelligence.</p><p>This family of LLMs consists of:</p><ul><li><strong>Claude Haiku</strong>: The fastest model that can execute lightweight actions, with industry-leading speed.&nbsp; Suitable for tasks that require speed but are also cost-effective is, however, the least performing among the family.</li><li><strong>Claude Sonnet</strong>: Provides the best combination of performance and speed for efficient, high-throughput tasks. It is the middle-of-the-road model among the three and it’s more inclined to serve enterprise tasks like data processing, quality control, and product recommendations.</li><li><strong>Claude Opus</strong>: Is the highest-performing model, and can handle complex analysis, longer tasks with many steps, and higher-order math and coding tasks. It outperforms Sonnet and Haiku on many evaluation benchmarks for AI systems.</li></ul><p><strong>License:</strong></p><p>Proprietary/Commercial</p><p><strong>Key features for coding:</strong></p><p>The Claude 3 family is a general-purpose LLM family, so is suitable for coding tasks, among others. They can work with a wide variety of programming languages and frameworks–but they are particularly proficient with Python and JavaScript/TypeScript.</p><p>Also, the Opus model excels in complex reasoning and advanced cognitive processing, making it suitable for generating new, high-level software architectures.</p><h3 id="the-gpt-family">The GPT family</h3><p><strong>Best for:</strong> Refactoring and modifying specific parts of a program.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXc9oEM_i6rROCWpWK_PYkvwAyleCHh8Lc6ILHvRKl60R2pbqqP4D8axZ3SriSDaCpsEpi8CbTc38jeU8aA7-pLONgsI_3SdOu-3X58NFqXi-peyh3s26x9Q5EKaME67jQFzQIRh?key=V2J9xv6PXC5DZeqc4AtWjfpF" class="kg-image" alt="ChatGPT UI - screenshot taken from the ChatGPT website" loading="lazy" width="602" height="255"><figcaption><span style="white-space: pre-wrap;">ChatGPT UI - screenshot taken from the ChatGPT website</span></figcaption></figure><p>The GPT family–which stands for “Generative Pre-trained Transformers”–is a family of LLMs based on the transformer deep learning architecture introduced by <a href="https://openai.com/?ref=blog.n8n.io"><u>OpenAI</u></a>.</p><p>Among the different <a href="https://platform.openai.com/docs/models?ref=blog.n8n.io"><u>products and models</u></a> released by OpenAI, ChatGPT is certainly the most famous. Its latest versions are currently based on the following models:</p><ul><li><a href="https://platform.openai.com/docs/models?ref=blog.n8n.io#gpt-3-5-turbo"><u>GPT-3.5 Turbo</u></a>: This general-purpose model can understand and generate natural language or code and has been optimized for chatting by using the Chat Completions API.&nbsp;</li><li><a href="https://platform.openai.com/docs/models?ref=blog.n8n.io#gpt-4o"><u>GPT-4o/mini/audio/realtime</u></a>: This sub-family of models is versatile and highly intelligent. The GPT-4o, for example, accepts both text and image inputs, and produces text outputs. Its ‘mini’ version is fast and ideal for fine-tuning. The ‘Realtime’ and ‘Audio’ versions, instead, respond to audio and text inputs in real time and accept audio inputs and outputs, respectively.</li><li><a href="https://platform.openai.com/docs/models?ref=blog.n8n.io#o1"><u>GPT-o1/mini</u></a>: This series of models is trained with reinforcement learning to perform complex reasoning. In particular, the o1 models’ reasoning is designed to solve hard problems across domains; the o1-mini, instead, provides a fast and affordable reasoning model for specialized tasks.</li></ul><p><strong>License:</strong></p><p>Proprietary/Commercial</p><p><strong>Key features for coding:</strong></p><p>The GPT family is a general-purpose LLM family, but it is also suitable for coding tasks and for a wide variety of programming languages and frameworks.</p><p>Its coding features that are particularly loved by developers are:</p><ul><li><strong>API</strong>: You can access OpenAI models via <a href="https://openai.com/index/openai-api/?ref=blog.n8n.io"><u>API calls</u></a>. This allows you to leverage its LLMs via your preferred programming language, allowing you to prompt its models by using the APIs. This helps you integrate the power of AI into your coding projects.</li><li><strong>Canvas</strong>: The GPT-4o provides <a href="https://openai.com/index/introducing-canvas/?ref=blog.n8n.io"><u>Canvas</u></a>. With Canvas you can highlight specific sections to indicate exactly what you want ChatGPT to focus on. This means, for example, that you can directly edit a portion of code you highlighted without asking ChatGPT to recreate it all or avoiding copy-paste it into the editor.</li></ul><h3 id="codex">Codex</h3><p><strong>Best for:</strong> Coding in Python.</p><figure class="kg-card kg-image-card"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXeDCBRZCZcQqAtlJ5RpFeOQePs5a_2ktBijR9OFoAhsdHCF27RwCpuXMcxHYH9T7uEtHflwMKCGCwKJU5qNonWTIPS6b4-iofu2nNJTo9ZCi-hqnxw8ThdSWSfqGULGR7uMUnc3FQ?key=V2J9xv6PXC5DZeqc4AtWjfpF" class="kg-image" alt="Codex website" loading="lazy" width="602" height="505"></figure><p><a href="https://openai.com/index/openai-codex/?ref=blog.n8n.io"><u>OpenAI Codex</u></a>–the model that powers <a href="https://github.com/features/copilot?ref=blog.n8n.io"><u>GitHub Copilot</u></a>⁠–is an advanced AI system designed to translate natural language into code, enhancing the programming experience by allowing users to interact with software through everyday language. As a descendant of GPT-3, Codex has been trained on a vast dataset that includes both natural language and billions of lines of publicly available source code, notably from GitHub repositories. This training enables Codex to proficiently understand and generate code in over a dozen programming languages.</p><p>Codex excels at breaking down complex problems into simpler components and mapping these components to existing code libraries or functions, which is often considered one of the more tedious aspects of programming. By automating this process, Codex lowers the barrier to entry for new programmers and enhances productivity for experienced developers.</p><p><strong>License</strong>:</p><p>Proprietary/Commercial.</p><p><strong>Key features for coding:</strong></p><p>Codex is specifically fine-tuned for programming tasks, making it particularly suitable at understanding and generating code.</p><p>What makes it particularly stand out is its 14KB memory capacity for Python code. This allows it to consider more contextual information when generating code, leading to more accurate Pythonic outputs.</p><h3 id="the-llama-family">The LLaMA family</h3><p><strong>Best for:</strong> Long contexts handling.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXcejjb5UO-SsZqYiEnbnDrPCBAC00Rf2pDx1dVCoK9aeqfaqZrFZ_xeeysw3MuBdLkEPzVZNqjzPakuM3PLdlSollNe2-mqUFsVXxJg5FKb0fBuhO_mKxddAf8mvvaT8UgKDZMl?key=V2J9xv6PXC5DZeqc4AtWjfpF" class="kg-image" alt="The LLaMA website" loading="lazy" width="602" height="307"><figcaption><span style="white-space: pre-wrap;">The LLaMA website</span></figcaption></figure><p>The <a href="https://www.llama.com/?ref=blog.n8n.io"><u>LLaMA</u></a> (Large Language Model Meta AI) family is a series of advanced models developed by Meta. They are designed for natural language processing (NLP) tasks such as text generation, summarization, coding, reasoning, and more.</p><p>While LLaMA 3.x models are not specifically optimized for coding tasks–but can handle them due to their general training–the model specifically designed for coding purposes is <a href="https://codellama.dev/about?ref=blog.n8n.io"><u>Code LLaMA</u></a>.</p><p><strong>License</strong>:</p><p>Open-source (community license: free for research and commercial use but the training datasets are not publicly available).</p><p><strong>Key features for coding:</strong></p><p>Code LLaMA is the best choice of the family for coding tasks, as it is fine-tuned for programming. It offers advanced features like long context handling and support for multiple programming languages.</p><p>CodeLLaMA is itself a family of models and <a href="https://huggingface.co/codellama/CodeLlama-7b-Python-hf?ref=blog.n8n.io"><u>it is subdivided into</u></a>:</p><ul><li><strong>Base model</strong>: General-purpose coding model.</li><li><strong>Python-specific model</strong>: Fine-tuned for Python tasks.</li><li><strong>Instruct model</strong>: Optimized for instruction-following tasks, making it better at understanding and responding to natural language prompts about code.</li></ul><p>Note that all these models can be downloaded from the Ollama <a href="https://github.com/ollama/ollama?ref=blog.n8n.io"><u>library</u></a>, available both for Python and Javascript.</p><h3 id="mistral-ai">Mistral AI</h3><p><strong>Best for:</strong> Generating code suggestions.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXcmkGEIb3Uq73v6mmqAdxHUEavgLjiToW7T_wYSJhTwOlHRGaCixNShZglDYM0UrGtDwAEOT0vQ2VOlJV1jeKOigvYT5NcErss9wvPnK85YU4rcXh1WCHYcd_O4UUXU_hy93ZtX?key=V2J9xv6PXC5DZeqc4AtWjfpF" class="kg-image" alt="Mistral UI - screenshot taken from the Mistral website" loading="lazy" width="602" height="189"><figcaption><span style="white-space: pre-wrap;">Mistral UI - screenshot taken from the Mistral website</span></figcaption></figure><p>Mistral is a pre-trained, general-purpose, model developed by Mistral AI. Currently, their latest model is <a href="https://mistral.ai/news/announcing-mistral-7b/?ref=blog.n8n.io"><u>Mistral 7B</u></a> which has been pre-trained with 7 billion parameters.</p><p>One of the standout features of Mistral 7B is its open-weight nature, meaning the model weights are freely available to the public. This openness has made it a popular choice among researchers, developers, and organizations looking to integrate advanced AI capabilities into their workflows without the constraints of proprietary systems.</p><p><strong>License:</strong></p><p>Open-weight model (the model weights are freely available for download and use under the Apache 2.0 license).</p><p><strong>Key features for coding:</strong></p><p>Despite being a general-purpose model, Mistral 7 B approaches the performance of specialized models like Code Llama 7 B in code-related tasks. Thanks to advanced attention mechanisms like Grouped-Query Attention (GQA) and Sliding Window Attention (SWA), which enhance its efficiency and ability to handle longer sequences, Mistral 7B has fewer parameters but is still able to perform as well as GQA and SWA.</p><p>This can be of particular interest to developers, as Mistral 7B also provides <a href="https://docs.mistral.ai/api/?ref=blog.n8n.io"><u>public APIs</u></a>. Thus, it can be integrated into development tools like IDEs, enabling real-time code suggestions and improvements. It also supports fine-tuning for specific tasks, making it adaptable to various coding needs.</p>
<!--kg-card-begin: html-->
<script>
  workflowBanner([2333, 2335], document.currentScript, { 
      workflowsHeader: "Integrate Mistral's AI into your workflows with n8n"
  });
</script>
<!--kg-card-end: html-->
<h3 id="palm-2">Palm 2</h3><p><strong>Best for:</strong> Coding into specialized programming languages.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfoSCRq_CpMUoNLEWK7JwFBbXFywqwJ01r_ux6f13JurlsguQxttIsOblMHV-csZMCLomZvcXC1-Fu8BD1T8-Gd3dDK0zUOuERZBVQf_FQR2XIO_QDLJC0SbopEJRH-4L13d00i?key=V2J9xv6PXC5DZeqc4AtWjfpF" class="kg-image" alt="The PaLM website" loading="lazy" width="602" height="501"><figcaption><span style="white-space: pre-wrap;">The PaLM website</span></figcaption></figure><p>PaLM 2 (Pathways Language Model 2) is a state-of-the-art large language model developed <a href="https://ai.google/get-started/our-models/?ref=blog.n8n.io"><u>by Google</u></a>, designed to advance natural language understanding and generation.</p><p>One of the standout features of PaLM 2 is its enhanced multilingual proficiency. It supports over 100 languages and demonstrates a deep understanding of cultural nuances, idiomatic expressions, and context-specific meanings. This makes it particularly effective for translation, cross-lingual tasks, and global applications.</p><p><strong>License:</strong></p><p>Proprietary/Commercial</p><p><strong>Key features for coding:</strong></p><p>As a general model, PaLM is also suitable for coding purposes, supporting a wide range of programming languages, including Python, JavaScript, Go, and more.</p><p>As it has been trained on a vast dataset, it can also generate code in specialized languages like Prolog, Fortran, and Verilog.&nbsp;</p><h3 id="the-gemini-family">The Gemini family</h3><p><strong>Best for:</strong> Integrating into the Google ecosystem.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXf8CNsthoHFWTOP4jJcytBh1hmcemGpfhab5fw3mhTJTNtB9R22Sn3O8ofKaJgp7ix231154bDRuTiqNYiTA4TPLn8O6zhSB7uTvlxOMk_-jDiuZK-HUfGGa6p4SDI2iBmTiKY4Qw?key=V2J9xv6PXC5DZeqc4AtWjfpF" class="kg-image" alt="The Gemini website" loading="lazy" width="602" height="275"><figcaption><span style="white-space: pre-wrap;">The Gemini website</span></figcaption></figure><p>The Gemini family, developed by <a href="https://ai.google/get-started/our-models/?ref=blog.n8n.io"><u>Google DeepMind</u></a>, represents a diverse range of capabilities tailored to various use cases, from high-performance reasoning to efficient on-device tasks.</p><p>Currently, there are the following models in this family:</p><ul><li><strong>Gemini 2.0 Flash Experimental</strong>: The latest and most advanced model in the lineup. This experimental model introduces multimodal capabilities, including native image generation, text-to-speech, and real-time interaction through the Multimodal Live API.</li><li><strong>Gemini 1.0 Ultra and Gemini 1.5 Pro</strong>: The earlier models in the Gemini family that cater to more established use cases. Gemini 1.0 Ultra is the largest model in the family, designed for highly complex tasks like advanced coding, mathematical reasoning, and multimodal problem-solving. Gemini 1.5 Pro strikes a balance between performance and versatility, offering a 2 million token context window and the ability to process large-scale data, such as hours of audio or thousands of lines of code.</li><li><strong>Gemini 1.0 Pro and Gemini 1.0 Nano</strong>: These are for more lightweight and specialized applications. Gemini 1.0 Pro, though set to be deprecated in the first months of 2025, focuses on natural language tasks, multi-turn conversations, and code generation, serving as a foundational model for text-based applications. On the other hand, Gemini 1.0 Nano is optimized for on-device tasks, offering efficient performance for mobile and embedded systems.</li></ul><p><strong>License:</strong></p><p>Proprietary/Commercial</p><p><strong>Key features for coding:</strong></p><p>Among all the models, Gemini 2.0 Flash Experimental and Gemini 1.5 Pro excel in coding tasks. In particular, they can process extensive codebases, with context windows of up to 2 million tokens. This allows them to handle large-scale projects, such as analyzing thousands of lines of code or managing complex multi-file systems.</p><p>Finally, Gemini models can be integrated into Google's ecosystem, such as Google Cloud's Vertex AI, where developers can access its coding capabilities through the <a href="https://ai.google.dev/gemini-api/docs?hl=en&ref=blog.n8n.io"><u>Gemini Developer APIs</u></a>. This makes it easy to incorporate its features into development pipelines and workflows.</p>
<!--kg-card-begin: html-->
<script>
  workflowBanner([2812, 2789, 2658], document.currentScript, { 
      workflowsHeader: "Integrate Gemini's AI into your workflows with n8n"
  });
</script>
<!--kg-card-end: html-->
<h3 id="codebert">CodeBERT</h3><p><strong>Best for:</strong> Clone detection.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXezDN2S9E9M7l7EoMTxnIr2graNTW922VYr4cjYGKG8Cq3v_wOc6ini_vx437Qm3xEV16p3VKrcqwGyNL5ryfrlWFv75zRC9bbE9UThE8nyEi2fKa1YHg53bRqk5ACoQe4_2UsFlw?key=V2J9xv6PXC5DZeqc4AtWjfpF" class="kg-image" alt="CodeBERT - Screenshot taken from the CodeBERT repository on GitHub" loading="lazy" width="602" height="301"><figcaption><span style="white-space: pre-wrap;">CodeBERT - Screenshot taken from the CodeBERT repository on GitHub</span></figcaption></figure><p><a href="https://github.com/microsoft/CodeBERT?ref=blog.n8n.io"><u>CodeBERT</u></a>, developed by Microsoft, is a pre-trained model designed for programming and natural languages. It is part of a series of models designed to improve code understanding and generation tasks.</p><p>CodeBERT is a multi-programming-lingual model trained on natural language (NL) and programming language (PL) pairs across six programming languages: Python, Java, JavaScript, PHP, Ruby, and Go. The model is particularly useful for tasks such as code search, code documentation generation, and embedding generation for NL-PL pairs.</p><p><strong>License:</strong></p><p>Open source (MIT License).</p><p><strong>Key features for coding:</strong></p><p>CodeBERT is built on the <a href="https://huggingface.co/docs/transformers/main/index?ref=blog.n8n.io"><u>Hugging Face Transformers framework</u></a>, making it easy to load and use pre-trained models. Developers can integrate it into their workflows with minimal effort using familiar tools like <code>AutoTokenizer</code> and <code>AutoModel</code>.</p><p>As is it pre-trained on natural language and programming language pairs across six popular programming languages (Python, Java, JavaScript, PHP, Ruby, and Go), this makes this model particularly specialized in those programming languages.</p><p>Also, CodeBERT generates embeddings for both code and natural language, enabling tasks like code search, where developers can search for code snippets using natural language queries. It even supports semantic understanding of code, making it useful for tasks like code classification, clone detection, and bug detection.</p><h3 id="the-command-family">The Command family</h3><p><strong>Best for:</strong> Real-time applications.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXdyoTD8qqwqcTx6d6TzRGcT-4bg0Hq7u9-L6O_BnAA5TKSLX2H7riBDeHMp6tL-2sIfsa3jnhp6vwEBpehc7qI-AHyj0UooMAT3Bjw5incA-cX_CbYM6bvOQ6nYRYB5jwWWBdpIKQ?key=V2J9xv6PXC5DZeqc4AtWjfpF" class="kg-image" alt="The Command website" loading="lazy" width="602" height="295"><figcaption><span style="white-space: pre-wrap;">The Command website</span></figcaption></figure><p>The<a href="https://cohere.com/command?ref=blog.n8n.io"><u> Command family of models by Cohere</u></a> is a suite of high-performance, scalable language models designed to deliver strong accuracy and efficiency. These models are tailored for enterprise use, enabling businesses to transition seamlessly from proof-of-concept stages to production-grade applications.</p><p>By balancing efficiency and accuracy, these models are ideal for businesses looking to integrate AI into their workflows for tasks like content generation, document analysis, and large-scale data processing.</p><p><strong>License:</strong></p><p>Proprietary/Commercial.</p><p><strong>Key features for coding:</strong></p><p>Command models are optimized for tool use, meaning they can interact with external tools like APIs, databases, or search engines to enhance their functionality.&nbsp;</p><p>With a context window of up to 128K tokens (in models like Command R7B), these models can process and understand large codebases, making them suitable for complex coding tasks. Also, Models like Command R7B are optimized for high throughput and low latency, making them ideal for real-time.</p><h3 id="the-falcon-family">The Falcon family</h3><p><strong>Best for:</strong> Deployment on low-resource devices.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXdgsavkL0qHNXv9f1JZEBeUEII0Gj085o6gj5B2kj8m21Pd7auqn9MWjf7F-LhNWSsu79Vkc9fKphA32_qmSpCeyvJPg46M8zRolo03Ef0_BqEUH5UpablR4oIus45FlqwSWdL5dQ?key=V2J9xv6PXC5DZeqc4AtWjfpF" class="kg-image" alt="The Falcon website" loading="lazy" width="602" height="267"><figcaption><span style="white-space: pre-wrap;">The Falcon website</span></figcaption></figure><p><a href="https://falconllm.tii.ae/?ref=blog.n8n.io"><u>The Falcon LLM models</u></a>, developed by the Technology Innovation Institute (TII) in Abu Dhabi, represent a cutting-edge suite of open-source large language models (LLMs) designed to democratize access to advanced AI.&nbsp;</p><p>This ecosystem currently includes the following models:</p><ul><li><strong>Falcon 3</strong>: Lightweight and resource-efficient model that can run on minimal infrastructure, including laptops, without sacrificing performance. It includes four scalable models optimized for multilingual and diverse applications.</li><li><strong>Falcon Mamba 7B</strong>: The first open-source State Space Language Model (SSLM), offering low memory costs and the ability to generate long text blocks efficiently. It outperforms traditional transformer models like Meta’s Llama 3.1 8B and Mistral 7B.</li><li><strong>Falcon 2</strong>: A multilingual and multimodal model with vision-to-language capabilities. It outperforms Meta’s Llama 3 8B and rivals Google’s Gemma 7B, with plans to incorporate "Mixture of Experts" (MoE) for enhanced performance.</li><li><strong>Falcon 40B</strong>: A 40-billion-parameter model trained on one trillion tokens, designed for both research and commercial use. It was the first open-source large language model released with weights under the permissive Apache 2.0 license.</li><li><strong>Falcon 180B</strong>: A 180-billion-parameter model trained on 3.5 trillion tokens, ranking as one of the most powerful open-source LLMs globally. It is available for research and commercial use under a royalty-free license.</li></ul><p><strong>License:</strong></p><p>All Falcon models are open source, but Falcon 180B has additional licensing conditions for specific use cases, particularly for shared hosting services.</p><p><strong>Key features for coding:</strong></p><p>Falcon models are built on a transformer-based causal decoder architecture, which is well-suited for coding tasks, but they are general-purpose models.</p><p>However, the best LLM for coding in this family is Falcon 3 as it offers quantized versions, making it efficient for deployment on low-resource devices, which can be useful for lightweight coding tools.</p><h3 id="the-stability-family">The Stability family</h3><p><strong>Best for:</strong> Filling code in the middle of tasks (FIM).</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXccBMAtywKVVI2C3MkCups6rV096gZzCSZVQJxw2qi1rtFo7NAJKU6m8KoVYSSw9l_EjqKzqasRoErllowtU-qGB3GUD-0y-GjjEbPL98r3f5bTxZv6P5JPg4QSEl01jRWdumHjvw?key=V2J9xv6PXC5DZeqc4AtWjfpF" class="kg-image" alt="The Stability website" loading="lazy" width="602" height="331"><figcaption><span style="white-space: pre-wrap;">The Stability website</span></figcaption></figure><p><a href="https://stability.ai/stable-lm?ref=blog.n8n.io"><u>Stability AI's language models</u></a>, branded under the "Stable LM" series, are designed for a wide range of applications, from multilingual communication to specialized tasks like coding and instruction-following. In addition to general-purpose LLMs, Stability AI offers specialized models like Stable Code 3B and Stable Code Instruct 3B, which are optimized for software development tasks such as code generation and completion.&nbsp;</p><p>Here’s how this family of LLMs is composed:</p><ul><li><strong>Stable LM 2 12B</strong>: A 12-billion-parameter multilingual model trained in English, Spanish, German, Italian, French, Portuguese, and Dutch, available in both base and instruction-tuned versions for versatile applications.</li><li><strong>Stable LM 2 1.6B</strong>: A smaller, 1.6-billion-parameter multilingual model offering state-of-the-art performance in multiple languages, designed for lightweight and efficient deployment.</li><li><strong>Stable Code 3B</strong>: A 3-billion-parameter model optimized for accurate and responsive code completion, comparable to larger models like CodeLLaMA 7B but more efficient.</li><li><strong>Stable LM Zephyr 3B</strong>: A lightweight 3-billion-parameter chat model fine-tuned for instruction-following and Q&amp;A tasks, offering responsive and user-friendly interactions.</li><li><strong>Japanese Stable LM</strong>: A specialized model trained exclusively in Japanese, achieving top performance on various Japanese language benchmarks.</li><li><strong>Japanese Stable LM 2 1.6B</strong>: A 1.6-billion-parameter Japanese language model available in both base and instruction-tuned versions, tailored for diverse Japanese language tasks.</li><li><strong>Stable Beluga</strong>: A powerful LLM with exceptional reasoning abilities, suitable for tasks like copywriting, answering scientific questions, and generating creative ideas.</li><li><strong>Stable Code Instruct 3B</strong>: An instruction-tuned version of Stable Code 3B, capable of handling code generation, math, and other software development tasks with natural language prompts.</li></ul><p><strong>License:</strong></p><p>The base Stable LM models, such as Stable LM 2 12B and Stable LM 2 1.6B, are open source and can be freely used, modified, and adapted for various purposes.</p><p>Fine-tuned models, such as Stable LM 2 12B (Instruction-Tuned) or Stable Beluga, trained on datasets like Alpaca or GPT4All, are released under proprietary licenses.</p><p><strong>Key features for coding:</strong></p><p>Among all the stability models, the best coding LLM is Stable Code 3B. In particular, it stands out for its ability to perform FIM (Fill-in-the-Middle) tasks. This ability allows this model to generate code that fills in a missing section in the middle of an existing code snippet. This is different from traditional code completion, which typically involves generating code at the end of a snippet.</p><h3 id="starcoder">Starcoder</h3><p><strong>Best for:</strong> Inferencing AI models.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXcrYlq4GLNIDQWBRnYy8WCrPzafFHJ2UPFzH4COD1tE05Y-mqMiKS_x42KEDIOmlXRO94htLoof-BwFrmrP0vFKLWr9Y28FIsOV4jRKbkJkpnf-yEkflUwwzcWVuMHABHutSd-hQg?key=V2J9xv6PXC5DZeqc4AtWjfpF" class="kg-image" alt="The Starcoder website" loading="lazy" width="602" height="272"><figcaption><span style="white-space: pre-wrap;">The Starcoder website</span></figcaption></figure><p><a href="https://github.com/bigcode-project/starcoder?ref=blog.n8n.io"><u>StarCoder</u></a> is a language model (LM) developed by the <a href="https://www.bigcode-project.org/?ref=blog.n8n.io"><u>BigCode project</u></a>, designed to handle both source code and natural language text. It has been trained on a diverse dataset that includes over 80 programming languages, as well as text from GitHub issues, commits, and notebooks and this makes it particularly adept at tasks like code generation.&nbsp;</p><p>The model is accessible through the Hugging Face Transformers library, enabling developers to integrate it into their workflows for coding assistance and generation. The model has been fine-tuned to function as a coding assistant, with a specific focus on enhancing its ability to follow instructions and align its outputs with human needs. This fine-tuning process leverages high-quality datasets, such as Q&amp;A pairs from Stack Exchange, and employs tools like Hugging Face's PEFT and bits and bytes for efficient training.</p><p><strong>License</strong>:</p><p>Open source (Apache-2.0).</p><p><strong>Key features for coding:</strong></p><p>Developers can fine-tune StarCoder on specific datasets or tasks to improve its performance in niche areas, such as domain-specific programming or unique coding styles. This flexibility allows organizations to adapt the model to their specific needs.</p><p>Furthermore, it supports efficient inference through optimizations like FP16, BF16, and 8-bit precision, which reduce memory requirements while maintaining performance. This makes it accessible for use on consumer-grade GPUs or even CPUs, depending on the task and model size.</p><h3 id="the-xgen-family">The XGen family</h3><p><strong>Best for:</strong> Analyzing large code bases.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXd3WZqRI8U9n3QHPuNzvJcqvaeVqCadV4f_9f15yADO5hN4g2vYCYZc5pBzM_uxDA54SzzsXQSr1p37Kelk8Ja0hJtPWni4TAo8C1GgCW-yWVW9Syalpu4dvpSsfG9-nNbMpdjNyw?key=V2J9xv6PXC5DZeqc4AtWjfpF" class="kg-image" alt="The XGen website" loading="lazy" width="602" height="184"><figcaption><span style="white-space: pre-wrap;">The XGen website</span></figcaption></figure><p>The <a href="https://github.com/salesforce/xGen?ref=blog.n8n.io"><u>XGen family</u></a> of models, developed by <a href="https://www.salesforceairesearch.com/?ref=blog.n8n.io"><u>Salesforce AI Research</u></a>, represents a series of open-source large language models designed for long-sequence modeling. The flagship model, XGen-7B, is trained to handle input sequences of up to 8000 tokens, making it particularly suitable for tasks requiring extended context. Tis family includes three variants:</p><ul><li><strong>XGen-7B-4K-Base</strong> supporting 4K sequence length.</li><li><strong>XGen-7B-8K-Base</strong> supporting 8K sequence length.</li><li><strong>XGen-7B-8K-Inst</strong> fine-tuned for instruction-based tasks and intended for research purposes.</li></ul><p>These models are designed as auto-regressive samplers, enabling developers to generate text by providing a prompt and sampling from the model's output. The implementation is straightforward, utilizing the HuggingFace Transformers library for loading the models and tokenizers.</p><p><strong>License</strong>:</p><p>Open source (Apache-2.0).</p><p><strong>Key features for coding:</strong></p><p>While primarily designed for long-sequence natural language processing tasks, the XGen models are also suitable for coding-related applications.</p><p>For example, with the support for up to 8000 tokens, the XGen-7B-8K-Base model can process and generate code that spans long files or complex scripts. This feature makes it the best LLM for coding from its family when you have to manage tasks like analyzing large codebases.</p><h3 id="the-pythia-family">The Pythia family</h3><p><strong>Best for</strong>: Learning how LLM models learn and process information.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXe6poFQhGASS4Z2afcqPQtrTRHP0l5X4cSYMuFvrs0q7jy1Ig9ApmaykGJL3HaKOkOeTpGpIPTzLIqPlV-Q9XGJDzodQi2seHqteVN664pK9ks88b6wHtl7h0NX-C21YWTCcff3ow?key=V2J9xv6PXC5DZeqc4AtWjfpF" class="kg-image" alt="The Pythia website" loading="lazy" width="602" height="236"><figcaption><span style="white-space: pre-wrap;">The Pythia website</span></figcaption></figure><p>The <a href="https://github.com/EleutherAI/pythia?ref=blog.n8n.io"><u>Pythia LLM family</u></a>, developed by <a href="https://www.eleuther.ai/?ref=blog.n8n.io"><u>EleutherAI</u></a>, is a suite of autoregressive transformer models designed to facilitate research in interpretability, learning dynamics, and ethical AI practices. The project uniquely emphasizes transparency and reproducibility, offering public access to all models, data, and code.&nbsp;</p><p>This suite of LLMs includes eight model sizes, ranging from 14 million to 12 billion parameters, trained on approximately 300 billion tokens. A standout feature of Pythia is its 154 checkpoints saved throughout training, enabling researchers to study the learning dynamics of LLMs in unprecedented detail. All models were trained on the same dataset, "<a href="https://pile.eleuther.ai/?ref=blog.n8n.io"><u>The Pile</u></a>," in the same order, ensuring consistency and enabling causal interventions in the training process.</p><p><strong>License</strong>:</p><p>Open source (Apache 2.0).</p><p><strong>Key features for coding:</strong></p><p>Pythia models are a general-purpose LLM family. However, its 154 training checkpoints make it particularly interesting for coding. These checkpoints are available for each model, so developers can fine-tune Pythia models for specific coding datasets or tasks, such as improving performance in a particular programming language or domain.</p><p>This particular design enables researchers to study how the models learn and process information, which can be applied to understanding how the models handle coding tasks, such as syntax generation or error detection.</p><h3 id="the-wizardlm-family">The WizardLM family</h3><p><strong>Best for</strong>: Debugging code.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXcra_Z4mE8fFO-ybGbrXvYQWA-LXAQ7WBWpX1OshlATVwod26wJ1HUPJjhYbsL5YOZp5GPzCS84BBHX3_MympT4U_0MeG8_h3mTkotBIFwA1V9tEZc_dHB6BUxf2_PI0OpPfC4kbA?key=V2J9xv6PXC5DZeqc4AtWjfpF" class="kg-image" alt="The WizardLM website" loading="lazy" width="602" height="325"><figcaption><span style="white-space: pre-wrap;">The WizardLM website</span></figcaption></figure><p><a href="https://github.com/nlpxucan/WizardLM?ref=blog.n8n.io"><u>WizardLM</u></a> is a family of LLMs designed to follow complex instructions that excels in various tasks, including natural language processing, code generation, and mathematical reasoning. Built upon the Evol-Instruct framework, WizardLM leverages a method to automatically generate diverse and challenging open-domain instructions using LLMs instead of human input. This approach enhances the model's ability to handle a wide range of skills and difficulty levels, making it a versatile tool for both academic and practical applications.</p><p>The project includes several specialized models, such as WizardCoder for coding tasks and WizardMath for mathematical reasoning, each fine-tuned to achieve state-of-the-art performance in its respective domain.</p><p><strong>License</strong>:</p><p>While the WizardLM project provides access to many of its model weights and resources for academic and research purposes, not all WizardLM models are fully open-source.</p><p><strong>Key features for coding:</strong></p><p>Among the family models, the best coding LLM is the WizardCoder series, as it is designed to excel in coding-related tasks.</p><p>In particular, the WizardCoder models are optimized for multi-turn interactions, allowing them to engage in iterative problem-solving and debugging processes. This feature is useful for developers who need step-by-step assistance or clarification during coding tasks.</p><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">💡</div><div class="kg-callout-text">During development, adding log messages is a good practice that helps you with debugging errors. To configure logging for your development workflow in n8n, <a href="https://docs.n8n.io/hosting/logging-monitoring/logging/?ref=blog.n8n.io#log-levels"><u>read about the logging feature and how to configure it</u></a>.</div></div><h3 id="the-vicuna-family">The Vicuna family</h3><p><strong>Best for</strong>:&nbsp;Understanding and managing multi-file projects.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfor7lomboiGHyMQDDbrhHZGCdKJnZaCQZPL3t4KGw_g-AY7asT7V8p7iTolSuBR0iziUP13Yv0n5Sw0qG6iMlrGHAkXNI635UcXTFY5s44SCf0jzUuEISoKgdbUDH6B9f8ZHbN9A?key=V2J9xv6PXC5DZeqc4AtWjfpF" class="kg-image" alt="The Vicuna website" loading="lazy" width="602" height="409"><figcaption><span style="white-space: pre-wrap;">The Vicuna website</span></figcaption></figure><p>The <a href="https://ollama.com/library/vicuna?ref=blog.n8n.io"><u>Vicuna</u></a> family models, by the <a href="https://lmsys.org/projects/?ref=blog.n8n.io"><u>LMSYS</u></a>, are a general-purpose chat assistant built on the foundation of Llama and Llama 2 architectures. The model is offered in three sizes: 7 billion, 13 billion, and 33 billion parameters, catering to varying computational needs and performance requirements.</p><p>These models are designed to handle a wide range of general-purpose chat tasks, making them versatile tools for applications like customer support, personal assistance, and educational purposes.</p><p><strong>License</strong>:</p><p>Open-weight models (the models are built on top of the LLaMA and LLaMA 2 architectures, which are themselves released under a non-commercial license. So, their weights are publicly available for download and use but their usage is subject to the licensing terms of the underlying LLaMA and LLaMA 2 models).</p><p><strong>Key features for coding</strong>:</p><p>The Vicuna models are general-purpose conversational models, but they exhibit features that make them useful for coding-related tasks.</p><p>In particular, Vicuna excels in multi-turn conversations, which is advantageous for iterative coding tasks, so developers can engage in back-and-forth discussions with the model to refine code, troubleshoot errors, or explore alternative solutions. Also, the v1.5-16k variant of supports a context size of up to 16,000 tokens: this extended context length makes this the best LLM for coding from its family in the particular case where coding tasks involve analyzing or generating large codebases and understanding multi-file projects.</p><h3 id="the-sqlcoder-family">The SQLcoder family</h3><p><strong>Best for</strong>: Working with SQL queries.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfGZ2TWxKKn4eMpsC7O4lX8CoeS8qo_2-opRNRlzsf3ZSb-DblJMyxO9kIzGa6fYMXHEWXnDD7fS-YEcmNF7CBOpMlRScIQMCjw-8Xkd86HovE05gyqCBqgS7WbgVcjFJ8RmZSBFw?key=V2J9xv6PXC5DZeqc4AtWjfpF" class="kg-image" alt="The SQLcoder UI - screenshot taken from the SQLcoder website" loading="lazy" width="602" height="348"><figcaption><span style="white-space: pre-wrap;">The SQLcoder UI - screenshot taken from the SQLcoder website</span></figcaption></figure><p><a href="https://github.com/defog-ai/sqlcoder?ref=blog.n8n.io"><u>SQLCoder</u></a>, developed by <a href="https://defog.ai/?ref=blog.n8n.io"><u>Defog</u></a>, is a specialized code completion model fine-tuned on the StarCoder base model, designed specifically for SQL generation tasks. It is optimized to convert natural language questions into SQL queries, making it particularly useful for database-related tasks.</p><p>The model is designed to handle complex SQL query generation by adhering to specific rules, such as using table aliases to avoid ambiguity and casting numerators as floats when creating ratios. It is capable of processing detailed database schemas and generating accurate SQL queries tailored to the schema's structure and it comes in two sizes: a 7B parameter version (4.1GB) and the full 15B parameter version (9.0GB), with the latter requiring at least 16GB of RAM for optimal performance.</p><p><strong>License</strong>:</p><p>Open source (Apache-2.0).</p><p><strong>Key coding features</strong>:</p><p>SQLCoder is fine-tuned specifically for SQL-related tasks, enabling it to convert natural language questions into accurate SQL queries. It is trained on a diverse dataset of SQL examples, allowing it to excel at simple and complex queries across various database schemas.</p><p>Also, as the models are open-source, developers can use, modify, and fine-tune them for specific use cases.</p><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">💡</div><div class="kg-callout-text">n8n has strong support for all major SQL engines. We’ve already posted several articles dedicated to different use cases for<a href="https://n8n.io/integrations/mysql/?ref=blog.n8n.io" target="_blank" rel="noopener">&nbsp;MySQL</a>,&nbsp;<a href="https://n8n.io/integrations/microsoft-sql/?ref=blog.n8n.io" target="_blank" rel="noopener">MS SQL</a>,&nbsp;<a href="https://n8n.io/integrations/postgres/?ref=blog.n8n.io" target="_blank" rel="noopener">PostgreSQL</a>.</div></div><h3 id="the-jamba-family">The Jamba family</h3><p><strong>Best for</strong>: REST APIs interaction.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfHOfGEJ0SSP0b4GPo-wBESz-iC7ixnwMFmfSLd5EGKHyB3-OKn0-s0zCBeODCAAhQzNFr6WmDehzV3oTmENVthctllrMjBR04_AQ3MayCrHV8eC1_QmdefWkEzUNPu-Qpfp0hx?key=V2J9xv6PXC5DZeqc4AtWjfpF" class="kg-image" alt="The Jamba UI - screenshot taken from the Jamba website" loading="lazy" width="602" height="289"><figcaption><span style="white-space: pre-wrap;">The Jamba UI - screenshot taken from the Jamba website</span></figcaption></figure><p>The <a href="https://www.ai21.com/jamba?ref=blog.n8n.io"><u>Jamba family</u></a>, developed by AI21 Labs, represents a significant innovation in AI architecture that combines the strengths of Transformer and Mamba Structured State Space models. This hybrid architecture, known as the SSM-Transformer, addresses key limitations of traditional Transformer models, such as their large memory footprint and inefficiency with long contexts.&nbsp;</p><p>These models excel in handling extensive context windows, offering an industry-leading 256K token context length, which is particularly beneficial for tasks like document summarization, retrieval-augmented generation (RAG), and complex reasoning. This family currently includes two models–Jamba 1.5 Mini and Jamba 1.5 Large–both optimized for speed, quality, and resource efficiency.</p><p><strong>License</strong>:</p><p>Open-source (Apache 2.0).</p><p><strong>Key features for coding</strong>:</p><p>The Jamba family is a general-purpose one but offers interesting coding-related features.</p><p>For example, they support structured JSON output and function calls, which are essential for coding tasks. This allows developers to generate well-structured code snippets, API responses, or data outputs that can be directly integrated into applications. The ability to handle function calls also makes it easier to automate workflows and interact with APIs programmatically.</p><h3 id="the-qwen-family">The Qwen family</h3><p><strong>Best for:</strong> Enhancing coding workflows.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXcANo9H3jSWn5OPPwlZ54AkdtlIxLJOxnJXTzP_b6vpQPQVVaWDAjBelztUgaR6xzvnZqvKUSZWc1EvywOoWDS2GGvnvhgkxPzMYaI-6W-YhIJisuW0AZPYAoVubzJSsyDQWVwjJg?key=V2J9xv6PXC5DZeqc4AtWjfpF" class="kg-image" alt="The Qwen website" loading="lazy" width="602" height="212"><figcaption><span style="white-space: pre-wrap;">The Qwen website</span></figcaption></figure><p>The <a href="https://qwenlm.github.io/?ref=blog.n8n.io"><u>Qwen family,</u></a> developed by the <a href="https://www.alibabacloud.com/en/solutions/generative-ai/qwen?_p_lc=1&ref=blog.n8n.io"><u>Alibaba Group's Qwen Team</u></a>, represents a cutting-edge initiative aimed at advancing AI’s capabilities across various domains, including mathematical reasoning, coding, and multimodal understanding. The models are designed to address key challenges in AI, such as improving reasoning reliability and extending context length for better comprehension.&nbsp;</p><p>Here’s the current model's composition:</p><ul><li><strong>Qwen2.5-Turbo</strong>: Supports an extended context length of up to 1 million tokens, enabling the processing of vast amounts of information in a single session.</li><li><strong>Qwen2.5-Coder Series</strong>: Open-source coding models with state-of-the-art coding capabilities, strong general reasoning, and mathematical skills.</li><li><strong>QVQ (Qwen Vision-Question)</strong>: Combines language and vision to enhance cognitive capabilities, mimicking human perception and reasoning.</li><li><strong>QwQ (Qwen with Questions)</strong>: A philosophically inspired model that emphasizes curiosity and deep reasoning across diverse domains.</li></ul><p><strong>License</strong>:</p><p>Many of the Qwen models, such as Qwen2.5 and its variants (e.g., Qwen2.5-Coder and Qwen2.5-Math), are open source under the Apache 2.0 license. However, exceptions include the 3B and 72B variants, which are not open-source.</p><p>Additionally, flagship models like Qwen-Plus and Qwen-Turbo are not open source but are available through <a href="https://www.alibabacloud.com/help/en/model-studio/developer-reference/use-qwen-by-calling-api?ref=blog.n8n.io"><u>APIs provided by Alibaba Cloud's Model Studio</u></a>.</p><p><strong>Key features for coding</strong>:</p><p>The Qwen family is a general-purpose one, and while they can all handle coding tasks, the best coding LLM of the group is the Qwen2.5-Coder series, as it is designed for coding.</p><p>These models are compatible with popular IDEs and can handle extensive context lengths. They also excel in generating structured outputs like JSON and enhancing its utility in coding workflows.</p><h3 id="the-codet5-family">The CodeT5 family</h3><p><strong>Best for:</strong> Deployment as AI-powered coding assistants.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXesWKN8TPBQmIgCIbrBiVA0mSFVxTEWPHXIuHxfmdb8dx8iyDUn7jVweLX3CVoDDIJQlR06nrhT5MUUIUzFkLz7Gclx-VpE8N2KhYz-jIL3M0pqV7FlxepLv8sVxkNNySiofKO63A?key=V2J9xv6PXC5DZeqc4AtWjfpF" class="kg-image" alt="The CodeT5 process - Screenshot taken from the CodeT5 repository on GitHub" loading="lazy" width="602" height="201"><figcaption><span style="white-space: pre-wrap;">The CodeT5 process - Screenshot taken from the CodeT5 repository on GitHub</span></figcaption></figure><p>The <a href="https://github.com/salesforce/CodeT5?ref=blog.n8n.io"><u>CodeT5 family</u></a>, developed by <a href="https://www.salesforceairesearch.com/?ref=blog.n8n.io"><u>Salesforce Research</u></a>, consists of two large language models designed for code understanding and generation. They have been widely recognized in the research community, with their papers being accepted at prestigious conferences like EMNLP and NeurIPS.</p><p>Here’s its current composition:</p><ul><li><strong>CodeT5</strong> model, introduced in 2021, is an identifier-aware, unified pre-trained encoder-decoder model. It was designed to handle tasks such as text-to-code generation, code autocompletion, and code summarization.</li><li><strong>CodeT5+</strong> in May 2023, which represents an evolution of the original model. CodeT5+ introduces improvements in both architecture and performance, making it more effective for complex code understanding and generation tasks. The model is part of a broader effort to create open, large-scale LLMs for code, and it has been accompanied by research papers and resources to support its adoption. CodeT5+ is designed to be accessible to the developer community, with checkpoints available on platforms like Hugging Face for easy integration into workflows.</li></ul><p><strong>License</strong>:</p><p>Open-source (BSD-3-Clause license).</p><p><strong>Key features for coding</strong>:</p><p>As these LLMs specialize in coding tasks, they’re your best option for custom deployment to use them as coding assistant.</p><h2 id="create-llm-powered-workflows-with-n8n">Create LLM-powered workflows with n8n</h2><p>So far, we reviewed the 20 best LLMs for coding.</p><p>It's important to understand that LLMs operate in isolation, without the workflow orchestration needed to make their outputs immediately actionable.</p><p>Here’s where <a href="https://n8n.io/ai/?ref=blog.n8n.io" rel="noreferrer">n8n</a> comes in!</p><p>n8n provides workflow integration: developers can use AI tools that don’t just generate code but also integrate with existing tools, and processes.</p><p>As a low-code solution specifically developed for automating workflows by using its UI, you can use its prebuilt nodes as they are, but also customize some of them by using code, if you need it.</p><p>Here are the interesting nodes in this scenario:</p><ul><li><a href="https://docs.n8n.io/code/code-node/?ref=blog.n8n.io"><strong><u>The Code node</u></strong></a>: This allows you to write custom code in Python and Javascript and run it as a step in your workflows, allowing you to customize them.</li><li><a href="https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.httprequest/?utm_source=n8n_app&utm_medium=node_settings_modal-credential_link&utm_campaign=n8n-nodes-base.httpRequest"><strong><u>The HTTP request node</u></strong></a>: This allows you to make HTTP requests to query data from any service with REST APIs.</li><li><a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.agent/?ref=blog.n8n.io"><strong><u>The AI Agent node:</u></strong></a> This is an autonomous AI agent node that gives you six LangChain agent options, receives data, makes decisions, and acts to achieve specific goals.&nbsp;</li><li><a href="https://docs.n8n.io/code/ai-code/?ref=blog.n8n.io"><strong><u>The AI coding with GPT</u></strong></a> node: This allows you to leverage AI-generated code while building automation workflows.&nbsp;</li></ul><div class="kg-card kg-callout-card kg-callout-card-red"><div class="kg-callout-emoji">⚠️</div><div class="kg-callout-text"><b><strong style="white-space: pre-wrap;">ATTENTION</strong></b>: <br>The AI coding with GPT node is currently in beta. It’s only available to cloud users and only supports JavaScript.&nbsp;</div></div><p>So, you can use n8n to move beyond standalone AI use cases to create scalable, end-to-end automation that delivers real business impact.</p><p>Let’s see some practical examples!</p><h3 id="how-to-use-llms-for-coding-with-n8n-streamline-code-reviews">How to use LLMs for coding with n8n: Streamline code reviews</h3><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXd0h1tymnx5RgeOK4qmKmFREJmHhZmUkEFponRBMXOJiyZ3gWSPfJVDCxZUfaX7ylnpsCei-HM0tvCVEyABSy_IhOjrC80bfdySP6_MK6AdOHwDda80SyvEth5BnsdnZBHwooZj?key=V2J9xv6PXC5DZeqc4AtWjfpF" class="kg-image" alt="n8n AI-powered workflow for automatic core review - screenshot by Federico Trotta" loading="lazy" width="602" height="133"><figcaption><span style="white-space: pre-wrap;">n8n AI-powered workflow for automatic core review</span></figcaption></figure>
<!--kg-card-begin: html-->
<script>
  workflowBanner(2167, document.currentScript);
</script>
<!--kg-card-end: html-->
<p>Let’s be honest: code reviews take time, especially if you’re working in a large enterprise and need to interact with different teams.</p><p>Also, sometimes, you may just need a “second opinion” to ensure that you gave your peers the right advice when reviewing their code.</p><p>So, fear no more: n8n is here to help you with that! We created a template useful for every engineer who wants to automate their code reviews in GitLab or (just get a 2nd opinion on their PRs). When set up, this workflow automatically reviews your changes in a Gitlab PR using AI: it’s triggered when you comment to a Gitlab PR, makes its analysis with ChatGPT, and replies to the discussion.</p><h3 id="how-to-use-llms-for-coding-with-n8n-write-sql-queries-based-on-database-schema">How to use LLMs for coding with n8n: Write SQL queries based on database schema</h3><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXdHa1kyDlp2gusxYerBo8rMYMuQbwaXwWEa4pTVK3nm9-T-kZsKm3UJun4rX-ZyBFaj4f1iRPD7SjFCBBBfNtCKw7W5r2aVbOh6NYnPl1dxvs0hAxo04R2U6AMDPShCjo8tVh11gA?key=V2J9xv6PXC5DZeqc4AtWjfpF" class="kg-image" alt="n8n AI-powered workflow for creating SQL queries - screenshot by Federico Trotta" loading="lazy" width="602" height="248"><figcaption><span style="white-space: pre-wrap;">n8n AI-powered workflow for creating SQL queries based on database schema</span></figcaption></figure>
<!--kg-card-begin: html-->
<script>
  workflowBanner(2508, document.currentScript);
</script>
<!--kg-card-end: html-->
<div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">💡</div><div class="kg-callout-text">This workflow is created with the <a href="https://docs.n8n.io/integrations/builtin/app-nodes/n8n-nodes-base.mysql/?ref=blog.n8n.io"><u>MySQL </u></a>node, but you can modify it to use any other supported relational database like <a href="https://docs.n8n.io/integrations/builtin/app-nodes/n8n-nodes-base.postgres/?ref=blog.n8n.io"><u>Postgres</u></a>, or <a href="https://docs.n8n.io/integrations/builtin/app-nodes/n8n-nodes-base.microsoftsql/?ref=blog.n8n.io"><u>Microsoft SQL</u></a>.</div></div><p>SQL queries: cross and delight of every engineer! Well, sometimes more a cross than a delight, isn’t it? We know it, and this is why we created a workflow that generates SQL queries prompting ChatGPT that are tailored to the database schema.</p><p>In this workflow, the AI agent accesses only the database schema, not the actual data. This allows the agent to generate SQL queries based on the structure of tables and their relationships, without having to access the actual data, thus providing a secure process.</p><h3 id="how-to-use-llms-for-coding-with-n8n-create-a-chat-assistant-with-postgres-memory">How to use LLMs for coding with n8n: Create a chat assistant with Postgres memory&nbsp;</h3><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXddzLdM4f--q67Ki0PF-Kb8DxVVI9AcawBzAEq0bp4JvrXYAdYSiLZeuDl0Kxf9VN953eITSkMnZGMj33w16RzpXAgekVLmLyyIjdo6pHRxhfF7XLO5UlljYS9A5BSUaYggKhj_?key=V2J9xv6PXC5DZeqc4AtWjfpF" class="kg-image" alt="n8n AI-powered workflow for creating a chat assistant with Postgres - Screenshot by Federico Trotta" loading="lazy" width="602" height="451"><figcaption><span style="white-space: pre-wrap;">n8n AI-powered workflow for creating a chat assistant with Postgres</span></figcaption></figure>
<!--kg-card-begin: html-->
<script>
  workflowBanner(2637, document.currentScript);
</script>
<!--kg-card-end: html-->
<p>This workflow is an intelligent chatbot–that uses the OpenAI node–integrated with a backend that supports WhatsApp Business, and it’s designed to handle various use cases such as sales and customer support.</p><p>It also uses the <a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.memorypostgreschat/?ref=blog.n8n.io"><strong><u>Postgres Chat Memory</u></strong></a> for storing chat history and the HTTP nodes for connecting to anything that may be of help to your customers, like a knowledge base of your online shop. This powers up the interaction with the OpenAI node so that users receive contextualized responses.</p><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">💡</div><div class="kg-callout-text"><b><strong style="white-space: pre-wrap;">TIP</strong></b>:<br>If you are not a master in writing SQL queries, you can modify this workflow by using the schema we've described in the previous workflow that generates SQL queries based on the database schema.</div></div><h3 id="how-to-use-llms-for-coding-with-n8n-automate-chart-generation">How to use LLMs for coding with n8n: Automate chart generation </h3><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXdGZZxIe9W6Lw_IaVP6pFGhcyz0xlL6Eu1Oub-h3vSimuQnMSHp27cH-sbyYqgEvnuB3G4wIdZ4MQn8eqjtlKoCWk2MUf0EpGhiu4jqECpCFS2o587Lz6cASdC-Gk5ELWx9b26y?key=V2J9xv6PXC5DZeqc4AtWjfpF" class="kg-image" alt="n8n AI-powered workflow for automating chart generation - screenshot by Federico Trotta" loading="lazy" width="602" height="383"><figcaption><span style="white-space: pre-wrap;">n8n AI-powered workflow for automating chart generation</span></figcaption></figure>
<!--kg-card-begin: html-->
<script>
  workflowBanner(2559, document.currentScript);
</script>
<!--kg-card-end: html-->
<p>Often, when you query a database the output you need is a chart. However, this process often requires interacting with different software and it might be annoying, particularly if what you need is a chart for a prototype.</p><p>Wouldn’t it be thrilling if you could have an automated process that queries a database and provides a chart, but only if you actually need it? Yes, this is a workflow we created for you!</p><p>This workflow provides data visualization to a native SQL Agent, fostering data analysis and data visualization. It does so by connecting to a database and can query it and translate the response in a human format.</p><h2 id="wrap-up">Wrap up</h2><p>In this article, we’ve gone through an overview of the LLMs landscape and discovered the 20 best LLMs for coding.&nbsp;&nbsp;</p><p>However, while LLMs excel at different tasks – like writing code – they operate in isolation, leaving users to figure out integration and execution.</p><p>This is where n8n comes into the game: it bridges this gap by allowing you to embed LLM capabilities into dynamic, multi-step workflows.</p>
<!--kg-card-begin: html-->
<div class="content-banner">
  <div>
    <h3>Create your own LLM workflows</h3>
    <p>Bridge the gap with n8n—turn LLM outputs into action!</p>
  </div>
  <a href="https://app.n8n.cloud/register?ref=blog.n8n.io" class="global-button blog-banner-signup">Try n8n now</a>
</div>
<!--kg-card-end: html-->
<h2 id="what%E2%80%99s-next">What’s next?</h2><p>Expand your knowledge on AI, automation, and workflow optimization with these in-depth resources:</p><ul><li><a href="../open-source-llm/index.html" rel="noreferrer"><strong>The Best 11 Open-Source LLM Applications</strong></a> – Discover these top 11 open-source LLMs and build advanced AI workflows with n8n LangChain integration.</li><li><a href="../ai-tools-for-business/index.html" rel="noopener"><strong>Top AI Tools for Business</strong></a> – Discover essential AI tools that can enhance efficiency and streamline operations.</li><li><a href="../ai-agents/index.html" rel="noopener"><strong>A Guide to AI Agents</strong></a> – Understand how AI agents work and how they can automate complex decision-making processes.</li><li><a href="../ai-coding-assistants/index.html" rel="noopener"><strong>AI Coding Assistants: Boost Developer Productivity</strong></a> – Explore how AI-powered coding assistants can speed up development and reduce errors.</li><li><a href="https://n8n.io/integrations/categories/ai/?ref=blog.n8n.io" rel="noopener"><strong>AI Integrations for Workflow Automation</strong></a> – Browse AI-powered integrations to enhance your automation workflows in n8n.</li></ul><p>n8n also provides AI-powered workflows for all your needs that span from simple to very complicated. Give them a try:</p>
<!--kg-card-begin: html-->
<script>
  workflowBanner([2373, 2665, 1951, 2673], document.currentScript, { 
      workflowsHeader: "AI workflows powered by n8n"
  });
</script>
<!--kg-card-end: html-->

		<div class="newsletter-banner">
	    <div class="newsletter-banner-content">
	      <div class="section-header">
	        <h2>Subscribe to <span>n8n newsletter</span></h2>
	        <div class="section-subheader--bottom">
	          Get the best, coolest, and latest in automation and low-code delivered to your inbox each week.
	        </div>
	      </div>
	      <div class="newsletter-banner-form">
	        <form autocomplete="off" class="contact-form" onsubmit="subscribeNewsletter(event)">
	        	<div id="recaptcha" class="g-recaptcha"
              data-sitekey="6LeAQeopAAAAAKlLsRb1weWm6T_vijoQBkGkbHzB"
              data-callback="submitSubscription"
              data-size="invisible">
            </div>
	          <div class="input-wrapper">
	            <input placeholder="Email" name="email" type="email" required="required" class="">
	            <div class="messages">
	              <div class="message message--error">Something went wrong. Please try again later.</div>
	              <div class="message message--success">Subscribed!</div>
	            </div>
	          </div>
	          <button type="submit" class="submit-btn">Subscribe</button>
	        </form>
	      </div>
	    </div>
    </div>
		<div class="post-share-section">
	<div class="post-share-wrap">
		<a href="https://twitter.com/intent/tweet?text=The%2020%20best%20LLMs%20for%20coding%20(%2B%20free%20workflow%20templates)&amp;url=https://blog.n8n.io/best-llm-for-coding/" target="_blank" rel="noopener" aria-label="Twitter share icon"><svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M23.954 4.569c-.885.389-1.83.654-2.825.775 1.014-.611 1.794-1.574 2.163-2.723-.951.555-2.005.959-3.127 1.184-.896-.959-2.173-1.559-3.591-1.559-2.717 0-4.92 2.203-4.92 4.917 0 .39.045.765.127 1.124C7.691 8.094 4.066 6.13 1.64 3.161c-.427.722-.666 1.561-.666 2.475 0 1.71.87 3.213 2.188 4.096-.807-.026-1.566-.248-2.228-.616v.061c0 2.385 1.693 4.374 3.946 4.827-.413.111-.849.171-1.296.171-.314 0-.615-.03-.916-.086.631 1.953 2.445 3.377 4.604 3.417-1.68 1.319-3.809 2.105-6.102 2.105-.39 0-.779-.023-1.17-.067 2.189 1.394 4.768 2.209 7.557 2.209 9.054 0 13.999-7.496 13.999-13.986 0-.209 0-.42-.015-.63.961-.689 1.8-1.56 2.46-2.548l-.047-.02z"/></svg></a>
		<a href="https://www.facebook.com/sharer/sharer.php?u=https://blog.n8n.io/best-llm-for-coding/" target="_blank" rel="noopener" aria-label="Facebook share icon"><svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M23.9981 11.9991C23.9981 5.37216 18.626 0 11.9991 0C5.37216 0 0 5.37216 0 11.9991C0 17.9882 4.38789 22.9522 10.1242 23.8524V15.4676H7.07758V11.9991H10.1242V9.35553C10.1242 6.34826 11.9156 4.68714 14.6564 4.68714C15.9692 4.68714 17.3424 4.92149 17.3424 4.92149V7.87439H15.8294C14.3388 7.87439 13.8739 8.79933 13.8739 9.74824V11.9991H17.2018L16.6698 15.4676H13.8739V23.8524C19.6103 22.9522 23.9981 17.9882 23.9981 11.9991Z"/></svg></a>
		<!-- <a href="javascript:" class="post-share-link" id="copy" data-clipboard-target="#copy-link" aria-label="Copy link icon"><svg role="img" viewBox="0 0 33 24" xmlns="http://www.w3.org/2000/svg"><path d="M27.3999996,13.4004128 L21.7999996,13.4004128 L21.7999996,19 L18.9999996,19 L18.9999996,13.4004128 L13.3999996,13.4004128 L13.3999996,10.6006192 L18.9999996,10.6006192 L18.9999996,5 L21.7999996,5 L21.7999996,10.6006192 L27.3999996,10.6006192 L27.3999996,13.4004128 Z M12,20.87 C7.101,20.87 3.13,16.898 3.13,12 C3.13,7.102 7.101,3.13 12,3.13 C12.091,3.13 12.181,3.139 12.272,3.142 C9.866,5.336 8.347,8.487 8.347,12 C8.347,15.512 9.866,18.662 12.271,20.857 C12.18,20.859 12.091,20.87 12,20.87 Z M20.347,0 C18.882,0 17.484,0.276 16.186,0.756 C14.882,0.271 13.473,0 12,0 C5.372,0 0,5.373 0,12 C0,18.628 5.372,24 12,24 C13.471,24 14.878,23.726 16.181,23.242 C17.481,23.724 18.88,24 20.347,24 C26.975,24 32.347,18.628 32.347,12 C32.347,5.373 26.975,0 20.347,0 Z"/></svg></a>
		<small class="share-link-info">The link has been copied!</small> -->
	</div>
	<input type="text" value="https://blog.n8n.io/best-llm-for-coding/" id="copy-link" aria-label="Copy link input">
</div>
	</div>
</article>
<aside class="nextprev-section">
	<div class="nextprev-wrap">
		<section class="nextprev-newer post tag-ai">
			<a href="../iterations-hallucinations-and-lessons-learned-rebuilding-our-ai-assistant-on-n8n/index.html" class="global-link" aria-label="Iterations, hallucinations, and lessons learned: Rebuilding our AI Assistant on n8n"></a>
			<a href="../iterations-hallucinations-and-lessons-learned-rebuilding-our-ai-assistant-on-n8n/index.html" class="nextprev-image global-image">
				<img src="../content/images/size/w400/2025/02/rebuilding-ai-assistant1.png" loading="lazy" alt="Iterations, hallucinations, and lessons learned: Rebuilding our AI Assistant on n8n">			</a>
			<div>
				<small>Newer post</small>
				<h3><a href="../iterations-hallucinations-and-lessons-learned-rebuilding-our-ai-assistant-on-n8n/index.html">Iterations, hallucinations, and lessons learned: Rebuilding our AI Assistant on n8n</a></h3>
			</div>
		</section>
		<section class="nextprev-older post tag-ai tag-guide tag-hash-import-2024-10-24-16-31">
			<a href="../ai-agents/index.html" class="global-link" aria-label="AI Agents Explained: From Theory to Practical Deployment"></a>
			<div>
				<small>Older post</small>
				<h3><a href="../ai-agents/index.html">AI Agents Explained: From Theory to Practical Deployment</a></h3>
			</div>
			<a href="../ai-agents/index.html" class="nextprev-image global-image">
				<img src="../content/images/size/w400/2024/06/ai-chatbots-8--1---3-.png" loading="lazy" alt="AI Agents Explained: From Theory to Practical Deployment">			</a>
		</section>
	</div>
</aside><div class="comments-section">
	<div class="comments-wrap">
			</div>
</div>
            <div class="related-posts">
                  <h3>Other Guides on AI</h3>
              <div class="global-sections global-sections-items-4">
                <h2 class="global-label global-zigzag">
	
	<svg role='img' viewBox='0 0 136 24' xmlns='http://www.w3.org/2000/svg'><path d='M1.525 1.525a3.5 3.5 0 014.95 0L20 15.05 33.525 1.525a3.5 3.5 0 014.95 0L52 15.05 65.525 1.525a3.5 3.5 0 014.95 0L84 15.05 97.525 1.525a3.5 3.5 0 014.95 0L116 15.05l13.525-13.525a3.5 3.5 0 014.95 4.95l-16 16a3.5 3.5 0 01-4.95 0L100 8.95 86.475 22.475a3.5 3.5 0 01-4.95 0L68 8.95 54.475 22.475a3.5 3.5 0 01-4.95 0L36 8.95 22.475 22.475a3.5 3.5 0 01-4.95 0l-16-16a3.5 3.5 0 010-4.95z'/></svg></h2>
<article class="item-section post tag-ai tag-tutorial">
	<a href="../how-to-build-ai-agent/index.html" class="global-link" aria-label="How To Build Your First AI Agent (+Free Workflow Template)"></a>
	<div class="global-image">
		<img srcset="../content/images/size/w300/2025/04/ai-2--1-.png 300w,
			../content/images/size/w400/2025/04/ai-2--1-.pngg 400w,
		../content/images/size/w600/2025/04/ai-2--1-.pngng 600w"
	 sizes="(max-width:480px) 150px, 200px"
	 src="../content/images/size/w300/2025/04/ai-2--1-.png"
	 loading="lazy"
	 alt="How To Build Your First AI Agent (+Free Workflow Template)">	</div>
	<div class="global-sections-content">
		<h3><a href="../how-to-build-ai-agent/index.html">How To Build Your First AI Agent (+Free Workflow Template)</a></h3>
		<div class="global-sections-meta global-meta global-pointer">
			<a href="../author/mihai/index.html">Mihai Farcas</a>
		</div>
	</div>
</article>
                <article class="item-section post tag-ai tag-guide">
	<a href="../ai-agent-frameworks/index.html" class="global-link" aria-label="9 AI Agent Frameworks Battle: Why Developers Prefer n8n"></a>
	<div class="global-image">
		<img srcset="../content/images/size/w300/2025/04/ai-agent-frameworks5.jpg 300w,
			../content/images/size/w400/2025/04/ai-agent-frameworks5.jpgg 400w,
		../content/images/size/w600/2025/04/ai-agent-frameworks5.jpgpg 600w"
	 sizes="(max-width:480px) 150px, 200px"
	 src="../content/images/size/w300/2025/04/ai-agent-frameworks5.jpg"
	 loading="lazy"
	 alt="9 AI Agent Frameworks Battle: Why Developers Prefer n8n">	</div>
	<div class="global-sections-content">
		<h3><a href="../ai-agent-frameworks/index.html">9 AI Agent Frameworks Battle: Why Developers Prefer n8n</a></h3>
		<div class="global-sections-meta global-meta global-pointer">
			<a href="../author/yulia/index.html">Yulia Dmitrievna</a>, <a href="../author/eduard/index.html">Eduard Parsadanyan</a>
		</div>
	</div>
</article>
                <article class="item-section post tag-ai tag-guide">
	<a href="../ai-agents-examples/index.html" class="global-link" aria-label="15 Practical AI Agent Examples to Scale Your Business in 2025"></a>
	<div class="global-image">
		<img srcset="../content/images/size/w300/2025/03/Slide-16_9---172--1-.png 300w,
			../content/images/size/w400/2025/03/Slide-16_9---172--1-.pngg 400w,
		../content/images/size/w600/2025/03/Slide-16_9---172--1-.pngng 600w"
	 sizes="(max-width:480px) 150px, 200px"
	 src="../content/images/size/w300/2025/03/Slide-16_9---172--1-.png"
	 loading="lazy"
	 alt="15 Practical AI Agent Examples to Scale Your Business in 2025">	</div>
	<div class="global-sections-content">
		<h3><a href="../ai-agents-examples/index.html">15 Practical AI Agent Examples to Scale Your Business in 2025</a></h3>
		<div class="global-sections-meta global-meta global-pointer">
			<a href="../author/federico/index.html">Federico Trotta</a>
		</div>
	</div>
</article>
                <article class="item-section post tag-ai tag-guide">
	<a href="../best-ai-for-coding/index.html" class="global-link" aria-label="8 best AI coding tools for developers: tested &amp; compared!"></a>
	<div class="global-image">
		<img srcset="../content/images/size/w300/2025/03/11-ai-tools-coding--2---2-.png 300w,
			../content/images/size/w400/2025/03/11-ai-tools-coding--2---2-.pngg 400w,
		../content/images/size/w600/2025/03/11-ai-tools-coding--2---2-.pngng 600w"
	 sizes="(max-width:480px) 150px, 200px"
	 src="../content/images/size/w300/2025/03/11-ai-tools-coding--2---2-.png"
	 loading="lazy"
	 alt="8 best AI coding tools for developers: tested &amp; compared!">	</div>
	<div class="global-sections-content">
		<h3><a href="../best-ai-for-coding/index.html">8 best AI coding tools for developers: tested &amp; compared!</a></h3>
		<div class="global-sections-meta global-meta global-pointer">
			<a href="../author/yulia/index.html">Yulia Dmitrievna</a>, <a href="../author/eduard/index.html">Eduard Parsadanyan</a>
		</div>
	</div>
</article>
              </div>
            </div>
  <aside class="two-column-posts">
    <h3>Latest n8n guides</h3>
    <div class="two-column-posts__inner">
	      <section class="nextprev-newer post">
  <a href="../how-to-build-ai-agent/index.html" class="global-link" aria-label="How To Build Your First AI Agent (+Free Workflow Template)"></a>
    <a href="../how-to-build-ai-agent/index.html" class="nextprev-image global-image">
      <img src="../content/images/size/w400/2025/04/ai-2--1-.png" loading="lazy" alt="How To Build Your First AI Agent (+Free Workflow Template)">    </a>
  <div>
    <h3><a href="../how-to-build-ai-agent/index.html">How To Build Your First AI Agent (+Free Workflow Template)</a></h3>
  </div>
</section>
	      <section class="nextprev-newer post">
  <a href="../ai-agent-frameworks/index.html" class="global-link" aria-label="9 AI Agent Frameworks Battle: Why Developers Prefer n8n"></a>
    <a href="../ai-agent-frameworks/index.html" class="nextprev-image global-image">
      <img src="../content/images/size/w400/2025/04/ai-agent-frameworks5.jpg" loading="lazy" alt="9 AI Agent Frameworks Battle: Why Developers Prefer n8n">    </a>
  <div>
    <h3><a href="../ai-agent-frameworks/index.html">9 AI Agent Frameworks Battle: Why Developers Prefer n8n</a></h3>
  </div>
</section>
	      <section class="nextprev-newer post">
  <a href="../series-b/index.html" class="global-link" aria-label="n8n closes €55M Series B round led by Highland Europe"></a>
    <a href="../series-b/index.html" class="nextprev-image global-image">
      <img src="../content/images/size/w400/2025/03/seriesB-blog.jpg" loading="lazy" alt="n8n closes €55M Series B round led by Highland Europe">    </a>
  <div>
    <h3><a href="../series-b/index.html">n8n closes €55M Series B round led by Highland Europe</a></h3>
  </div>
</section>
	      <section class="nextprev-newer post">
  <a href="../ai-agents-examples/index.html" class="global-link" aria-label="15 Practical AI Agent Examples to Scale Your Business in 2025"></a>
    <a href="../ai-agents-examples/index.html" class="nextprev-image global-image">
      <img src="../content/images/size/w400/2025/03/Slide-16_9---172--1-.png" loading="lazy" alt="15 Practical AI Agent Examples to Scale Your Business in 2025">    </a>
  <div>
    <h3><a href="../ai-agents-examples/index.html">15 Practical AI Agent Examples to Scale Your Business in 2025</a></h3>
  </div>
</section>
    </div>
  </aside>

					<!-- <div class="subscribe-section">
	<div class="subscribe-wrap">
		<h3>Subscribe to new posts</h3>
		<form data-members-form="subscribe" class="subscribe-form">
			<input data-members-email type="email" placeholder="Your email address" aria-label="Your email address" required>
			<button class="global-button" type="submit">Subscribe</button>
		</form>
		<div class="subscribe-alert">
			<small class="alert-loading global-alert">Processing your application</small>
			<small class="alert-success global-alert">Please check your inbox and click the link to confirm your subscription</small>
			<small class="alert-error global-alert">There was an error sending the email</small>
		</div>
	</div>
</div>
 -->
				</main>
				<div id="subFooter" class="sub-footer">
  <div class="sub-footer-container">
    <div class="footer-columns">
      <div>
        <div class="column-name">Popular integrations</div>
        <ul class="col-links">
          <li>
            <a href="https://n8n.io/integrations/google-sheets/" class="footer-link"> Google Sheets </a>
          </li>
          <li>
            <a href="https://n8n.io/integrations/telegram/" class="footer-link"> Telegram </a>
          </li>
          <li>
            <a href="https://n8n.io/integrations/mysql/" class="footer-link"> MySQL </a>
          </li>
          <li>
            <a href="https://n8n.io/integrations/slack/" class="footer-link"> Slack </a>
          </li>
          <li>
            <a href="https://n8n.io/integrations/discord/" class="footer-link"> Discord </a>
          </li>
          <li>
            <a href="https://n8n.io/integrations/postgres/" class="footer-link"> Postgres </a>
          </li>
          <li class="hidden-link">
            <a href="https://n8n.io/integrations/notion/" class="footer-link"> Notion </a>
          </li>
          <li class="hidden-link">
            <a href="https://n8n.io/integrations/gmail/" class="footer-link"> Gmail </a>
          </li>
          <li class="hidden-link">
            <a href="https://n8n.io/integrations/airtable/" class="footer-link"> Airtable </a>
          </li>
          <li class="hidden-link">
            <a href="https://n8n.io/integrations/google-drive/" class="footer-link"> Google Drive </a>
          </li>
        </ul>
        <div class="bottom-link hidden-link">
          <a href="https://n8n.io/integrations/" class="footer-link">
            Show more integrations
            <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 10 10" width="7px" height="7px">
              <g clip-path="url(#a)">
                <path
                  fill="#111010"
                  fill-rule="evenodd"
                  d="M7.678 1.36H.481V0H10v9.52H8.64v-7.2L.962 10 0 9.038 7.678 1.36Z"
                  clip-rule="evenodd"></path>
              </g>
              <defs>
                <clipPath id="a">
                  <path fill="#fff" d="M0 0h10v10H0z"></path>
                </clipPath>
              </defs></svg
            ></a>
        </div>
        <button
          type="button"
          class="footer-link footer-link--more"
          onclick="document.getElementById('subFooter').classList.toggle('sub-footer--full')"></button>
      </div>
      <div>
        <div class="column-name">Trending combinations</div>
        <ul class="col-links">
          <li>
            <a href="https://n8n.io/integrations/hubspot/and/salesforce/" class="footer-link">
              HubSpot and Salesforce
            </a>
          </li>
          <li>
            <a href="https://n8n.io/integrations/twilio/and/whatsapp-business-cloud/" class="footer-link">
              Twilio and WhatsApp
            </a>
          </li>
          <li>
            <a href="https://n8n.io/integrations/github/and/jira-software/" class="footer-link">
              GitHub and Jira
            </a>
          </li>
          <li>
            <a href="https://n8n.io/integrations/asana/and/slack/" class="footer-link"> Asana and Slack </a>
          </li>
          <li>
            <a href="https://n8n.io/integrations/asana/and/salesforce/" class="footer-link">
              Asana and Salesforce
            </a>
          </li>
          <li>
            <a href="https://n8n.io/integrations/jira-software/and/slack/" class="footer-link">
              Jira and Slack
            </a>
          </li>
          <li class="hidden-link">
            <a href="https://n8n.io/integrations/jira-software/and/salesforce/" class="footer-link">
              Jira and Salesforce
            </a>
          </li>
          <li class="hidden-link">
            <a href="https://n8n.io/integrations/github/and/slack/" class="footer-link"> GitHub and Slack </a>
          </li>
          <li class="hidden-link">
            <a href="https://n8n.io/integrations/hubspot/and/quickbooks-online/" class="footer-link">
              HubSpot and QuickBooks
            </a>
          </li>
          <li class="hidden-link">
            <a href="https://n8n.io/integrations/hubspot/and/slack/" class="footer-link"> HubSpot and Slack </a>
          </li>
        </ul>
        <div class="bottom-link hidden-link">
          <a href="https://n8n.io/integrations/" class="footer-link">
            Show more integrations
            <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 10 10" width="7px" height="7px">
              <g clip-path="url(#a)">
                <path
                  fill="#111010"
                  fill-rule="evenodd"
                  d="M7.678 1.36H.481V0H10v9.52H8.64v-7.2L.962 10 0 9.038 7.678 1.36Z"
                  clip-rule="evenodd"></path>
              </g>
              <defs>
                <clipPath id="a">
                  <path fill="#fff" d="M0 0h10v10H0z"></path>
                </clipPath>
              </defs></svg
            ></a>
        </div>
        <button
          type="button"
          class="footer-link footer-link--more"
          onclick="document.getElementById('subFooter').classList.toggle('sub-footer--full')"></button>
      </div>
      <div>
        <div class="column-name">Top integration categories</div>
        <ul class="col-links">
          <li>
            <a href="https://n8n.io/integrations/categories/development/" class="footer-link"> Development </a>
          </li>
          <li>
            <a href="https://n8n.io/integrations/categories/communication/" class="footer-link">
              Communication
            </a>
          </li>
          <li>
            <a href="https://n8n.io/integrations/categories/langchain/" class="footer-link"> Langchain </a>
          </li>
          <li>
            <a href="https://n8n.io/integrations/categories/ai/" class="footer-link"> AI </a>
          </li>
          <li>
            <a href="https://n8n.io/integrations/categories/data-and-storage/" class="footer-link">
              Data &amp; Storage
            </a>
          </li>
          <li>
            <a href="https://n8n.io/integrations/categories/marketing/" class="footer-link"> Marketing </a>
          </li>
          <li class="hidden-link">
            <a href="https://n8n.io/integrations/categories/productivity/" class="footer-link">
              Productivity
            </a>
          </li>
          <li class="hidden-link">
            <a href="https://n8n.io/integrations/categories/sales/" class="footer-link"> Sales </a>
          </li>
          <li class="hidden-link">
            <a href="https://n8n.io/integrations/categories/utility/" class="footer-link"> Utility </a>
          </li>
          <li class="hidden-link">
            <a href="https://n8n.io/integrations/categories/miscellaneous/" class="footer-link">
              Miscellaneous
            </a>
          </li>
        </ul>
        <div class="bottom-link hidden-link">
          <a href="https://n8n.io/integrations/" class="footer-link">
            Explore more categories
            <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 10 10" width="7px" height="7px">
              <g clip-path="url(#a)">
                <path
                  fill="#111010"
                  fill-rule="evenodd"
                  d="M7.678 1.36H.481V0H10v9.52H8.64v-7.2L.962 10 0 9.038 7.678 1.36Z"
                  clip-rule="evenodd"></path>
              </g>
              <defs>
                <clipPath id="a">
                  <path fill="#fff" d="M0 0h10v10H0z"></path>
                </clipPath>
              </defs></svg
            ></a>
        </div>
        <button
          type="button"
          class="footer-link footer-link--more"
          onclick="document.getElementById('subFooter').classList.toggle('sub-footer--full')"></button>
      </div>
      <div>
        <div class="column-name">Trending templates</div>
        <ul class="col-links">
          <li>
            <a href="https://n8n.io/workflows/1750-creating-an-api-endpoint/" class="footer-link">
              Creating an API endpoint
            </a>
          </li>
          <li>
            <a href="https://n8n.io/workflows/1954-ai-agent-chat/" class="footer-link">
              AI agent chat
            </a>
          </li>
          <li>
            <a href="https://n8n.io/workflows/1951-scrape-and-summarize-webpages-with-ai/" class="footer-link">
              Scrape and summarize webpages with AI
            </a>
          </li>
          <li>
            <a href="https://n8n.io/workflows/1700-very-quick-quickstart/" class="footer-link">
              Very quick quickstart
            </a>
          </li>
          <li>
            <a href="https://n8n.io/workflows/1748-pulling-data-from-services-that-n8n-doesnt-have-a-pre-built-integration-for/" class="footer-link">
              Pulling data from services that n8n doesn’t have a pre-built integration for
            </a>
          </li>
          <li>
            <a href="https://n8n.io/workflows/1747-joining-different-datasets/" class="footer-link">
              Joining different datasets
            </a>
          </li>
          <li class="hidden-link">
            <a href="https://n8n.io/workflows/1534-back-up-your-n8n-workflows-to-github/" class="footer-link">
              Back Up Your n8n Workflows To Github
            </a>
          </li>
          <li class="hidden-link">
            <a href="https://n8n.io/workflows/2006-ai-agent-that-can-scrape-webpages/" class="footer-link">
              AI agent that can scrape webpages
            </a>
          </li>
          <li class="hidden-link">
            <a href="https://n8n.io/workflows/1862-openai-gpt-3-company-enrichment-from-website-content/" class="footer-link">
              OpenAI GPT-3: Company Enrichment from website content
            </a>
          </li>
          <li class="hidden-link">
            <a href="https://n8n.io/workflows/1934-telegram-ai-chatbot/" class="footer-link">
              Telegram AI Chatbot
            </a>
          </li>
        </ul>
        <div class="bottom-link hidden-link">
          <a href="https://n8n.io/workflows/" class="footer-link">
            Explore 800+ workflow templates
            <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 10 10" width="7px" height="7px">
              <g clip-path="url(#a)">
                <path
                  fill="#111010"
                  fill-rule="evenodd"
                  d="M7.678 1.36H.481V0H10v9.52H8.64v-7.2L.962 10 0 9.038 7.678 1.36Z"
                  clip-rule="evenodd"></path>
              </g>
              <defs>
                <clipPath id="a">
                  <path fill="#fff" d="M0 0h10v10H0z"></path>
                </clipPath>
              </defs></svg
            ></a>
        </div>
        <button
          type="button"
          class="footer-link footer-link--more"
          onclick="document.getElementById('subFooter').classList.toggle('sub-footer--full')"></button>
      </div>
      <div>
        <div class="column-name">Top guides</div>
        <ul class="col-links">
          <li>
            <a href="../telegram-bots/index.html" class="footer-link"> Telegram bots </a>
          </li>
          <li>
            <a href="../open-source-chatbot/index.html" class="footer-link"> Open-source chatbot </a>
          </li>
          <li>
            <a href="../open-source-llm/index.html" class="footer-link"> Open-source LLM </a>
          </li>
          <li>
            <a href="../open-source-low-code-platforms.html" class="footer-link"> Open-source low-code platforms </a>
          </li>
          <li>
            <a href="../free-zapier-alternatives/index.html" class="footer-link"> Zapier alternatives </a>
          </li>
          <li>
            <a href="../make-vs-zapier/index.html" class="footer-link"> Make vs Zapier </a>
          </li>
          <li class="hidden-link">
            <a href="../ai-agents/index.html" class="footer-link"> AI agents </a>
          </li>
          <li class="hidden-link">
            <a href="../ai-coding-assistants/index.html" class="footer-link"> AI coding assistants </a>
          </li>
          <li class="hidden-link">
            <a href="../create-chatgpt-discord-bot/index.html" class="footer-link"> ChatGPT Discord bot </a>
          </li>
          <li class="hidden-link">
            <a href="../best-ai-chatbot/index.html" class="footer-link"> Best AI chatbot </a>
          </li>
        </ul>
        <div class="bottom-link hidden-link">
          <a href="../index.html" class="footer-link">
            Show guides
            <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 10 10" width="7px" height="7px">
              <g clip-path="url(#a)">
                <path
                  fill="#111010"
                  fill-rule="evenodd"
                  d="M7.678 1.36H.481V0H10v9.52H8.64v-7.2L.962 10 0 9.038 7.678 1.36Z"
                  clip-rule="evenodd"></path>
              </g>
              <defs>
                <clipPath id="a">
                  <path fill="#fff" d="M0 0h10v10H0z"></path>
                </clipPath>
              </defs></svg
            ></a>
        </div>
        <button
          type="button"
          class="footer-link footer-link--more"
          onclick="document.getElementById('subFooter').classList.toggle('sub-footer--full')"></button>
      </div>
    </div>
  </div>
</div><footer class="footer-section global-footer">
	<div class="footer-wrap">
		<div class="footer-data">
			<div class="footer-logo">
				<a href="../index.html" class="is-image"><img src="../content/images/2022/06/n8n-blog.png" alt="n8n Blog"></a>
			</div>
			<p class="footer-description">Automate without limits</p>
			<div class="footer-icons">
				<a href="https://www.facebook.com/n8nio" aria-label="link Facebook"><svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M23.9981 11.9991C23.9981 5.37216 18.626 0 11.9991 0C5.37216 0 0 5.37216 0 11.9991C0 17.9882 4.38789 22.9522 10.1242 23.8524V15.4676H7.07758V11.9991H10.1242V9.35553C10.1242 6.34826 11.9156 4.68714 14.6564 4.68714C15.9692 4.68714 17.3424 4.92149 17.3424 4.92149V7.87439H15.8294C14.3388 7.87439 13.8739 8.79933 13.8739 9.74824V11.9991H17.2018L16.6698 15.4676H13.8739V23.8524C19.6103 22.9522 23.9981 17.9882 23.9981 11.9991Z"/></svg></a>
				<a href="https://x.com/n8n_io" aria-label="link Twitter"><svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M23.954 4.569c-.885.389-1.83.654-2.825.775 1.014-.611 1.794-1.574 2.163-2.723-.951.555-2.005.959-3.127 1.184-.896-.959-2.173-1.559-3.591-1.559-2.717 0-4.92 2.203-4.92 4.917 0 .39.045.765.127 1.124C7.691 8.094 4.066 6.13 1.64 3.161c-.427.722-.666 1.561-.666 2.475 0 1.71.87 3.213 2.188 4.096-.807-.026-1.566-.248-2.228-.616v.061c0 2.385 1.693 4.374 3.946 4.827-.413.111-.849.171-1.296.171-.314 0-.615-.03-.916-.086.631 1.953 2.445 3.377 4.604 3.417-1.68 1.319-3.809 2.105-6.102 2.105-.39 0-.779-.023-1.17-.067 2.189 1.394 4.768 2.209 7.557 2.209 9.054 0 13.999-7.496 13.999-13.986 0-.209 0-.42-.015-.63.961-.689 1.8-1.56 2.46-2.548l-.047-.02z"/></svg></a>
				<a href="https://github.com/n8n-io/n8n" aria-label="link GitHub"><svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg></a>
				<a href="https://discord.gg/n8n" aria-label="link Discord"><svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20.222 0c1.406 0 2.54 1.137 2.607 2.475V24l-2.677-2.273-1.47-1.338-1.604-1.398.67 2.205H3.71c-1.402 0-2.54-1.065-2.54-2.476V2.48C1.17 1.142 2.31.003 3.715.003h16.5L20.222 0zm-6.118 5.683h-.03l-.202.2c2.073.6 3.076 1.537 3.076 1.537-1.336-.668-2.54-1.002-3.744-1.137-.87-.135-1.74-.064-2.475 0h-.2c-.47 0-1.47.2-2.81.735-.467.203-.735.336-.735.336s1.002-1.002 3.21-1.537l-.135-.135s-1.672-.064-3.477 1.27c0 0-1.805 3.144-1.805 7.02 0 0 1 1.74 3.743 1.806 0 0 .4-.533.805-1.002-1.54-.468-2.14-1.404-2.14-1.404s.134.066.335.2h.06c.03 0 .044.015.06.03v.006c.016.016.03.03.06.03.33.136.66.27.93.4.466.202 1.065.403 1.8.536.93.135 1.996.2 3.21 0 .6-.135 1.2-.267 1.8-.535.39-.2.87-.4 1.397-.737 0 0-.6.936-2.205 1.404.33.466.795 1 .795 1 2.744-.06 3.81-1.8 3.87-1.726 0-3.87-1.815-7.02-1.815-7.02-1.635-1.214-3.165-1.26-3.435-1.26l.056-.02zm.168 4.413c.703 0 1.27.6 1.27 1.335 0 .74-.57 1.34-1.27 1.34-.7 0-1.27-.6-1.27-1.334.002-.74.573-1.338 1.27-1.338zm-4.543 0c.7 0 1.266.6 1.266 1.335 0 .74-.57 1.34-1.27 1.34-.7 0-1.27-.6-1.27-1.334 0-.74.57-1.338 1.27-1.338z"/></svg></a>
				<a href="https://www.linkedin.com/company/n8n/" aria-label="link LinkedIn"><svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"/></svg></a>
				<a href="https://www.youtube.com/c/n8n-io" aria-label="link YouTube"><svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path class="a" d="M23.495 6.205a3.007 3.007 0 0 0-2.088-2.088c-1.87-.501-9.396-.501-9.396-.501s-7.507-.01-9.396.501A3.007 3.007 0 0 0 .527 6.205a31.247 31.247 0 0 0-.522 5.805 31.247 31.247 0 0 0 .522 5.783 3.007 3.007 0 0 0 2.088 2.088c1.868.502 9.396.502 9.396.502s7.506 0 9.396-.502a3.007 3.007 0 0 0 2.088-2.088 31.247 31.247 0 0 0 .5-5.783 31.247 31.247 0 0 0-.5-5.805zM9.609 15.601V8.408l6.264 3.602z"/></svg></a>
				

			</div>
		</div>
		<div class="footer-nav">
			



<div class="footer-nav-column">
	<!-- <small>Column 1</small> -->
	<ul>
		<li><a href="https://n8n.io/">n8n home</a></li>
		<li><a href="https://n8n.io/features/">Features</a></li>
		<li><a href="https://n8n.io/pricing/">Pricing</a></li>
		<li><a href="https://docs.n8n.io/">Docs</a></li>
	</ul>
</div>

<div class="footer-nav-column">
	<!-- <small>Column 2</small> -->
	<ul>
		<li><a href="https://community.n8n.io">Community</a></li>
	</ul>
</div>


		</div>
	</div>
	<div class="footer-copyright">
		Made with ❤️ in Berlin. © 2025 n8n | All rights reserved.
	</div>
</footer>
			</div>
		</div>
		<div id="notifications" class="global-notification">
	<div class="subscribe">You’ve successfully subscribed to n8n Blog</div>
	<div class="signin">Welcome back! You’ve successfully signed in.</div>
	<div class="signup">Great! You’ve successfully signed up.</div>
	<div class="expired">Your link has expired</div>
	<div class="checkout-success">Success! Check your email for magic link to sign-in.</div>
</div>
				<script src="../assets/js/global.js%3Fv=4801f6d1f9"></script>
		<script src="../assets/js/post.js%3Fv=4801f6d1f9"></script>
		
		<script>
!function(){"use strict";const p=new URLSearchParams(window.location.search),isAction=p.has("action"),isStripe=p.has("stripe"),success=p.get("success"),action=p.get("action"),stripe=p.get("stripe"),n=document.getElementById("notifications"),a="is-subscribe",b="is-signin",c="is-signup",d="is-expired",e="is-checkout-success";p&&(isAction&&(action=="subscribe"&&success=="true"&&n.classList.add(a),action=="signin"&&success=="true"&&n.classList.add(b),action=="signup"&&success=="true"&&n.classList.add(c),success=="false"&&n.classList.add(d)),isStripe&&stripe=="success"&&n.classList.add(e),(isAction||isStripe)&&setTimeout(function(){window.history.replaceState(null,null,window.location.pathname),n.classList.remove(a,b,c,d,e)},5000))}();
</script>

		
		<script>

// Contain every link in an array.
var links = document.querySelectorAll('a');

// For every link,
for (var i = 0; i < links.length; i++) {

  // if the link's hostname is different from this Ghost's hostname,
  // i.e. if the link is external,
  if (links[i].hostname != window.location.hostname) {

    // change the target and rel value as the following.
    links[i].target = '_blank';
    links[i].rel = 'noopener';

  }
}
</script>
	</body>
</html>
