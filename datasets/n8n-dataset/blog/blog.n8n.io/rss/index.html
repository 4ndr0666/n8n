<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:media="http://search.yahoo.com/mrss/"><channel><title><![CDATA[n8n Blog]]></title><description><![CDATA[Automate without limits]]></description><link>https://blog.n8n.io/</link><image><url>https://blog.n8n.io/favicon.png</url><title>n8n Blog</title><link>https://blog.n8n.io/</link></image><generator>Ghost 5.119</generator><lastBuildDate>Tue, 06 May 2025 03:40:11 GMT</lastBuildDate><atom:link href="https://blog.n8n.io/rss/" rel="self" type="application/rss+xml"/><ttl>60</ttl><item><title><![CDATA[How To Build Your First AI Agent (+Free Workflow Template)]]></title><description><![CDATA[Step-by-step guide to building AI agents with three practical approachesâ€”coding from scratch for full control, leveraging powerful frameworks like LangChain or LlamaIndex for faster development, or using no-code tools like n8n for rapid prototyping and automation.]]></description><link>https://blog.n8n.io/how-to-build-ai-agent/</link><guid isPermaLink="false">67f7f8dd089957000133b16e</guid><category><![CDATA[AI]]></category><category><![CDATA[Tutorial]]></category><dc:creator><![CDATA[Mihai Farcas]]></dc:creator><pubDate>Thu, 24 Apr 2025 16:45:20 GMT</pubDate><media:content url="https://blog.n8n.io/content/images/2025/04/ai-2--1-.png" medium="image"/><content:encoded><![CDATA[<img src="https://blog.n8n.io/content/images/2025/04/ai-2--1-.png" alt="How To Build Your First AI Agent (+Free Workflow Template)"><p>Imagine building an assistant that can research topics online, summarize the findings, and save them directly to your Notion &#x2013; automatically. That&#x2019;s the kind of intelligent automation <a href="https://blog.n8n.io/ai-agents/" rel="noreferrer">AI agents</a> make possible.</p><p>But here&#x2019;s the real challenge: getting an AI to reliably act in the real world&#x2014;interacting with APIs, scraping websites, updating databases. How do you bridge the gap between the AI&#x2019;s reasoning and the tools it needs to execute real tasks?</p><p>In this guide, we&#x2019;ll discuss three solid ways to build AI agents:</p><ul><li>From scratch (if you&apos;re feeling hardcore),</li><li>With frameworks like LangChain and CrewAI (if you want flexibility without reinventing the wheel),</li><li>Or with n8n (if you like visual workflows and want to build fast, production-ready AI agents).</li></ul><p>We&#x2019;ll keep it hands-on, and by the end, you&#x2019;ll have a working AI agent that actually does stuff &#x2014; not just thinks about it.</p><h2 id="understanding-the-basics-of-building-ai-agents">Understanding the basics of building AI Agents</h2><p>Before diving into building, let&apos;s break down how an AI agent works.</p><p>At its core, an AI agent acts as a system that acts on behalf of a user (or program) to achieve a specific result by perceiving its environment, making decisions, and taking actions. While they can range from simple chatbots to complex autonomous systems, most AI agents share a few fundamental components:</p><h3 id="perception">Perception</h3><p>It&apos;s the ability to gather information from its environment. This environment could be a chat interface, a database, a webpage, or even physical sensors. Inputs might include:</p><ul><li>Text commands from a user (i.e. a message or prompt).</li><li>Events triggered by other systems, such as webhooks or messages.</li><li>Information retrieved from websites or APIs.</li><li>Content from documents or databases.</li></ul><h3 id="decision-making">Decision-making</h3><p>This is the agent&apos;s &quot;brain.&quot; Based on its perception (the information gathered) and its programmed goals, the agent decides what to do next. This core logic can involve:</p><ul><li>Large Language Models (LLMs)<strong>:</strong> Modern agents often leverage LLMs (like GPT, Gemini, Claude etc.) as their primary reasoning engine to understand requests, formulate plans, and generate responses.</li><li>Rule-Based Systems<strong>:</strong> Simple instructions like &quot;if the customer asks for a refund, execute the refund workflow.&quot;</li><li>Machine Learning Models<strong>:</strong> Algorithms trained to predict outcomes or classify information to guide decisions.</li></ul><p>Planning<strong>:</strong> Breaking down a complex goal (e.g., &quot;plan a trip to Rome&quot;) into smaller, manageable steps (search flights, find hotels, check visa requirements).</p><h3 id="action">Action</h3><p>Once a decision is made, the agent needs to act upon it. This involves interacting with its environment to execute the chosen steps. Actions can be diverse, such as:</p><ul><li>Sending a message back to the user.</li><li>Calling an API (like searching the web or posting to to a Discord channel).</li><li>Running a workflow (like an n8n workflow!).</li><li>Updating information in a database.</li><li>Controlling a physical device. Actions are how the agent influences its environment to move closer to its goal. The ability to use various AI agent tools (like APIs or workflows) is central to an agent&apos;s effectiveness.</li></ul><p>When an agent uses an LLM for decision-making, the LLM needs a structured way to understand which actions it can take and how to execute them. This is often achieved through defining <strong>Tools </strong>or enabling <strong>Function Calling</strong>. These mechanisms allow the LLM to signal its intent to use a specific capability (like calling an external API or running an n8n workflow) and provide the necessary parameters.</p><h3 id="memory">Memory</h3><p>Agents often need to remember past interactions or learned information to provide context for future decisions. Memory allows an agent to:</p><ul><li>Recall previous parts of a conversation to maintain context.</li><li>Store user preferences (e.g., &quot;always use metric units&quot;).</li><li>Access external knowledge bases (like documents or databases) to answer questions accurately (often using techniques like Retrieval-Augmented Generation or RAG).</li><li>Learn from past experiences to improve future performance.</li></ul><p>These components work together in a continuous loop: the agent perceives its environment, decides on an action based on its goals and memory, and then performs that action, potentially changing the environment and starting the cycle again.</p><p>Understanding these basic building blocks is the first step. Next, let&apos;s look at the different ways you can actually build AI agents.</p><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text">Interested in seeing AI agents in action? This article provides <a href="https://blog.n8n.io/ai-agents-examples/" rel="noreferrer">15 real-world examples of how AI agents</a>, particularly those built with n8n, are automating tasks like data analysis, customer support, and more!</div></div><h2 id="how-to-create-ai-agents-3-practical-approaches">How to create AI agents: 3 practical approaches</h2><p>So, how do we actually go about building an AI agent? There are several ways to approach this, each with its own set of trade-offs in terms of flexibility, complexity, and development speed.</p><p>Let&apos;s look at three common methods:</p><h3 id="building-ai-agents-from-scratch">Building AI agents from scratch</h3><p>Learning how to build an AI agent from scratch involves coding all the components using programming languages like Python and potentially leveraging specific AI/ML libraries.</p><p>This approach offers maximum flexibility and control over every aspect of the agent&apos;s behavior.&#xA0;</p><p>However, it requires significant technical expertise in areas like software engineering, API integration, and potentially machine learning. It also demands considerable development time and effort to build, test, and maintain the entire system.</p><p>This path often answers the question &apos;how much does it cost to build an AI agent?&apos; with &apos;significantly&apos;, due to the required development time and expertise. It is often chosen for highly specialized or research-oriented projects where existing tools don&apos;t meet specific requirements.</p><h3 id="using-existing-frameworks-for-building-ai-agents">Using existing frameworks for building AI agents</h3><p>Several frameworks (like LangChain, LlamaIndex, Semantic Kernel, or Autogen) provide pre-built components and abstractions designed for creating AI agents. These frameworks offer building blocks for managing prompts, connecting to LLMs, handling memory, defining tools (actions), and orchestrating agent steps. They significantly accelerate development compared to building from scratch by handling much of the underlying complexity.</p><p>However, they still require coding proficiency and a good understanding of the chosen framework&apos;s architecture and concepts.</p><p>This approach strikes a balance between flexibility and development speed, suitable for teams wanting structured development with some customization.</p><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text">We&#x2019;ve rounded up <a href="https://blog.n8n.io/ai-agent-frameworks/" rel="noreferrer">9 popular AI agent frameworks</a>&#x2014;from drag-and-drop simplicity to fully code-driven setups. Each one offers a different level of control, complexity, and customization.</div></div><h3 id="using-workflow-automation-tools">Using workflow automation tools</h3><p><a href="https://n8n.io/ai/?ref=blog.n8n.io"><u>Platforms like n8n</u></a> provide a visual, node-based environment for building agents. You connect services like LLMs, APIs, and databases as nodes, defining the agent&apos;s logic and actions by arranging and configuring these nodes in a workflow.</p><p>This approach significantly lowers the barrier to entry and speeds up development and prototyping, shifting the focus from complex coding to workflow design and tool integration.</p><p>It&apos;s particularly well-suited for automating tasks, rapidly building agent prototypes, and integrating AI capabilities into broader business processes.</p><h2 id="how-to-build-an-ai-agent-with-n8n-step-by-step-tutorial">How to build an AI agent with n8n: Step-by-step tutorial</h2><p>n8n stands out as a choice for building AI agents because it uniquely balances implementation flexibility with speed of delivery. Although primarily a workflow automation tool, it allows for the creation of agents that can call multiple pre-built or custom tools, integrate RAG capabilities for knowledge retrieval and hook up to various chat interfaces via its flexible API and SDK options.</p><p>We&#x2019;re going to build a practical research agent that scrapes the web and saves the summary for us&#x2014;automatically!</p><p>Since AI agents&apos; main functionality is the use of <a href="https://docs.n8n.io/advanced-ai/examples/understand-tools/?ref=blog.n8n.io" rel="noreferrer">tools</a> such as <a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.toolhttprequest/?ref=blog.n8n.io" rel="noreferrer">HTTP requests</a> and the Notion tool &#x2013; this example leverages advanced LLMs like the recently released Gemini 2.5 Pro, whose reliable tool calling and enormous context window make such tasks feasible!</p><p>Here is an image of what we will build using n8n:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://blog.n8n.io/content/images/2025/04/Screenshot-2025-04-13-110742.png" class="kg-image" alt="How To Build Your First AI Agent (+Free Workflow Template)" loading="lazy" width="1392" height="714" srcset="https://blog.n8n.io/content/images/size/w600/2025/04/Screenshot-2025-04-13-110742.png 600w, https://blog.n8n.io/content/images/size/w1000/2025/04/Screenshot-2025-04-13-110742.png 1000w, https://blog.n8n.io/content/images/2025/04/Screenshot-2025-04-13-110742.png 1392w" sizes="(min-width: 720px) 720px"><figcaption><span style="white-space: pre-wrap;">n8n research agent workflow</span></figcaption></figure>
<!--kg-card-begin: html-->
<script>
  workflowBanner(3535, document.currentScript);
</script>
<!--kg-card-end: html-->
<p>Let&apos;s break this down!</p><h3 id="prerequisites">Prerequisites</h3><p>Before we start building the workflow, ensure you have the following set up:</p><ul><li><strong>n8n instance:</strong> You need n8n running. This can be a <a href="https://docs.n8n.io/hosting/?ref=blog.n8n.io"><u>self-hosted instance </u></a>(e.g., using Docker) or an account on <a href="https://app.n8n.cloud/register?ref=blog.n8n.io"><u>n8n Cloud</u></a>.</li><li><strong>Browserless:</strong> Access to a <a href="https://www.browserless.io/?ref=blog.n8n.io"><u>Browserless</u></a> instance is required for web scraping. You can use their cloud service or self-host your own instance (e.g., using Docker).</li><li><strong>Google AI API Key:</strong> Obtain an API key from <a href="https://aistudio.google.com/?ref=blog.n8n.io"><u>Google AI Studio</u></a> to use the Gemini model.</li><li><strong>Discord</strong>: Configure a <a href="https://docs.n8n.io/integrations/builtin/credentials/discord/?ref=blog.n8n.io"><u>Discord webhook or bot account</u></a> to send notification when research is done.</li></ul><h3 id="step-1-set-up-the-trigger">Step 1: Set up the trigger</h3><p>Every n8n workflow starts with a trigger node. This node initiates the workflow when a specific event occurs. For our AI Research Agent, we want it to activate when we send it a message containing a URL, typically via a chat interface.</p><p>In the n8n canvas, click the &apos;+&apos; button to add your first node. Choose a trigger relevant to how you want to interact with your agent. In this case we can use the <a href="https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-langchain.chattrigger?ref=blog.n8n.io" rel="noreferrer">Chat trigger</a>. Other common triggers for such a use case would be the <a href="https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.webhook?ref=blog.n8n.io" rel="noreferrer">Webhook trigger</a>, which creates a unique URL to which you can send HTTP requests from a custom application or another service, or the <a href="https://docs.n8n.io/integrations/builtin/trigger-nodes/n8n-nodes-base.slacktrigger?ref=blog.n8n.io" rel="noreferrer">Slack trigger</a> which listens for messages or commands in Slack.</p><h3 id="step-2-configure-the-agents-core">Step 2: Configure the Agent&apos;s core</h3><p>The heart of our workflow is the <a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.agent?ref=blog.n8n.io" rel="noreferrer">AI Agent node</a>. This node acts as the central orchestrator, connecting the trigger, the Large Language Model (LLM), and the tools the agent can use. </p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://blog.n8n.io/content/images/2025/04/Screenshot-2025-04-14-073414.png" class="kg-image" alt="How To Build Your First AI Agent (+Free Workflow Template)" loading="lazy" width="1002" height="1066" srcset="https://blog.n8n.io/content/images/size/w600/2025/04/Screenshot-2025-04-14-073414.png 600w, https://blog.n8n.io/content/images/size/w1000/2025/04/Screenshot-2025-04-14-073414.png 1000w, https://blog.n8n.io/content/images/2025/04/Screenshot-2025-04-14-073414.png 1002w" sizes="(min-width: 720px) 720px"><figcaption><span style="white-space: pre-wrap;">AI Agent node configuration</span></figcaption></figure><p>First, add an AI Agent node to the canvas and connect the output of your trigger node to the input of the AI Agent node. </p><p>In the AI Agent node settings (see image), ensure the <strong>Agent</strong> dropdown is set to <em>Tools Agent</em>. This type is designed for agents that need to utilize specific tools to accomplish tasks. Set the <strong>Source for Prompt (User Message)</strong> to <em>Connected Chat Trigger Node</em>. This tells the agent to use the input from your trigger (e.g., the chat message containing the URL) as the user&apos;s request. The specific input field might vary depending on your trigger node&apos;s output.</p><h3 id="step-3-define-the-agents-goal-and-instructions">Step 3: Define the Agent&apos;s goal and instructions</h3><p>This is where you tell the AI what you want it to do and how it should use its tools. Clear instructions are crucial for reliable agent performance.</p><p>Add a <a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatgooglegemini?ref=blog.n8n.io" rel="noreferrer">Google Gemini Chat Model node</a> (or your preferred LLM node like OpenAI Chat Model, Anthropic Chat Model, etc.) and configure it with your credentials (your Google AI API Key).</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://blog.n8n.io/content/images/2025/04/Screenshot-2025-04-14-073558.png" class="kg-image" alt="How To Build Your First AI Agent (+Free Workflow Template)" loading="lazy" width="1013" height="537" srcset="https://blog.n8n.io/content/images/size/w600/2025/04/Screenshot-2025-04-14-073558.png 600w, https://blog.n8n.io/content/images/size/w1000/2025/04/Screenshot-2025-04-14-073558.png 1000w, https://blog.n8n.io/content/images/2025/04/Screenshot-2025-04-14-073558.png 1013w" sizes="(min-width: 720px) 720px"><figcaption><span style="white-space: pre-wrap;">Google Gemini LLM configuration</span></figcaption></figure><p>Select the desired Model (e.g., gemini-2.5-pro) and connect this LLM node to the Chat Model input of the AI Agent node. </p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://blog.n8n.io/content/images/2025/04/Screenshot-2025-04-14-073510.png" class="kg-image" alt="How To Build Your First AI Agent (+Free Workflow Template)" loading="lazy" width="1086" height="1039" srcset="https://blog.n8n.io/content/images/size/w600/2025/04/Screenshot-2025-04-14-073510.png 600w, https://blog.n8n.io/content/images/size/w1000/2025/04/Screenshot-2025-04-14-073510.png 1000w, https://blog.n8n.io/content/images/2025/04/Screenshot-2025-04-14-073510.png 1086w" sizes="(min-width: 720px) 720px"><figcaption><span style="white-space: pre-wrap;">Configure the system prompt</span></figcaption></figure><p>In the AI Agent node parameters, there is a field called <strong>System Message </strong>within the <strong>Options </strong>section. This is where you provide the core instructions for the agent. Here you can define the agent&apos;s instructions. For best results, the system message should:</p><ol><li>Clearly state the agent&apos;s task.</li><li>Explicitly instruct the agent on when and how to use each tool.</li><li>Add any important constraints such as &quot;Remember you always have to scrape the website using the website_scraper tool.&quot;, &quot;Don&apos;t try to summarize without scraping!&quot; etc. </li></ol><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text">Read more about using <a href="https://docs.n8n.io/advanced-ai/examples/understand-tools?ref=blog.n8n.io" rel="noreferrer">AI Tools in n8n</a>.</div></div><h3 id="step-4-add-the-web-scraping-tool">Step 4: Add the web scraping tool</h3><p>Now we configure the actual tools the agent can use. First, the web scraper uses Browserless. Since there isn&apos;t a dedicated Browserless node, we use the versatile <a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.toolhttprequest?ref=blog.n8n.io" rel="noreferrer">HTTP Request Tool node</a>.</p><p>Add an HTTP Request Tool node to the canvas and rename it to <em>website_scraper </em>(or similar). This name must match the tool name used in the AI Agent&apos;s system message.</p><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text">Choose a clear name and description for the tool; this significantly improves the chances the LLM will use it correctly.</div></div><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://blog.n8n.io/content/images/2025/04/Screenshot-2025-04-14-073738.png" class="kg-image" alt="How To Build Your First AI Agent (+Free Workflow Template)" loading="lazy" width="1057" height="1760" srcset="https://blog.n8n.io/content/images/size/w600/2025/04/Screenshot-2025-04-14-073738.png 600w, https://blog.n8n.io/content/images/size/w1000/2025/04/Screenshot-2025-04-14-073738.png 1000w, https://blog.n8n.io/content/images/2025/04/Screenshot-2025-04-14-073738.png 1057w" sizes="(min-width: 720px) 720px"><figcaption><span style="white-space: pre-wrap;">Configuring Browserless web scraping tool using the HTTP Tool node</span></figcaption></figure><p>Configure the node like in the image above:</p><ul><li><strong>Method</strong>: <em>POST</em></li><li><strong>URL</strong>: Enter your Browserless API endpoint for scraping content.</li><li><strong>Authentication</strong>: Configure if required by your Browserless setup.</li><li><strong>Body</strong>: <em>Using JSON Below</em></li><li><strong>JSON</strong>: Provide the JSON payload Browserless expects. Use a placeholder for the URL the agent will provide:</li></ul><pre><code class="language-json">{
  &quot;url&quot;: &quot;{url}&quot;,
  &quot;gotoOptions&quot;: {
    &quot;waitUntil&quot;: &quot;networkidle0&quot;
  }
}
</code></pre>
<ul><li><strong>Placeholder Definitions</strong>: Define the placeholders used in the JSON body.<ul><li>Click <strong>Add Definition</strong>.</li><li><strong>Placeholder Name</strong>: <em>url </em>(must match the placeholder name in the JSON body and the parameter name expected by the AI Agent).</li><li><strong>Description</strong>: Provide a clear description for the AI (e.g., &quot;the URL of the website to scrape&quot;).</li><li><strong>Type</strong>: <em>String</em>.</li></ul></li></ul><p>Finally, connect the HTTP Request Tool node (website_scraper) to the Tool input of the AI Agent node.</p><h3 id="step-5-define-the-save-to-notion-tool">Step 5: Define the save to Notion tool</h3><p>Next, configure the tool to save the scraped and summarized information to your Notion database. </p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXe9H14j_BfFa_D0lUjx_eMSwbj6N_wAYNgMeNmuLxPxCqJe2DYHWaCPB_GsqYjpXEeyc4HNYqvN1UFSXCzaaKH87RCQEnZIynJLIPpO41Ch7r0Vu47MUPwFo4u3kOUc-7BXGgITQw?key=_r48LiEg_FwI2Mdj77UgjnLb" class="kg-image" alt="How To Build Your First AI Agent (+Free Workflow Template)" loading="lazy" width="994" height="967"><figcaption><span style="white-space: pre-wrap;">Configuring the Notion Tool node</span></figcaption></figure><p>Add a <a href="https://docs.n8n.io/integrations/builtin/app-nodes/n8n-nodes-base.notion?ref=blog.n8n.io" rel="noreferrer">Notion Tool node</a> to the canvas and rename it to <em>save_to_notion</em>, again, matching the tool name from the system message. Then, Set the <strong>Tool Description</strong> to <em>Manually</em> and provide a description (e.g., &quot;save_to_notion: This tool saves the information to the Notion database.&quot;). </p><p>For authenticating to Notion, Select your configured Notion API credentials. <strong>Resource </strong>should be set to<strong> </strong><em>Database Page </em>and <strong>Operation </strong>to <em>Create.</em></p><p>Select your target Notion database (e.g., &quot;Knowledge Database&quot;). Ensure the n8n integration has access to this database and that it contains the necessary properties (Name, URL, Description, Tags, etc., as defined in your setup). The <strong>Properties</strong> section is where you map the data generated by the AI Agent (based on the parameters defined in Step 3) to your Notion database fields. For each property (e.g., &quot;Title&quot;, &quot;Description&quot;, &quot;URL&quot;, &quot;Tags&quot;, &quot;Publication Date&quot;, &quot;Icon&quot;), use the <code>{{ $fromAI(&apos;parameterName&apos;, &apos;Description&apos;, &apos;type&apos;) }}</code> expression. Replace <code>parameterName</code> with the exact parameter name you defined in the AI Agent&apos;s system message. Example for &quot;Title&quot;: <code>{{ $fromAI(&apos;title&apos;, &apos;The original title of the article&apos;, &apos;string&apos;) }}</code>.</p><p>Here is how this specific Notion database is structured:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://blog.n8n.io/content/images/2025/04/Screenshot-2025-04-13-112907.png" class="kg-image" alt="How To Build Your First AI Agent (+Free Workflow Template)" loading="lazy" width="1725" height="745" srcset="https://blog.n8n.io/content/images/size/w600/2025/04/Screenshot-2025-04-13-112907.png 600w, https://blog.n8n.io/content/images/size/w1000/2025/04/Screenshot-2025-04-13-112907.png 1000w, https://blog.n8n.io/content/images/size/w1600/2025/04/Screenshot-2025-04-13-112907.png 1600w, https://blog.n8n.io/content/images/2025/04/Screenshot-2025-04-13-112907.png 1725w" sizes="(min-width: 720px) 720px"><figcaption><span style="white-space: pre-wrap;">Notion database structure</span></figcaption></figure><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXdVSPzYBYhR3l0Nt4Lg0ZSqu68_bZMT0MKPUimU4YCJaxarNBiJU6Y3m5VfwdmcgxL_Lt9O4R3_sFeY8R_rojLuh-jgVh6pWee7_6NDDV98PtHiIuSpVOJXNbhV61cjF6YHnXuqiw?key=_r48LiEg_FwI2Mdj77UgjnLb" class="kg-image" alt="How To Build Your First AI Agent (+Free Workflow Template)" loading="lazy" width="986" height="1819"><figcaption><span style="white-space: pre-wrap;">Configure the AI generated fields for the Notion database page</span></figcaption></figure><p>As a useful visual touch, let&apos;s prompt the AI agent to select a fitting emoji for each page:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXcpfOi1CAmt9nBB9De-lYPxd8nQqhtHInlSSyqkh7N09WI9NMgAn_fvfTIihkhVZL4HUJigx-KabBqPvN_wdE31StccMv8cUx7u8Vw0qr9nzY9W6cIuF5kOdjWTNq2JxXdGUQVMVQ?key=_r48LiEg_FwI2Mdj77UgjnLb" class="kg-image" alt="How To Build Your First AI Agent (+Free Workflow Template)" loading="lazy" width="959" height="296"><figcaption><span style="white-space: pre-wrap;">Use AI to choose an emoji icon for the article</span></figcaption></figure><h3 id="step-6-define-the-discord-notification-tool">Step 6: Define the Discord notification tool</h3><p>To ensure the AI agent can report its task completion, we&apos;ll equip it with a tool for sending Discord messages. This allows the agent itself to decide when and how to notify you based on its instructions and the outcome of its tasks.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXctWtKCNcgS1ook5UyfPtdyutq6Ot0eYPXzSbZEsthKfLMBcg3T-w7q0NiH7o0UZ3RoD2tbm_OfzVR1ZlIcAo_xMlLm6L_NOkN98Ph9wfia0PRueTvF1VtL9fkBn94wVGageiDQyA?key=_r48LiEg_FwI2Mdj77UgjnLb" class="kg-image" alt="How To Build Your First AI Agent (+Free Workflow Template)" loading="lazy" width="998" height="1898"><figcaption><span style="white-space: pre-wrap;">Configuring the AI Agent Discord notifications</span></figcaption></figure><p>Add a Discord Tool node, name it &quot;discord_notification&quot; and select your Discord Webhook or Bot credentials. Select <em>Send a Message i</em>n the <strong>Operation </strong>dropdown. Here we will prompt the AI agent to craft the notification message, for example: <code>{{ $fromAI(&apos;Message&apos;, &apos;Confirmation that research was done along with the URL to the notion page where the research is now available.&apos;, &apos;string&apos;) }}</code>. And optionally in the <strong>Embeds </strong>field, we can embed a link for a richer notification by including the title and URL to the newly created Notion page.</p><h3 id="step-7-test-and-refine-your-ai-agent">Step 7: Test and refine your AI agent</h3><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text">Building AI agents is an iterative process. Testing thoroughly and refining your instructions are key to achieving reliable performance. </div></div><p>Make sure to save the workflow and send a chat message containing a URL you want researched. Observe the workflow execution in the n8n UI checking the input/output of each node, especially the AI Agent node, to see how it processes the request and which tools it decides to call. </p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXcMW8OlbPbsjSP7-qqoKYkkA1KVXj055_SBtgykGkv8ORFkQyMjn0ouhNtWeT-qsyk2VDxXUrNHc6aRWIuPPPUhGpc59z948644G1R1cRWiFzQHetg10ZJJD_3wtNn9g4DYwLa4?key=_r48LiEg_FwI2Mdj77UgjnLb" class="kg-image" alt="How To Build Your First AI Agent (+Free Workflow Template)" loading="lazy" width="2048" height="1458"><figcaption><span style="white-space: pre-wrap;">Testing the AI agent using the n8n UI</span></figcaption></figure><p>Verify that the website was scraped correctly, check that a new page was created in your Notion database with the expected content and summary and that you received a notification in Discord.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfZDffL9hgewmCfRKRlWLzh7vpTJvf9AFVFDYd0rhmdRtpY_Oh_eCA4zpNfkflCJq-tnlPwy1nTskQhHDKFQuDkDqR1Ftg2beXOFzJHxg9UGDH4p3EkVxOXPzwi2On163Y2fCr8hg?key=_r48LiEg_FwI2Mdj77UgjnLb" class="kg-image" alt="How To Build Your First AI Agent (+Free Workflow Template)" loading="lazy" width="1823" height="1243"><figcaption><span style="white-space: pre-wrap;">Discord notification sent by the AI agent</span></figcaption></figure><p>If the agent doesn&apos;t perform as expected, check each node and tool output, looking for reasoning or any errors in tool calling. Modify the instructions in the <strong>System Message</strong>, make the instructions clearer, add constraints, or refine the parameter definitions. Then save, and test again until the AI Research Agent reliably performs the desired scrape, summarize, save, and notify tasks.</p><h2 id="wrap-up">Wrap up</h2><p>In this article, we looked at the core components of AI agents (like how they perceive, decide, act, and remember) and the main ways to architect them: coding from scratch, using frameworks, or using visual tools like n8n.</p><p>Our research agent example showed how n8n makes it straightforward to create powerful agents. By connecting LLMs with different tools visually, you can build systems that act intelligently for you. Good tool integration is vital for agents, and n8n makes this easy.</p>
<!--kg-card-begin: html-->
<div class="content-banner">
  <div>
    <h3>Create your first AI agent</h3>
    <p>Use the power of n8n&apos;s flexibility to customize every step</p>
  </div>
  <a href="https://app.n8n.cloud/register?ref=blog.n8n.io" class="global-button blog-banner-signup">Try n8n now</a>
</div>
<!--kg-card-end: html-->
<p>AI agents are changing quickly, offering new ways to automate tasks and personalize experiences. We hope this guide clarified the basics and encourages you to try building your own agents with n8n.</p><h2 id="what%E2%80%99s-next">What&#x2019;s next?</h2><p>Now that you have a solid understanding of AI agents and how to start building them with n8n, you can experiment with different LLMs, try building agents for new use cases, and connect with the n8n community to share your creations and learn from others!</p><p>You can also dive deeper and explore more resources from the community:</p><ul><li>Check out this Reddit thread for insights on what <a href="https://www.reddit.com/r/AI_Agents/comments/1il8b1i/my_guide_on_what_tools_to_use_to_build_ai_agents/?ref=blog.n8n.io"><u>tools to use for building AI agents</u></a>.</li><li>See how others are building with n8n in this <a href="https://www.youtube.com/watch?v=XVO3zsHdvio&amp;ref=blog.n8n.io"><u>YouTube video</u></a>.</li><li>Read more on the n8n blog:<ul><li>Learn about building <a href="https://blog.n8n.io/ai-agentic-workflows/"><u>AI agentic workflows</u></a>.</li><li>Discover more on <a href="https://blog.n8n.io/ai-workflow-automation/"><u>AI workflow automation</u></a>.</li></ul></li><li>Get inspired or find a starting point by browsing <a href="https://n8n.io/workflows/categories/ai/?ref=blog.n8n.io"><u>AI workflows shared by the n8n community</u></a>.</li></ul><p>Happy automating!</p>]]></content:encoded></item><item><title><![CDATA[9 AI Agent Frameworks Battle: Why Developers Prefer n8n]]></title><description><![CDATA[From no-code builders to programming-first solutions, find your ideal AI agent framework. See why n8n's hybrid approach offers the perfect balance for real-world applications!]]></description><link>https://blog.n8n.io/ai-agent-frameworks/</link><guid isPermaLink="false">67f8cd4f089957000133b1b3</guid><category><![CDATA[AI]]></category><category><![CDATA[Guide]]></category><dc:creator><![CDATA[Yulia Dmitrievna]]></dc:creator><pubDate>Thu, 24 Apr 2025 09:47:55 GMT</pubDate><media:content url="https://blog.n8n.io/content/images/2025/04/ai-agent-frameworks5.jpg" medium="image"/><content:encoded><![CDATA[<img src="https://blog.n8n.io/content/images/2025/04/ai-agent-frameworks5.jpg" alt="9 AI Agent Frameworks Battle: Why Developers Prefer n8n"><p>AI agents sound exciting &#x2013; autonomous systems that can reason through complex tasks, coordinate with other agents, and achieve magical results with minimal supervision.</p><p>But if you&#x2019;ve actually tried to build an AI agent, you know that the reality is much messier: many AI agent frameworks promise to simplify agent development but <a href="https://www.youtube.com/watch?v=jLVl5V8roMU&amp;ref=blog.n8n.io"><u>end up adding layers of complexity</u></a> through abstractions and unpredictable behavior. When your agent suddenly starts hallucinating or loses track of crucial context after you&#x2019;ve spent days configuring it, that slick YouTube demo feels like a distant dream.</p><p>In this article, we&apos;ll look at 9 AI agent frameworks with three levels of complexity&#xA0; that really work.</p><p>We&#x2019;ll show how <a href="https://n8n.io/ai/?ref=blog.n8n.io"><u>n8n</u></a> strikes the balance many developers are looking for &#x2013; providing ready-made components for AI agents&apos; rapid development while preserving the flexibility to customize or simplify your agent as needed.</p><h3 id="table-of-contents">Table of contents</h3>
<ul>
<li><a href="#9-best-ai-agent-frameworks-comparison">9 best AI agent frameworks comparison</a></li>
<li><a href="#visual-no-code-frameworks">Visual no-code frameworks</a>
<ul>
<li><a href="#flowise">Flowise</a></li>
<li><a href="#botpress">Botpress</a></li>
<li><a href="#langflow">Langflow</a></li>
</ul>
</li>
<li><a href="#intermediate-low-code-complexity-frameworks">Intermediate low-code complexity frameworks</a>
<ul>
<li><a href="#n8n">n8n</a></li>
<li><a href="#crewai">CrewAI</a></li>
<li><a href="#rivet">Rivet</a></li>
</ul>
</li>
<li><a href="#programming-first-frameworks">Programming-first frameworks</a>
<ul>
<li><a href="#autogen">AutoGen</a></li>
<li><a href="#langgraph">LangGraph</a></li>
<li><a href="#smolagents">SmolAgents</a></li>
</ul>
</li>
<li><a href="#why-use-n8n-to-build-ai-agents">Why use n8n to build AI agents?</a>
<ul>
<li><a href="#agentic-workflows-not-just-agents">Agentic workflows, not just agents</a></li>
</ul>
</li>
</ul>
<h2 id="9-best-ai-agent-frameworks-comparison">9 best AI agent frameworks comparison</h2><p>We&apos;ve prepared a list of 9 popular AI agent frameworks, focusing on solutions that offer flexibility in deployment.</p><p>The frameworks we selected represent a diverse range of approaches to building AI agents, from visual workflow designers to code-centric solutions. This variety allows developers to choose a framework that best fits their skill level, project requirements, and desired level of customization. These frameworks are arranged by complexity level, from beginner-friendly to more advanced options. </p><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text">If you&#x2019;re new to creating AI agents, check out our in-depth <a href="https://blog.n8n.io/ai-agents/"><u>tutorial where we cover the fundamentals and show how to build AI agents with n8n</u></a>.</div></div><table>
<thead>
<tr>
<th><strong>Framework</strong></th>
<th><strong>Primary Strength</strong></th>
<th><strong>Best For</strong></th>
<th><strong>Language</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#flowise">Flowise</a></td>
<td>Visual workflow building<br>with drag-and-drop interface</td>
<td>Quick prototyping<br>without coding skills</td>
<td>JavaScript</td>
</tr>
<tr>
<td><a href="#botpress">Botpress</a></td>
<td>Visual workflow design<br>with extensive AI integrations</td>
<td>Customer service<br>automation and chatbots</td>
<td>JavaScript</td>
</tr>
<tr>
<td><a href="#langflow">Langflow</a></td>
<td>Visual IDE on top of LangChain<br>with pre-built templates</td>
<td>Visual LangChain prototyping<br>and workflow design</td>
<td>Python</td>
</tr>
<tr>
<td><a href="#n8n">n8n</a></td>
<td>Visual AI agent orchestration<br>with extensible architecture<br>for custom LLM integrations<br>and agent workflows</td>
<td>Building production-ready<br>AI agents with the flexibility to scale<br>from simple automations to complex<br>multi-agent systems</td>
<td>JavaScript/<br>TypeScript</td>
</tr>
<tr>
<td><a href="#crewai">CrewAI</a></td>
<td>Role-based collaboration<br>with specialized agent teams</td>
<td>Complex workflows requiring<br>role-specific expertise</td>
<td>Python</td>
</tr>
<tr>
<td><a href="#rivet">Rivet</a></td>
<td>Visual scripting for AI agents<br>with debugging capabilities</td>
<td>Rapid prototyping with<br>visual logic design</td>
<td>TypeScript</td>
</tr>
<tr>
<td><a href="#autogen">AutoGen</a></td>
<td>Advanced multi-agent<br>orchestration with<br>agent-to-agent communication</td>
<td>Complex problem-solving requiring<br>autonomous collaboration</td>
<td>Python</td>
</tr>
<tr>
<td><a href="#langgraph">LangGraph</a></td>
<td>Graph-based workflows<br>for structured reasoning</td>
<td>Multi-step reasoning tasks<br>with explicit decision paths</td>
<td>Python</td>
</tr>
<tr>
<td><a href="#smolagents">SmolAgents</a></td>
<td>Minimal, efficient design<br>with direct code execution</td>
<td>Quick automation tasks with<br>lightweight implementation</td>
<td>Python</td>
</tr>
</tbody>
</table>
<h2 id="visual-no-code-frameworks">Visual no-code frameworks</h2><p>These frameworks prioritize visual interfaces and simplified workflows, making AI agent development accessible to users with minimal technical experience.</p><h3 id="flowise">Flowise</h3><p><strong>Primary strength</strong>: Visual workflow building with a drag-and-drop interface</p><p><a href="https://flowiseai.com/?ref=blog.n8n.io"><u>Flowise</u></a> is an open-source platform for building customized LLM applications. It offers a drag-and-drop user interface and integrates with popular frameworks such as LangChain and LlamaIndex.</p><p>While Flowise simplifies many aspects of AI development, there&#x2019;s still a learning curve. For example, Flowise sequential agents are built on top of the LangGraph framework.</p><figure class="kg-card kg-image-card kg-width-wide kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXdWli-VV9Jj_RgU078Y1sD93Oq8yTdaYmZCEOe5Q0SZHrMQacrtyfClCYOJm_9nAEERkCNijc37ptkkppdcuqHJbTPHG33-4sQWAz35er3V8MDx6Ok5qUWdAYDvG8WiWSruLx08zQ?key=YcWxiydCxbItAKhZbEzRfAno" class="kg-image" alt="9 AI Agent Frameworks Battle: Why Developers Prefer n8n" loading="lazy" width="602" height="307"><figcaption><span style="white-space: pre-wrap;">Build AI workflows visually with Flowise&apos;s drag-and-drop canvas</span></figcaption></figure><p><strong>Key features:</strong></p><ul><li>Integration with popular AI frameworks such as LangChain, LangGraph and LlamaIndex</li><li>Support for sequential agents, multi-agent systems and Retrieval-Augmented Generation (RAG)</li><li>Extensive library of pre-built nodes and integrations</li><li>Tools to analyze and troubleshoot chatflows and agentflows (two types of applications you can build with Flowise)</li><li>Generation of the chat widget that can be embedded into websites or applications</li></ul><p><strong>Pricing:</strong></p><ul><li>Cloud version starts at $35/month</li><li>Open-source version for self-hosted deployment</li></ul><h3 id="botpress">Botpress</h3><p><strong>Primary strength</strong>: Visual workflow design with extensive AI integrations</p><p><a href="https://botpress.com/?ref=blog.n8n.io"><u>Botpress</u></a> is an AI agent development platform that is available both in the cloud and as an open-source version. Its browser-based Studio interface features a visual flow builder, making it accessible to both developers and non-developers.</p><p>With Botpress, creating your first AI agent requires no coding. You can simply select templates that fit your use case, define your agent&#x2019;s instructions and identity, and integrate knowledge bases by uploading documents or providing textual inputs.</p><figure class="kg-card kg-image-card kg-width-wide kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXctJSmLDU5lc3YyHOYVk39sbN87koqM-yR4BlN-TjChcjDymrNgM4rJJ567DDP3VV1KN6Yu-KXtE0zr14YkaPfRwcqHJJaK_83OR0jmMs5OsI_Uf-jzCbAJpkXotL3dyrfn_ZzX?key=YcWxiydCxbItAKhZbEzRfAno" class="kg-image" alt="9 AI Agent Frameworks Battle: Why Developers Prefer n8n" loading="lazy" width="602" height="363"><figcaption><span style="white-space: pre-wrap;">Craft chatbots in Botpress that talk to customers across multiple platforms</span></figcaption></figure><p><strong>Key features:</strong></p><ul><li>Visual workflow design with a drag-and-drop interface</li><li>Built-in chat emulator for testing your chatbot</li><li>Knowledge base capabilities for uploading documents and external data sources</li><li>Template-based approach for rapid agent creation</li><li>Multi-channel deployment options for websites, messaging apps, and more</li><li>Support for both technical and non-technical users</li></ul><p><strong>Pricing:</strong></p><ul><li>Cloud hosting is free for 1 bot, paid tiers start at $79/month</li><li>Paid add-ons available</li><li>An open-source version of V12 Botpress is available</li></ul><h3 id="langflow">Langflow</h3><p><strong>Primary strength</strong>: Visual IDE on top of LangChain with pre-built templates</p><p><a href="https://www.langflow.org/?ref=blog.n8n.io"><u>Langflow</u></a> is a visual framework for creating multi-agent and RAG applications that is built on top of the LangChain ecosystem. Langflow provides LangChain tools and components as pre-built elements, allowing developers to quickly add functionality to their AI applications without having to code from scratch.</p><figure class="kg-card kg-image-card kg-width-wide kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXcj0QJlkpkla4WjiJEBpcDVTg2gs55CEfh7LvUea5IRvYCrsloAE07qV2yZOUHKyJCpcf8ulUriEkFTB92ERKEJtLfRde234sqTviu-OOCQSe1htRUr4kTu3VRswlmfo6ltFGjaYQ?key=YcWxiydCxbItAKhZbEzRfAno" class="kg-image" alt="9 AI Agent Frameworks Battle: Why Developers Prefer n8n" loading="lazy" width="602" height="272"><figcaption><span style="white-space: pre-wrap;">Design LangChain applications with Langflow&apos;s visual canvas</span></figcaption></figure><p><strong>Key features:</strong></p><ul><li>Drag-and-drop interface for building AI workflows</li><li>Integration with various LLMs, APIs, and data sources</li><li>Export flows as JSON files: can import in another Langflow instance or reuse in the Python Langflow runtime</li><li>Pre-built templates for quick prototyping</li><li>Open-source with cloud deployment options</li><li>Fully customizable and LLM/vector store agnostic</li></ul><p><strong>Pricing:</strong></p><ul><li>Langflow offers a free-to-use model, available as both a self-hosted project and as a cloud service</li><li>While the cloud version is free, its default vector store is backed by AstraDB, which has usage-based pricing</li></ul><h2 id="intermediate-low-code-complexity-frameworks">Intermediate low-code complexity frameworks</h2><p>These frameworks balance visual development with more powerful customization capabilities, which is ideal for developers who want to easily build sophisticated agents, but still be able to code when needed.</p><h3 id="n8n">n8n</h3><p><strong>Primary strength</strong>: Visual AI agent orchestration with extensible architecture for custom LLM integrations and agent workflows</p><p>n8n is a <a href="https://n8n.io/ai/?ref=blog.n8n.io"><u>powerful source-available automation platform</u></a> that combines AI capabilities with traditional workflow automation. This approach allows users with varying levels of expertise to build custom AI applications and integrate them into business workflows.</p><p>As one of the leading frameworks for AI agent orchestration, n8n offers an intuitive drag-and-drop interface while allowing for advanced customization when needed. It offers a balance between ease of use and functionality, making it suitable for both simple automations and complex multi-agent systems.</p><figure class="kg-card kg-image-card kg-width-wide kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXf4ZQkNAYFj3tleIPZuzk7ROTFN_sJ4z0mzLzqFuOqBUJospFrN6qyv-KRoZ4bJxpSeQFGu59H78NPEtole_eQWIrBXTk7TZwzE86fxAE_vA-NPgZpvQqrTDF1HCDNY4YRUI-aJ?key=YcWxiydCxbItAKhZbEzRfAno" class="kg-image" alt="9 AI Agent Frameworks Battle: Why Developers Prefer n8n" loading="lazy" width="602" height="305"><figcaption><span style="white-space: pre-wrap;">Orchestrate AI agents in n8n while connecting them to your existing business systems and data sources</span></figcaption></figure><p><strong>Key features:</strong></p><ul><li>Flexible deployment: choose between cloud-hosted or self-hosted solutions to meet security and compliance requirements</li><li>Advanced AI components: implement chatbots, personalized assistants, multi-agent systems and more with pre-built AI nodes</li><li>Custom code support: add custom JavaScript when needed (available for <a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.code/?ref=blog.n8n.io"><u>LangChain components</u></a> and as a separate <a href="https://docs.n8n.io/code/code-node/?ref=blog.n8n.io"><u>Code node</u></a>)</li><li>LangChain integration and vector store compatibility: integrate with various vector databases (<a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.vectorstorepinecone/?ref=blog.n8n.io"><u>Pinecone</u></a>, <a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.vectorstoreqdrant/?ref=blog.n8n.io"><u>Qdrant</u></a>, <a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.vectorstorezep/?ref=blog.n8n.io"><u>Zep</u></a>) for efficient storage and retrieval of embeddings</li><li>Memory management and RAG support: implement context-aware AI applications with built-in memory options for ongoing conversations and relevant information from custom data sources</li><li><a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.agent/tools-agent?ref=blog.n8n.io"><u>Use of tools</u></a>: extend agent functionality with built-in nodes: <a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.toolhttprequest/?ref=blog.n8n.io"><u>HTTP Request tool</u></a>, <a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.toolworkflow/?ref=blog.n8n.io"><u>workflow tool</u></a> to run other workflows, or <a href="https://community.n8n.io/t/review-node-as-tools-is-finally-here/57539?ref=blog.n8n.io"><u>Nodes as Tools</u></a></li><li>n8n interacts with MCP as an MCP client via <a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.toolmcp/?ref=blog.n8n.io" rel="noreferrer">the MCP Client Tool node</a> to use external tools by connecting to MCP servers with authentication. Additionally, n8n acts as an MCP server through <a href="https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-langchain.mcptrigger/?ref=blog.n8n.io" rel="noreferrer">the MCP Server Trigger node</a> to expose its tools and workflows using SSE and configurable URLs with authentication</li><li>Scalable architecture: handles enterprise-level workloads with a robust infrastructure</li></ul><p><strong>Pricing:</strong></p><ul><li>Cloud version starts at 24&#x20AC;/month</li><li>Custom pricing for enterprise customers (with discounts for eligible startups)</li><li>Community edition is free for self-hosted deployment</li></ul><h3 id="crewai">CrewAI</h3><p><strong>Primary strength</strong>: Role-based collaboration with specialized agent teams</p><p><a href="https://www.crewai.com/?ref=blog.n8n.io"><u>CrewAI</u></a> is a lean Python framework developed entirely from scratch &#x2013; completely independent of LangChain or other agent frameworks. With the Studio interface users can create agents without actually programming them.</p><p>CrewAI stands out for its ability to create a &#x201C;crew&#x201D; of AI agents, each with specific roles, goals and backstories. For instance, you can have a researcher agent that gathers information, a writer agent that creates content, and an editor agent that refines the final output &#x2013; all working in concert within the same framework.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXd7YpefF4gtKd5eCoeCsRepYJoK5Zo3sAu9sKGhvTvvja2lyP4a_E1wa8W1zz5PjpYRV1PsWo4F4e-xYTPBJSoj9O43P4BqNO0jIXEaRyfcC_54IX3tw0Kla4Ju8kkNWIrdK_sedw?key=YcWxiydCxbItAKhZbEzRfAno" class="kg-image" alt="9 AI Agent Frameworks Battle: Why Developers Prefer n8n" loading="lazy" width="602" height="555"><figcaption><span style="white-space: pre-wrap;">Assemble specialized AI agent teams in CrewAI where each member plays a specific role</span></figcaption></figure><p><strong>Key features:</strong></p><ul><li>Role-based agents with defined roles, expertise, and goals</li><li>Flexible tools to equip agents with custom tools and APIs</li><li>Task management for defining sequential or parallel workflows</li><li>Support for both Crews (autonomous collaboration) and Flows (structured automation)</li><li>Event-driven orchestration with fine-grained control</li></ul><p><strong>Pricing:</strong></p><ul><li>Custom pricing for enterprise customers</li><li>An open-source version is available</li></ul><h3 id="rivet">Rivet</h3><p><strong>Primary strength</strong>: Visual scripting for AI agents with debugging capabilities</p><p><a href="https://rivet.ironcladapp.com/?ref=blog.n8n.io"><u>Rivet</u></a> is a powerful Integrated Development Environment (IDE) and library for creating AI agents using a visual, graph-based interface. It consists of two main components: Rivet Application (editor/IDE) and Rivet Core/Node (TypeScript libraries for execution).</p><p>Rivet&#x2019;s node-based editor enables you to create, configure, and debug complex AI prompt chains and AI agent chains visually. This approach makes it easier to understand the data flow and state of your AI agent at any point in time, with real-time visibility into inputs, outputs, and AI responses.</p><figure class="kg-card kg-image-card kg-width-wide kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXdW1Sv8-cr9lBCZ4QCQKWCgPSW5iHRZel-5KPOsMXPXwBrzIvOeRoYIol5OLse7ImI4bmwXSvR_urao-wxVTGqthRQYq68ixLiP66_WzKfkAP2CX0JsDl12XdPmPoMl2p8qIvUg2g?key=YcWxiydCxbItAKhZbEzRfAno" class="kg-image" alt="9 AI Agent Frameworks Battle: Why Developers Prefer n8n" loading="lazy" width="602" height="351"><figcaption><span style="white-space: pre-wrap;">See your AI agent&apos;s thinking process unfold with Rivet&apos;s visual debugging environment</span></figcaption></figure><p><strong>Key features:</strong></p><ul><li>Visual editor for creating and debugging complex AI prompt chains</li><li>Live debugging of AI chains as they run, with support for remote debugging</li><li>TypeScript libraries for executing projects in applications</li><li>Integrated testing to ensure graphs work for all inputs (via separate Trivet library)</li></ul><p><strong>Pricing:</strong></p><ul><li>Rivet editor is a multi-platform free desktop app for MacOS, Windows and Linux</li></ul><h2 id="programming-first-frameworks">Programming-first frameworks</h2><p>These frameworks emphasize code-first approaches, offering maximum flexibility and control for developers with programming experience.</p><h3 id="autogen">AutoGen</h3><p><strong>Primary strength</strong>: Advanced multi-agent orchestration with agent-to-agent communication</p><p><a href="https://microsoft.github.io/autogen/stable/?ref=blog.n8n.io"><u>AutoGen</u></a> is one of Microsoft&apos;s frameworks for building AI agents. Its main focus is on the creation of scalable multi-agent systems.</p><p>AutoGen&#x2019;s event-driven programming approach makes it particularly suited for building agentic workflows for business processes, research on multi-agent collaboration, and distributed agents for multi-language applications (Python &amp; Dotnet).</p><figure class="kg-card kg-image-card kg-width-wide kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXck2L5AHuACMmqXVg7NQfMJi8iaE47Ycoo6i_OjD3tOdWoGLwMZ1AY517ig_GfnViQd_vwyQHRHFTV8Cc10-_2MD8otTuKoQnIK2mgzZ3FpjYAHW7zoortyoEUXLOka20tEpEvD?key=YcWxiydCxbItAKhZbEzRfAno" class="kg-image" alt="9 AI Agent Frameworks Battle: Why Developers Prefer n8n" loading="lazy" width="602" height="279"><figcaption><span style="white-space: pre-wrap;">Create AI agents that collaborate autonomously in AutoGen, passing information and solving problems together</span></figcaption></figure><p><strong>Key features:</strong></p><ul><li>AgentChat for building conversational agents</li><li>Event-driven programming framework for scalable multi-agent AI systems</li><li>Extensions for using LangChain tools, Assistant API, and Docker container execution</li><li>Command-line interface (<a href="https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/magentic-one.html?ref=blog.n8n.io"><u>Magentic-One CLI</u></a>) for fast agent interactions</li><li>AutoGen Studio for prototyping and managing agents without writing code</li></ul><p><strong>Pricing:</strong></p><ul><li>Open-source project </li></ul><h3 id="langgraph">LangGraph</h3><p><strong>Primary strength</strong>: Graph-based workflows for structured reasoning</p><p><a href="https://www.langchain.com/langgraph?ref=blog.n8n.io"><u>LangGraph</u></a> is a low-level orchestration framework for building controllable agents. While LangChain provides integrations and composable components for LLM application development, LangGraph enables agent orchestration with customizable architectures, long-term memory, and human-in-the-loop capabilities.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXd3pywBRuOI5-qt0c3hwxrxItr1eoNeBp5eJoiVQ6kWtRHx2JusAdBDx1Ui1hWaLogf91Z9Qebo0qXWld42zGGhcsJwXFqsbDm4-oNXhewd2QAzSuAL9q0Gbk91p9y7ABZXEVALLA?key=YcWxiydCxbItAKhZbEzRfAno" class="kg-image" alt="9 AI Agent Frameworks Battle: Why Developers Prefer n8n" loading="lazy" width="602" height="823"><figcaption><span style="white-space: pre-wrap;">Map out your agent&apos;s decision paths with LangGraph&apos;s structured reasoning framework</span></figcaption></figure><p><strong>Key features:</strong></p><ul><li>Reliability and controllability with moderation checks and human-in-the-loop approvals</li><li>Low-level and extensible design with fully descriptive primitives</li><li>First-class streaming support with token-by-token visibility into agent reasoning</li><li>Customizable agent architectures for specific use cases</li><li>Persistence capabilities for context in long-running workflows</li><li>Integration with other LangChain products (LangSmith and LangGraph Platform)</li></ul><p><strong>Pricing:</strong></p><ul><li>Paid tiers on the LangGraph platform</li><li>Open-source version available</li></ul><h3 id="smolagents">SmolAgents</h3><p><strong>Primary strength</strong>: Minimal, efficient design with direct code execution</p><p><a href="https://github.com/huggingface/smolagents?ref=blog.n8n.io"><u>SmolAgents</u></a> is a newer framework from HuggingFace for agentic systems. It positions itself as a minimalistic framework for building powerful agents. For example, the core agent logic fits in approximately 1,000 lines of code.</p><p>One of SmolAgents&#x2019; standout features is its first-class support for Code Agents &#x2013; agents that write their actions in code, as opposed to agents being used to write code. This approach enables direct code execution for efficient automation tasks.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXcjKjphTWmsTQIVpKGSWGD_Cum7QbgVzkRFUlG0RXJGGerjhsRS4n9lOG1znX7yK33cgiikIK66WlzkMbW3nF-0wsuqbA0tDmgdNZm8D3ew-m9tDU_InODnfRiN7OsQLL631_d8-w?key=YcWxiydCxbItAKhZbEzRfAno" class="kg-image" alt="9 AI Agent Frameworks Battle: Why Developers Prefer n8n" loading="lazy" width="602" height="423"><figcaption><span style="white-space: pre-wrap;">Build lightweight, efficient agents with SmolAgents&apos; minimalist approach</span></figcaption></figure><p><strong>Key features:</strong></p><ul><li>Minimal, efficient design with minimal abstractions</li><li>Support for any LLM, including models from Hugging Face, OpenAI, Anthropic, and more</li><li>HuggingFace hub integrations for sharing and loading Gradio Spaces as tools</li><li>Simplified framework for quick implementation of automation tasks</li></ul><p><strong>Pricing:</strong></p><ul><li>Open-source project </li></ul><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text">Looking to improve your development workflow? Check out our <a href="https://blog.n8n.io/ai-coding-assistants/"><u>guide to AI coding assistants</u></a>.</div></div><h2 id="how-to-pick-an-ai-agent-framework">How to pick an AI agent framework?</h2><p>When selecting an AI agent framework, consider the following key factors:</p><ol><li><strong>Project complexity</strong>: assess whether you need a simple chatbot or a complex multi-agent system. AutoGen, for example, is great for orchestrating multiple AI agents for complex tasks, while CrewAI is more suitable for smaller projects.</li><li><strong>Developer expertise</strong>: evaluate your team&#x2019;s familiarity with AI concepts and programming skills. Frameworks like Flowise offer a more intuitive approach, while LangChain or AutoGen provide deeper customization for experienced developers.</li><li><strong>Language preferences</strong>: consider the programming languages your team is comfortable with. Most frameworks support either Python or JavaScript, and there are also some less popular solutions for other languages.</li><li><strong>Build type</strong>: decide between no-code, low-code or code-centric development frameworks depending on your technical expertise and project requirements.</li><li><strong>Integration needs</strong>: determine whether you want to build from scratch or add AI to existing systems. n8n, for example, is designed to integrate AI into existing business systems without major rewrites.</li><li><strong>Scalability</strong>: ensure that the framework can handle your current needs and future growth. Frameworks like LangGraph offer solutions for complex, long-running applications.</li></ol><p>By carefully evaluating these factors, you can select an AI agent framework that meets your project goals, your team&apos;s capabilities and your long-term business needs.</p><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text">Want to discover more AI solutions for your business? Our <a href="https://blog.n8n.io/ai-tools-for-business/"><u>comprehensive guide covers 20 top AI tools and how to integrate them with n8n</u></a> for maximum productivity.</div></div><h2 id="why-use-n8n-to-build-ai-agents">Why use n8n to build AI agents?</h2><p><strong>n8n is a powerful choice for building AI agents that connect with existing business systems and scale to production.</strong> Its blend of visual development, robust integrations, and enterprise-level scalability makes it ideal for real-world use. While other AI agent frameworks may offer niche features, n8n&#x2019;s flexibility stands out for production-ready AI solutions.</p><p>Here&#x2019;s why:</p><h3 id="agentic-workflows-not-just-agents">Agentic workflows, not just agents</h3><p>n8n excels at creating complete workflows and agents. It uniquely enables agents to trigger traditional workflows as tools, resulting in more controlled agentic behavior. Agents initiate workflows, reducing the chances of unpredictable or random behavior (<a href="https://blog.n8n.io/ai-agentic-workflows/"><u>AI agentic workflows guide</u></a>).</p>
<!--kg-card-begin: html-->
<script>
  workflowBanner([2592, 3189, 1963, 2338, 2347], document.currentScript, { 
      workflowsHeader: "Explore how AI agents work in practice with these free workflows:"
  });
</script>
<!--kg-card-end: html-->
<h3 id="out-of-the-box-agent-components">Out-of-the-box agent components</h3><p>n8n provides a rich set of pre-built components specifically for creating agents:</p><ul><li><a href="https://docs.n8n.io/advanced-ai/langchain/langchain-n8n/?ref=blog.n8n.io"><u>LangChain nodes</u></a>: direct integration with LangChain&#x2019;s components.</li><li>Memory: built-in support for various memory types (see below).</li><li>Flexible tools: HTTP Request tool node, workflow execution via the Workflow tool node and Nodes as tools.</li><li>Interchangeable LLMs: easily swap between cloud providers and local models.</li><li>Structured output parsing: ensure reliable, consistent agent outputs.</li></ul><h3 id="a-variety-of-tools">A variety of tools</h3><p>One of the most important capabilities of the AI agents is interaction with other systems. This is done via a range of tools in n8n:</p><ul><li>Web parsing: extract data from websites using the <a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.toolhttprequest/?ref=blog.n8n.io"><u>HTTP Request tool node</u></a>.</li><li>Workflow execution: trigger complete n8n workflows as tools using the <a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.toolworkflow/?ref=blog.n8n.io"><u>Workflow Tool</u></a>.</li><li><a href="https://community.n8n.io/t/review-node-as-tools-is-finally-here/57539?ref=blog.n8n.io"><u>Nodes as tools</u></a>: use specific n8n nodes as tools for fine-grained control.</li><li>RAG features: integrate with vector databases like <a href="https://n8n.io/integrations/qdrant-vector-store/?ref=blog.n8n.io"><u>Qdrant</u></a>, <a href="https://n8n.io/integrations/pinecone-vector-store/?ref=blog.n8n.io"><u>Pinecone</u></a>, <a href="https://n8n.io/integrations/supabase-vector-store/?ref=blog.n8n.io"><u>Supabase</u></a>, and <a href="https://n8n.io/integrations/postgres-pgvector-store/?ref=blog.n8n.io"><u>PGVector</u></a> for knowledge-augmented agents. n8n also provides an <a href="https://n8n.io/integrations/in-memory-vector-store/?ref=blog.n8n.io"><u>in-memory vector store</u></a> for quick prototyping.</li></ul><p>Model Context Protocol (MCP) support: a <a href="https://community.n8n.io/t/we-re-adding-mcp-client-tool-mcp-trigger-nodes-try-them-now/99338?ref=blog.n8n.io" rel="noopener noreferrer">native support for both MCP clients and servers</a>. This opens up completely new integration opportunities with programs and services tools that may not natively support REST API integrations.</p><figure class="kg-card kg-embed-card"><iframe width="200" height="113" src="https://www.youtube.com/embed/45WPU7P-1QQ?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen title="n8n Just Released Native MCP Trigger and AI Agent Tool [Official Walkthrough]"></iframe></figure><h3 id="diverse-memory-approaches">Diverse memory approaches:</h3><p>Maintain the conversation context with different storage options:</p><ul><li><a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.memorypostgreschat/?ref=blog.n8n.io"><u>Postgres Chat Memory</u></a>: for persistent, auditable memory.</li><li><a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.memoryredischat/?ref=blog.n8n.io"><u>Redis Chat Memory</u></a>: high-performance caching of conversation history.</li><li>Zep Memory: use <a href="https://n8n.io/integrations/zep/?ref=blog.n8n.io"><u>Zep</u></a> for long-term memory capabilities.</li></ul><p><a href="https://n8n.io/integrations/window-buffer-memory/?ref=blog.n8n.io"><u>Window Buffer Memory</u></a>: a simple, in-memory buffer for short-term context.</p>
<!--kg-card-begin: html-->
<script>
  workflowBanner([2612, 2568, 3115, 2534], document.currentScript);
</script>
<!--kg-card-end: html-->
<h3 id="robust-output-parsing">Robust output parsing</h3><p>When creating AI agents or integrating LLMs into products, you need to ensure agents produce consistent, reliable outputs. n8n supports two way of doing so:</p><ul><li><a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.outputparserstructured/?ref=blog.n8n.io"><u>Structured Output Parser</u></a>: enforce a predefined JSON schema, automatically retrying if the output is invalid.</li><li><a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.outputparserautofixing/?ref=blog.n8n.io"><u>Auto-Fixing Parser</u></a>: use the LLM to automatically correct parsing errors.</li></ul>
<!--kg-card-begin: html-->
<script>
  workflowBanner([2766, 3107, 3123], document.currentScript);
</script>
<!--kg-card-end: html-->
<h3 id="model-flexibility">Model flexibility</h3><p>Easily switch between different LLMs:</p><ul><li>Cloud providers: connect to <a href="https://n8n.io/integrations/openai-chat-model/?ref=blog.n8n.io"><u>OpenAI</u></a>, <a href="https://n8n.io/integrations/anthropic-chat-model/?ref=blog.n8n.io"><u>Anthropic</u></a>, <a href="https://n8n.io/integrations/azure-openai-chat-model/?ref=blog.n8n.io"><u>Azure</u></a>, <a href="https://n8n.io/integrations/deepseek-chat-model/?ref=blog.n8n.io"><u>DeepSeek</u></a> and <a href="https://n8n.io/integrations/mistral-cloud-chat-model/?ref=blog.n8n.io"><u>Mistral</u></a>.</li><li><a href="https://n8n.io/integrations/openrouter-chat-model/?ref=blog.n8n.io"><u>OpenRouter</u></a>: access a wide range of models through the OpenRouter integration.</li></ul><p>Local models: run models locally using the <a href="https://n8n.io/integrations/ollama-chat-model/?ref=blog.n8n.io"><u>Ollama integration</u></a>.</p>
<!--kg-card-begin: html-->
<script>
  workflowBanner([2341, 2864, 2970], document.currentScript);
</script>
<!--kg-card-end: html-->
<h2 id="wrap-up">Wrap up</h2><p>In this guide, we&#x2019;ve reviewed 9 powerful AI agent frameworks in three main categories:</p><ul><li><strong>No-code visual tools</strong>: Flowise, Botpress and Langflow for visual workflow design.</li><li><strong>Intermediate cow-code frameworks</strong>: n8n, CrewAI and Rivet for balanced customization.</li><li><strong>Programming-first solutions</strong>: AutoGen, LangGraph and SmolAgents for code-centric development.</li></ul><p>Each framework offers unique advantages depending on your project requirements, team expertise and scalability needs.</p><p>For teams looking to deploy AI agents in business-critical systems, <a href="https://n8n.io/?ref=blog.n8n.io"><u>n8n</u></a> stands out with its unique hybrid approach. Unlike pure AI agent frameworks, n8n enables you to:</p><ul><li>Build agents that <a href="https://blog.n8n.io/ai-agentic-workflows/"><u>trigger traditional workflows as tools</u></a>.</li><li>Combine hundreds of pre-built integrations and create your own via the HTTP Request tool node.</li><li>Scale from simple chatbots to complex multi-agent systems.</li></ul>
<!--kg-card-begin: html-->
<div class="content-banner">
  <div>
    <h3>Start building AI agents with n8n</h3>
    <p>Our visual interface and pre-built components let you create production-ready systems faster than traditional coding approaches</p>
  </div>
  <a href="https://app.n8n.cloud/register?ref=blog.n8n.io" class="global-button blog-banner-signup">Try n8n now</a>
</div>
<!--kg-card-end: html-->
<h2 id="what%E2%80%99s-next">What&#x2019;s next?</h2><p>Deepen your AI agent expertise with these resources:</p><ul><li>Explore <a href="https://blog.n8n.io/ai-agents-examples/"><u>real-world AI agent implementations</u></a> in various industries.</li><li>Learn about <a href="https://blog.n8n.io/llamaindex-vs-langchain/"><u>the differences between LlamaIndex and LangChain for RAG applications</u></a> and how RAG extends the capabilities of AI agents.</li><li>Develop <a href="https://blog.n8n.io/ai-workflows-for-the-cautious-enterprise/"><u>an AI adoption strategy</u></a> for your enterprise environment.</li></ul>]]></content:encoded></item><item><title><![CDATA[n8n closes â‚¬55M Series B round led by Highland Europe]]></title><description><![CDATA[<p></p><p>When I started building n8n six years ago, I never imagined we&apos;d be where we are today. What began as a solution to my own frustration has grown into something used by over 200,000 people worldwide! Today, I&apos;m incredibly excited to announce that we&apos;</p>]]></description><link>https://blog.n8n.io/series-b/</link><guid isPermaLink="false">67dd504ebd35f20001848e39</guid><dc:creator><![CDATA[Jan Oberhauser]]></dc:creator><pubDate>Tue, 25 Mar 2025 12:18:47 GMT</pubDate><media:content url="https://blog.n8n.io/content/images/2025/03/seriesB-blog.jpg" medium="image"/><content:encoded><![CDATA[<img src="https://blog.n8n.io/content/images/2025/03/seriesB-blog.jpg" alt="n8n closes &#x20AC;55M Series B round led by Highland Europe"><p></p><p>When I started building n8n six years ago, I never imagined we&apos;d be where we are today. What began as a solution to my own frustration has grown into something used by over 200,000 people worldwide! Today, I&apos;m incredibly excited to announce that we&apos;ve secured &#x20AC;55 million in Series B funding led by Highland Europe with participation from HV Capital and previous investors Sequoia, Felicis, and Harpoon.</p><p><a href="https://techcrunch.com/2025/03/24/fair-code-pioneer-n8n-raises-60m-for-ai-powered-workflow-automation/?ref=blog.n8n.io">Read Ingrid Lunden&#x2019;s coverage of our round in TechCrunch</a></p><p><a href="https://www.highlandeurope.com/n8n-raises-e55-million-from-highland-europe-to-transform-workflow-automation-for-technical-teams-by-unifying-ai-code-and-human-building-blocks/?ref=blog.n8n.io">Read Highland Europe&apos;s coverage of our round</a></p><p>This milestone isn&apos;t just about the money &#x2013; it&apos;s about what our incredible community and team have built together! Our mission is <em>to give technical people the powers of a 10x developer</em>. Seeing so many people around the world connect with this, that&apos;s what really gets me excited!</p><h2 id="from-frustration-to-solution">From frustration to solution</h2><p>Like many founders, I built n8n to solve a pain point of my own. I was tired of workflow tools that either lacked flexibility or required deep technical expertise. So I created something different:<strong> a platform powerful enough for developers yet accessible to anyone willing to learn</strong>.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://blog.n8n.io/content/images/2025/03/n8n-first-version.jpeg" class="kg-image" alt="n8n closes &#x20AC;55M Series B round led by Highland Europe" loading="lazy" width="1395" height="805" srcset="https://blog.n8n.io/content/images/size/w600/2025/03/n8n-first-version.jpeg 600w, https://blog.n8n.io/content/images/size/w1000/2025/03/n8n-first-version.jpeg 1000w, https://blog.n8n.io/content/images/2025/03/n8n-first-version.jpeg 1395w" sizes="(min-width: 720px) 720px"><figcaption><i><em class="italic" style="white-space: pre-wrap;">n8n in september 2018 (pre-release)</em></i></figcaption></figure><p>The early days were challenging &#x2013; coding late into the night, questioning if anyone would even want what I was building. But then people started using n8n, sharing workflows, and building on top of what we&apos;d created. The community grew organically, with users pushing the boundaries of what was possible.</p><p>Today, we&apos;ve grown to over 200,000 users and 3,000+ enterprises, with our <a href="https://github.com/n8n-io/n8n/?ref=blog.n8n.io">GitHub repository</a> ranked among the top 150 projects of all time. This incredible growth shows we weren&apos;t alone in our frustration with existing tools!</p><h2 id="the-power-of-community">The power of community</h2><p>What makes n8n different isn&apos;t just what it can do &#x2013; it&apos;s how it lets you do it. We&apos;ve created an experience that respects technical users while welcoming everyone. Our open architecture lets developers extend functionality, while our visual interface makes complex integrations accessible.</p><p>n8n has become the trusted solution for government agencies, security teams, and enterprises worldwide. Companies like Vodafone and <a href="https://n8n.io/case-studies/delivery-hero/?ref=blog.n8n.io">Delivery Hero</a>,  are transforming their operations using n8n, connecting disparate systems and eliminating manual work. But what&apos;s most rewarding is seeing our community embrace this approach &#x2013; sharing templates, helping each other, and expanding what&apos;s possible on our platform.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://blog.n8n.io/content/images/2025/03/image.png" class="kg-image" alt="n8n closes &#x20AC;55M Series B round led by Highland Europe" loading="lazy" width="1024" height="768" srcset="https://blog.n8n.io/content/images/size/w600/2025/03/image.png 600w, https://blog.n8n.io/content/images/size/w1000/2025/03/image.png 1000w, https://blog.n8n.io/content/images/2025/03/image.png 1024w" sizes="(min-width: 720px) 720px"><figcaption><span style="white-space: pre-wrap;">Paris Community Meetup, December 2024</span></figcaption></figure><h2 id="ai-automation-where-were-headed">AI + Automation: Where we&apos;re headed</h2><p>If there&apos;s one thing I&apos;ve learned, it&apos;s that automation isn&apos;t just about connecting systems &#x2013; it&apos;s about <strong>augmenting human capabilities</strong>. With AI, we&apos;re entering a new era where this reaches unprecedented levels.</p><p>By <a href="https://n8n.io/workflows/categories/ai/?ref=blog.n8n.io">integrating AI directly into n8n workflows</a>, users can accomplish tasks that would have been impossible just months ago. Data that was previously too complex to process can now be analyzed automatically. Decisions that required human judgment can now be handled intelligently within workflows.</p><p>We believe AI should enhance human capabilities, not replace them. <strong>The winning recipe is AI, code and humans</strong>. That&apos;s why we&apos;re building AI features that amplify what users can accomplish, putting them in control of how intelligence is applied in their workflows. </p><figure class="kg-card kg-image-card kg-width-wide kg-card-hascaption"><img src="https://blog.n8n.io/content/images/2025/03/Product-hero.webp" class="kg-image" alt="n8n closes &#x20AC;55M Series B round led by Highland Europe" loading="lazy" width="2000" height="1125" srcset="https://blog.n8n.io/content/images/size/w600/2025/03/Product-hero.webp 600w, https://blog.n8n.io/content/images/size/w1000/2025/03/Product-hero.webp 1000w, https://blog.n8n.io/content/images/size/w1600/2025/03/Product-hero.webp 1600w, https://blog.n8n.io/content/images/size/w2400/2025/03/Product-hero.webp 2400w" sizes="(min-width: 1200px) 1200px"><figcaption><span style="white-space: pre-wrap;">n8n workflow canvas with AI agent </span></figcaption></figure><h2 id="what%E2%80%99s-next">What&#x2019;s next</h2><p>The Series B funding will <strong>accelerate</strong> our mission. We&apos;ll <a href="https://n8n.io/careers/?ref=blog.n8n.io">expand our team</a>, and continue making powerful automation accessible to everyone.</p><p>We&#x2019;ll also be significantly <strong>investing</strong> in education for both beginner and advanced users, as well as providing dedicated support and partnering closely with the power users of n8n who are evolving into experts, consultants, and founders of agencies offering their specialized expertise.</p><p><strong>The future</strong> we envision isn&apos;t just about more integrations &#x2013; it&apos;s about fundamentally changing how people interact with technology. It&apos;s about creating a world where repetitive tasks disappear, systems talk to each other, and people focus on creative, strategic work.</p><p><strong>To our community</strong> &#x2013; thank you. You&apos;ve been with us every step of the way. This funding round is as much your achievement as it is ours.</p><p><strong>To our team</strong> &#x2013; your dedication and passion have built n8n into what it is today. I&apos;m incredibly proud of what we&apos;ve accomplished together.</p><p><strong>And to those who haven&apos;t yet tried n8n</strong> &#x2013; I invite you to <a href="https://n8n.io/?ref=blog.n8n.io">join us</a>. The future of work is automated, and we&apos;re building the tools to make that future accessible to everyone.</p><p><strong>This &#x20AC;55 million Series B is not the destination &#x2013; it&apos;s fuel for the journey ahead.</strong> A journey toward a world where technology works for people, not the other way around. That&apos;s the world we&apos;re building at n8n and there is so much more to do!</p><figure class="kg-card kg-image-card"><img src="https://blog.n8n.io/content/images/2025/03/team_press_2.png" class="kg-image" alt="n8n closes &#x20AC;55M Series B round led by Highland Europe" loading="lazy" width="1920" height="1920" srcset="https://blog.n8n.io/content/images/size/w600/2025/03/team_press_2.png 600w, https://blog.n8n.io/content/images/size/w1000/2025/03/team_press_2.png 1000w, https://blog.n8n.io/content/images/size/w1600/2025/03/team_press_2.png 1600w, https://blog.n8n.io/content/images/2025/03/team_press_2.png 1920w" sizes="(min-width: 720px) 720px"></figure>]]></content:encoded></item><item><title><![CDATA[15 Practical AI Agent Examples to Scale Your Business in 2025]]></title><description><![CDATA[Discover what AI agents are, explore 5 key types, and see 15 real-world examples of AI agents automating tasks like data analysis and customer support.]]></description><link>https://blog.n8n.io/ai-agents-examples/</link><guid isPermaLink="false">67b70bbc6eff130001084af5</guid><category><![CDATA[AI]]></category><category><![CDATA[Guide]]></category><dc:creator><![CDATA[Federico Trotta]]></dc:creator><pubDate>Wed, 19 Mar 2025 12:59:49 GMT</pubDate><media:content url="https://blog.n8n.io/content/images/2025/03/Slide-16_9---172--1-.png" medium="image"/><content:encoded><![CDATA[<img src="https://blog.n8n.io/content/images/2025/03/Slide-16_9---172--1-.png" alt="15 Practical AI Agent Examples to Scale Your Business in 2025"><p><a href="https://blog.n8n.io/ai-agents/"><u>AI agents</u></a> are transforming the way technical teams approach automation, shifting from traditional rule-based workflows to more dynamic, intelligent systems that can adapt and make decisions in real-time.</p><p>Unlike static automation, which relies on predefined triggers and actions, AI agents leverage large language models (LLMs) to process complex data, understand context, and respond to unpredictable scenarios.</p><p>In this article, we&#x2019;ll explore 15 practical examples of AI agents, showing how they automate complex tasks and improve workflows. We&#x2019;ll also explain how platforms like <a href="https://n8n.io/ai/?ref=blog.n8n.io" rel="noreferrer"><strong>n8n</strong></a> make it easier to build, customize, and scale these AI agents for real-world use.</p><p>Let&apos;s dive in!</p><h2 id="what-is-an-ai-agent">What is an AI agent?</h2><p>AI agents are software tools that perform tasks, make decisions, and interact autonomously with their environment. At their core, they leverage <a href="https://blog.n8n.io/best-llm-for-coding/"><u>LLMs</u></a> to understand goals from natural language, generate tasks, and complete them.</p><p>AI agents can work as part of bigger systems by learning and changing based on the data they process, so you can use them to automate work and outsource complex cognitive tasks.</p><p>Yes, like creating a team of robotic coworkers to support you and your human teammates in your activities!</p><figure class="kg-card kg-embed-card"><iframe width="200" height="113" src="https://www.youtube.com/embed/77Z07QnLlB8?start=1371&amp;feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen title="Building AI Agents: Prompt Engineering for Beginners [Part 3]"></iframe></figure><h2 id="what-are-the-5-types-of-agents-in-ai">What are the 5 types of agents in AI?</h2><p>Before we jump into 15 real-world&#xA0; AI agents examples, let&#x2019;s discuss the <a href="https://blog.n8n.io/ai-agents/#what-are-the-types-of-agents-in-ai"><u>5 types of AI agents</u></a>. Understanding these categories will give you a clearer view of how they work and where they fit into your projects.</p><h3 id="simple-reflect-agents">Simple reflect agents</h3><p>A simple reflex agent is an AI agent that uses current data and ignores past data. It uses a set of condition-action rules coded into the system to make its decision or take any action. These agents are straightforward and are suitable for simple situations where a condition leads to an action.&#xA0;</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXcgK1A7c6fMQ_Eq1SgxPtmZCHquT5J5RC6_ep7TDzo_xmD2GEjMNKpH8SHW4Zq7VvOuWmOpV6_DmZ8JCbDJeZ0379DnT8JVn5cbf9nl8cg54GORMigHkbpH9P1FXq-zQUtBRkYaqA?key=Lgp4bKPxlxcRjHKSwFeh61Q8" class="kg-image" alt="15 Practical AI Agent Examples to Scale Your Business in 2025" loading="lazy" width="602" height="311"><figcaption><span style="white-space: pre-wrap;">Simple reflect AI agent schema</span></figcaption></figure><p>An example of a simple reflex agent can be a spam filter in an email system. In this case, the filter can act as a simple reflex agent by analyzing incoming emails and classifying them as &quot;spam&quot; or &quot;not spam&quot; based on predefined rules or patterns (e.g., presence of certain keywords, suspicious links, or sender reputation).</p><h3 id="model-based-reflex-agents">Model-based reflex agents</h3><p>Model-based reflex agents are a little more sophisticated as they use the current state of the world and the internal model of that world to decide on the best action. So, basically, they partially observe the external environment by maintaining an internal environment.</p><p>This partial observation of the external environment allows them to update their understanding of the world they&#x2019;ve analyzed before. For this reason, these agents are useful in environments where:</p><p>- Complete information isn&#x2019;t available.</p><p>- Some form of history needs to be considered.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXc0I_bv89pfFAWcqawTjldy8CIzkovdZvWWJ2TFB3b0DvInhWHs_p551iuRaR2P1qVXpB8b0hy_PE_QkYqVCXE3AB9rT-VheQEZM-ANsW4pC7EiglYtE21MmYpLTkEQplpoHrTwKg?key=Lgp4bKPxlxcRjHKSwFeh61Q8" class="kg-image" alt="15 Practical AI Agent Examples to Scale Your Business in 2025" loading="lazy" width="602" height="280"><figcaption><span style="white-space: pre-wrap;">Model-based reflex AI agent schema</span></figcaption></figure><p>An example of a model-based reflex agent is a virtual assistant. Virtual assistants, in fact, maintain a model of the user&apos;s preferences, context, and past interactions to provide better responses. For example, if a user asks, &quot;What&#x2019;s the weather like?&quot; the assistant uses the current query (perception) and its internal model (e.g., the user&#x2019;s location and time of day) to provide an accurate response.</p><h3 id="goal-based-agents">Goal-based agents</h3><p>Goal-based agents use the model of the world they have to consider the future consequences of their actions to achieve specific goals.</p><p>These kinds of agents are ideal for complex planning and decision-making tasks where achieving a specific outcome is your priority.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXe2sJlOu0naGFF5_pkKXXzy1YZsuRhc6E6gN2Kti-_Fxi5BZlDatlhbTUn6DGde1maoxGSN6PIojACSsTcgGTqhVIgAh8tUTe2CWWKIPTp4oAH8P9cR-x02XD86_cIGTvb5Z1J8jA?key=Lgp4bKPxlxcRjHKSwFeh61Q8" class="kg-image" alt="15 Practical AI Agent Examples to Scale Your Business in 2025" loading="lazy" width="602" height="320"><figcaption><span style="white-space: pre-wrap;">Goal-based AI agent schema</span></figcaption></figure><p>An example of a goal-based reflex agent is a movie recommendation system. Netflix, YouTube, and other similar platforms have recommendation systems that aim to maximize user satisfaction by suggesting content the user is likely to enjoy. The system evaluates user preferences, past behavior, and available content, then selects recommendations that align with the goal of keeping the user engaged.</p><h3 id="utility-based-agents">Utility-based agents</h3><p>These agents are more advanced. They aim not just to achieve goals: they maximize a measure of satisfaction or happiness, which is known as utility. They evaluate the potential utility of different states and choose actions that maximize the utility parameter.</p><p>Utility-based agents are useful in scenarios that require optimization among different criteria and variables. For example, they excel in financial analysis and personalized recommendation systems where the best outcome depends on maximizing certain metrics.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfnx7DXngVwJ9X8ZluhXfvwffXuEHeLJSbQjJziI4qVkeiDHEddmWBG-ZfAw8M5yTZYQvFQ3ob-CQYQPcWRikAe7GBZ_Fwg04RzkBhNpmk6qV2jqVN6Iyb7S5mRTKBHy-ZMbCTH6Q?key=Lgp4bKPxlxcRjHKSwFeh61Q8" class="kg-image" alt="15 Practical AI Agent Examples to Scale Your Business in 2025" loading="lazy" width="602" height="379"><figcaption><span style="white-space: pre-wrap;">Utility-based AI agent schema</span></figcaption></figure><p>An example of a utility-based agent is a stock trading bot. AI-powered trading systems analyze market data to decide when to buy, sell, or hold stocks. They do so by maximizing profit while minimizing risk and transaction costs.</p><h3 id="learning-agents">Learning agents</h3><p>Learning agents improve their performance and adapt to new circumstances over time. They can modify their behavior based on past experiences and feedback, learning from the environment to make better decisions. So, basically, they start with a basic set of knowledge and constantly improve based on their experiences.</p><p>These agents are key in dynamic environments where conditions constantly change. For example, they&apos;re utilized in adaptive systems such as personalized learning platforms, market trend analysis tools, and evolving security systems that adapt to new threats.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXdcMKOzD8Iy8V1PIgnFoHbaA7iPjt5Q11hKryQR5U_vTRI55V_50XzKDsGtb7VSW96QV376-8ogxy0xXtyHBeANdAAFiTRGrcV5mSkCrXrInyf-NFUvQFIMwFJiLhlPShkEA16atg?key=Lgp4bKPxlxcRjHKSwFeh61Q8" class="kg-image" alt="15 Practical AI Agent Examples to Scale Your Business in 2025" loading="lazy" width="602" height="379"><figcaption><span style="white-space: pre-wrap;">Learning AI agent schema</span></figcaption></figure><p>Examples of learning agents are autonomous vehicles with adaptive learning. Self-driving cars, in fact, learn to improve their driving performance by analyzing real-world driving data. The car learns from its own driving experiences (e.g., handling different weather conditions and traffic patterns) and from data collected by other vehicles in the fleet. The agent uses supervised learning (e.g., training on labeled driving data) and reinforcement learning (e.g., learning optimal driving policies through simulation or real-world feedback).</p><h2 id="15-ai-agents-examples">15 AI agents examples</h2><p>As you already saw, AI agents come in many forms, from simple rule-based systems to advanced, learning-based models.</p><p>You can build them using various tools and frameworks&#x2014;like <a href="https://www.langchain.com/?ref=blog.n8n.io" rel="noreferrer"><strong>LangChain</strong></a> for creating complex language-based agents, <a href="https://microsoft.github.io/autogen/stable/?ref=blog.n8n.io" rel="noreferrer"><strong>AutoGen</strong></a> for multi-agent collaboration, or <a href="https://n8n.io/?ref=blog.n8n.io" rel="noreferrer"><strong>n8n</strong></a> for customizable, no-code/low-code automation with AI integration. Each tool has unique strengths, depending on whether you need fine-tuned control, rapid prototyping, or scalable workflows.</p><p>In this section, we&#x2019;ll focus on <strong>n8n AI agent examples</strong> because they offer flexibility for developers to design and automate intelligent workflows without being locked into a specific framework. With its source-available nature and robust integrations, n8n makes it easy to connect AI models with real-world processes&#x2014;perfect for building practical, production-ready AI agents.</p><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text">In the AI agents examples below, you can think of n8n as the fuel and AI agents as the engine of your workflows!&#xA0;</div></div><h3 id="basic-ai-agent-chat">Basic AI agent chat</h3><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXeQiyUcvfGOtC20yI4JB1J7iAdSNQ713dXL7cdd4co0plIASufcnTtV1AwOjQwnpl5HCRr2E0VHcXUrtQoIdKanF8zoyLzR5-ZDg3n42yhQ1jbn-enrZBO0TJzyPm6fVXBsYo27?key=Lgp4bKPxlxcRjHKSwFeh61Q8" class="kg-image" alt="15 Practical AI Agent Examples to Scale Your Business in 2025" loading="lazy" width="602" height="308"><figcaption><span style="white-space: pre-wrap;">Basic AI agent chat by n8n</span></figcaption></figure><p>This workflow uses <a href="https://openai.com/?ref=blog.n8n.io"><u>OpenAI</u></a>&apos;s language models and <a href="https://serpapi.com/?ref=blog.n8n.io"><u>SerpAPI</u></a> to create a responsive conversational agent. It has manual chat triggers and memory buffer capabilities to ensure seamless interactions.</p><p><strong>Why we like it</strong></p><p>This is the most basic AI-powered chatbot you can create with an AI agent in n8n, so it is useful to gain confidence in our product and processes. However, note that you can create more complicated chatbots like an &quot;<a href="https://n8n.io/workflows/2872-ai-agent-chatbot-long-term-memory-note-storage-telegram/?ref=blog.n8n.io" rel="noreferrer">AI agent chatbot with long-term memory and note storage using Google Docs and Telegram integration</a>&quot;.</p>
<!--kg-card-begin: html-->
<script>
  workflowBanner(1954, document.currentScript);
</script>
<!--kg-card-end: html-->
<h3 id="vision-based-ai-agent-scraper">Vision-based AI agent scraper</h3><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfg-aY16SdjlE1oOnAB6rmhSd2d11NjIfYO4_cNAlwnBj37c4NTg2hSxAY-Kh7ZkYJWnkgWYub4en7q5ip9F7Le4ds-SXp6BaUw3XnEE32XxCzcXP-YA0dTMdyffUdybqvC-BaL?key=Lgp4bKPxlxcRjHKSwFeh61Q8" class="kg-image" alt="15 Practical AI Agent Examples to Scale Your Business in 2025" loading="lazy" width="602" height="221"><figcaption><span style="white-space: pre-wrap;">Vision-based AI agent scraper by n8n</span></figcaption></figure><p>If you are used to scraping the data from the web, we know that managing CSS selectors, Xpaths, and anything related can be annoying. Here&#x2019;s where this workflow comes in handy!</p><p>This agentic workflow extracts data effortlessly without worrying about how the DOM (Document Object Model) is structured, saving you from the typical headaches involved when scraping websites.</p><p>This workflow automates data scraping by taking a <a href="https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-langchain.chattrigger/?ref=blog.n8n.io"><u>chat input</u></a> to trigger the process, scraping URLs from a <a href="https://docs.n8n.io/integrations/builtin/app-nodes/n8n-nodes-base.googlesheets/?ref=blog.n8n.io"><u>Google Sheet</u></a> using the <a href="https://app.scrapingbee.com/api/v1?ref=blog.n8n.io"><u>ScrapeBee API</u></a>, and processing the data with an AI agent that leverages <a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatgooglegemini/?ref=blog.n8n.io"><u>Google Gemini</u></a>. It extracts and organizes the scraped content into a structured format, which is then stored back into Google Sheets for easy access and further use.</p><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text"><a href="https://ai.google/get-started/our-models/?ref=blog.n8n.io" rel="noreferrer">Gemini</a> is only one of the LLMs that n8n can leverage to super-power your workflows with AI. Read more about <a href="https://blog.n8n.io/best-llm-for-coding/" rel="noreferrer">how n8n can leverage LLMs in this article</a>.</div></div><p><strong>Why we like it</strong></p><p>n8n provides different AI-powered scraping workflows, but what we particularly liked about it is that it uses <a href="https://www.scrapingbee.com/?ref=blog.n8n.io"><u>ScrapeBee</u></a>. This provides the superpower to capture full-page screenshots and retrieve HTML data for fallback extraction, allowing you to get rid of CSS selectors and XPaths.</p><p>Remember to always verify compliance when web scraping, for example by analyzing the <code>robot.txt</code> file. Other than that, you can start using this workflow right now for a superior scraping experience:</p>
<!--kg-card-begin: html-->
<script>
  workflowBanner(2563, document.currentScript);
</script>
<!--kg-card-end: html-->
<h3 id="sql-agent-for-queries-visualization">SQL Agent for queries visualization</h3><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXf83qBDpuJ2DNwQsogKCt_3gIjXs_VUprArJhl_FHJj8yFWQ83bov_iYv-kInwdZvDglCT6dSjnT-obL87ZQ_hsXAaywcUl5rRaox5eOKNF2YEB6pyYb0Xqw-q6UYDrS9SAhDGMgQ?key=Lgp4bKPxlxcRjHKSwFeh61Q8" class="kg-image" alt="15 Practical AI Agent Examples to Scale Your Business in 2025" loading="lazy" width="602" height="405"><figcaption><span style="white-space: pre-wrap;">SQL AI Agent for queries visualization</span></figcaption></figure><p>SQL queries can be a hassle when you just need a quick plot to understand your data. This workflow simplifies that by adding data visualization to the native SQL Agent, using <a href="https://docs.n8n.io/integrations/builtin/app-nodes/n8n-nodes-langchain.openai/?ref=blog.n8n.io"><u>OpenAI</u></a> and <a href="https://quickchart.io/?ref=blog.n8n.io"><u>QuickChart</u></a>.</p><p>The AI agent extracts information with the OpenAI-powered <a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.information-extractor/?ref=blog.n8n.io"><u>Information Extractor</u></a>, queries a <a href="https://www.postgresql.org/?ref=blog.n8n.io"><u>Postgres</u></a> database, and maintains query history. It then analyzes the data with the <a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.text-classifier/%C3%B9?ref=blog.n8n.io"><u>Text Classifier</u></a>, and if plots are needed, the workflow triggers QuickChart via the OpenAI API.</p><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text">This workflow uses Postgres as <b><strong style="white-space: pre-wrap;">Data Source</strong></b> in the AI agent. However, note that n8n has strong support for all major SQL engine, so you can choose your favourite one. We&#x2019;ve already posted several articles dedicated to different use cases for<a href="https://n8n.io/integrations/mysql/?ref=blog.n8n.io" target="_blank" rel="noopener">&#xA0;MySQL</a>,&#xA0;<a href="https://n8n.io/integrations/microsoft-sql/?ref=blog.n8n.io" target="_blank" rel="noopener">MS SQL</a>,&#xA0;<a href="https://n8n.io/integrations/postgres/?ref=blog.n8n.io" target="_blank" rel="noopener">PostgreSQL</a>.</div></div><p><strong>Why we like it</strong></p><p>This workflow allows you to plot charts from SQL queries only if the AI agent understands they are needed. So, basically, you set your acceptance parameters and just let the automation work for you, plotting the charts only if needed. a great time saver!</p><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text">We also provide <a href="https://n8n.io/workflows/2508-generate-sql-queries-from-schema-only-ai-powered/?ref=blog.n8n.io" rel="noreferrer">a<u> workflow </u>to generate SQL queries based on database schema</a>. Integrating the two can be a game-changer for your SQL workflows! </div></div><p>Other than that, you can use this workflow as is here:</p>
<!--kg-card-begin: html-->
<script>
  workflowBanner(2559, document.currentScript);
</script>
<!--kg-card-end: html-->
<h3 id="web-pages-scraper-ai-agent">Web pages scraper AI agent</h3><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXflwerHv33J8GaGmjmiIxNrFYTBrtDbeNko5uYCSGUC9alpl9cO8a1CCF_lqF4tYnz5x-a_l4KCNzlMb4QIyzAXTZHHlg26XD-W7Q1-ZP26B0OHHbxaqbexDu-gDnbZDjRWhT-V?key=Lgp4bKPxlxcRjHKSwFeh61Q8" class="kg-image" alt="15 Practical AI Agent Examples to Scale Your Business in 2025" loading="lazy" width="602" height="300"><figcaption><span style="white-space: pre-wrap;">Web pages scraper AI agent by n8n</span></figcaption></figure><p>Yes, another scraping workflow! At n8n, we know that scraping is a vast field with its nuances to appreciate and solve. This workflow differs from the previous one because it uses the ReAct AI Agent &#x2013; which reasons and acts &#x2013; and extracts the HTML body as &#x201C;classical&#x201D; scrapers do.&#xA0;</p><p>It uses the <a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.agent/react-agent/?ref=blog.n8n.io"><u>ReAct AI Agent</u></a> node to fetch pages on the web, converts the query string to JSON, and retrieves the content via the <a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.toolhttprequest/?ref=blog.n8n.io"><u>HTTP Request node</u></a>.</p><p><strong>Why we like it</strong></p><p>This workflow employs the typical scraping process any engineer uses. So, while you need to manage the HTML body, tags, and anything related, this can be your starting point if you have never used n8n for scraping the web.</p><p>So, why not give it a try now?</p>
<!--kg-card-begin: html-->
<script>
  workflowBanner(2006, document.currentScript);
</script>
<!--kg-card-end: html-->
<h3 id="ai-data-analyst-agent">AI data analyst agent</h3><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXcVw3lkzQfAffZ5CzV70D4zTg696woxQThKhAU_X17CBRU3XEZkXmfiEzIRN3OGdszOo7wMW1IexVy3S3y5oQ_m66_AL_CbPWYWVjPxRdXQriR07TiDkzjHc9k6bwQl6jyr-vjOkQ?key=Lgp4bKPxlxcRjHKSwFeh61Q8" class="kg-image" alt="15 Practical AI Agent Examples to Scale Your Business in 2025" loading="lazy" width="602" height="127"><figcaption><span style="white-space: pre-wrap;">AI data analyst agent by n8n</span></figcaption></figure><p>This AI agent example transforms spreadsheet data into an interactive, AI-powered knowledge base that enables users to gain deep insights through natural language queries, searchability, and comparative analysis by storing data in <a href="https://docs.n8n.io/integrations/builtin/app-nodes/n8n-nodes-base.nocodb/?ref=blog.n8n.io" rel="noreferrer">NocoDB</a>.</p><p><strong>Why we like it</strong></p><p>Let&#x2019;s be honest: anyone is guilty of using at least one spreadsheet as if it were a database! This workflow is particularly helpful with large spreadsheets. The major pain point of data analysts is to combine different spreadsheets or analyze very large ones to gain insights. This workflow avoids all the associated headaches of such processes in a matter of a few clicks.</p>
<!--kg-card-begin: html-->
<script>
  workflowBanner(2653, document.currentScript);
</script>
<!--kg-card-end: html-->
<h3 id="ai-agent-talking-to-sql-lite">AI agent talking to SQL lite</h3><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXcQTHUrK2GTHpdZjBXCWgV2q9xIxVU7yx-lbaFyb364f7-FFwaKp7_MpxoWYKugb1fyId8KKuZh7D_KnL2SQVV1DqbZF4SXDLYhq27S_7p2ZzYbFEj8HcPSYidMcKCPKwfRYRxq?key=Lgp4bKPxlxcRjHKSwFeh61Q8" class="kg-image" alt="15 Practical AI Agent Examples to Scale Your Business in 2025" loading="lazy" width="602" height="163"><figcaption><span style="white-space: pre-wrap;">AI agent talking to SQL lite by n8n</span></figcaption></figure><p>How beautiful it would be if you could get answers from a database without writing queries but by prompting with natural language? Pretty awesome, uh?! Well, this is exactly what this workflow does! In this workflow, the agent can understand natural language queries and interact with a <a href="https://www.sqlitetutorial.net/sqlite-sample-database/?ref=blog.n8n.io"><u>tutorial SQLite database</u></a> to provide accurate answers.</p><p><strong>Why we like it</strong></p><p>We like the possibility of using the tutorial databases: this is a good way to gain confidence with n8n. However, this workflow has to be tailored to your needs if you want to make it work for your scenarios. In this case, if your scenario is complex, you can benefit from our advanced agentic database workflows like <a href="https://n8n.io/workflows/2508-generate-sql-queries-from-schema-only-ai-powered/?ref=blog.n8n.io" rel="noreferrer">&quot;Generate SQL queries from schema only - AI-powered&quot; one.</a></p>
<!--kg-card-begin: html-->
<script>
  workflowBanner(2292, document.currentScript);
</script>
<!--kg-card-end: html-->
<h3 id="ai-email-summarizing-agent">AI email-summarizing agent</h3><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXcCyHAF-ZoDFh4yDjOeR85VE1AwEx4shNADR59KMRWIPiLRtFPdT-P6I6fhfi4q8nunk71Lg_o6zEMVnfE4oTxpzF6s-eKh-HyxvJrnzjQapVD5rBjpC903qO27Vstz2rur0mXh?key=Lgp4bKPxlxcRjHKSwFeh61Q8" class="kg-image" alt="15 Practical AI Agent Examples to Scale Your Business in 2025" loading="lazy" width="602" height="169"><figcaption><span style="white-space: pre-wrap;">AI email-summarizing agent by n8n</span></figcaption></figure><p>This workflow automates email management using AI. It fetches your emails from your <a href="https://docs.n8n.io/integrations/builtin/app-nodes/n8n-nodes-base.gmail/?ref=blog.n8n.io"><u>Gmail</u></a> account at a <a href="https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.scheduletrigger/?ref=blog.n8n.io"><u>customizable hour of the day</u></a>, summarizes key points and actions, and sends two concise updates: one in the morning and one at night. No more distractions from notifications and no more hours spent reading countless emails!</p><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text">You&apos;re not using Gmail? No worries, you can still use the <a href="https://docs.n8n.io/integrations/builtin/app-nodes/n8n-nodes-base.microsoftoutlook/?ref=blog.n8n.io" rel="noreferrer">Outlook node</a>!</div></div><p><strong>Why we like it</strong></p><p>Shall we really discuss why we love an agentic-email summarizer?! That&#x2019;s the perfect solution for every company where communication is still managed via email! Also, if you don&#x2019;t want to send the summarized emails via email, you could use the <a href="https://n8n.io/integrations/slack/?ref=blog.n8n.io"><u>Slack</u></a> node or the <a href="https://n8n.io/integrations/microsoft-teams/?ref=blog.n8n.io"><u>Teams</u></a> one, depending on the chatting solution used in your company.</p>
<!--kg-card-begin: html-->
<script>
  workflowBanner(2722, document.currentScript);
</script>
<!--kg-card-end: html-->
<h3 id="ai-meeting-summarizing-agent">AI meeting-summarizing agent</h3><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXe2WM6faz2gwK8OkAN5DeaBBxEIawJbx8PR3sA_tjimIH4qUIT-4tCf4QO_PSt-Yt5vrtIpLJIh3VY985rdfwbqsOUk5eNggfhpbdA2Kl3haumgyXVusDB05XLqoWoTcoi4zC9NQQ?key=Lgp4bKPxlxcRjHKSwFeh61Q8" class="kg-image" alt="15 Practical AI Agent Examples to Scale Your Business in 2025" loading="lazy" width="602" height="432"><figcaption><span style="white-space: pre-wrap;">AI meeting-summarizing agent by n8n</span></figcaption></figure><p>We got another rabbit out of a top hat! Do you frequently participate in video meetings where you&#x2019;d like and need to take notes? Well, this workflow is here for you! It automates the transcription process in real time, ensuring that key discussions and decisions are accurately captured and easily accessible for later review, enhancing productivity and clarity in communications.</p><p>In this workflow, the recording data is structured via the <a href="https://docs.n8n.io/integrations/builtin/app-nodes/n8n-nodes-base.supabase/?ref=blog.n8n.io"><u>Supabase </u></a>node, saved into a <a href="https://docs.n8n.io/integrations/builtin/app-nodes/n8n-nodes-base.postgres/?ref=blog.n8n.io"><u>Postgres</u></a> database, and summarized via OpenAI.</p><p><strong>Why we like it</strong></p><p>This workflow is more flexible than dedicated tools by combining Recall.ai, OpenAI, and Supabase for real-time transcription, AI insights, and structured data storage. It offers full customization and control, allowing you to tailor actions, data processing, and storage to your business needs.</p>
<!--kg-card-begin: html-->
<script>
  workflowBanner(2651, document.currentScript);
</script>
<!--kg-card-end: html-->
<h3 id="ai-customer-support-agent">AI customer support agent</h3><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXdUJ2EsJWgEJfqvRa3ZWH3rprR7IOFi33AyFoTkVL7gjPu84WqW-w6OqXvu5rXZBusFCDexbvES9IaRElZBu4EyxvoRQpxngpAir9rxdyQj5xMVzQdz6-fMVEmWcLlOfBFEqrZM?key=Lgp4bKPxlxcRjHKSwFeh61Q8" class="kg-image" alt="15 Practical AI Agent Examples to Scale Your Business in 2025" loading="lazy" width="602" height="413"><figcaption><span style="white-space: pre-wrap;">AI customer support agent by n8n</span></figcaption></figure><p>If you are a support engineer, you know the feeling of being overwhelmed by customers&#x2019; tickets! This workflow has got you covered. It automates email support using AI to provide smart, context-aware responses based on your knowledge base stored in Google Drive, and creates a response draft ready to be reviewed and sent to your customers. No more drowning in support tickets!</p><p><strong>Why we like it</strong></p><p>This workflow can really revolutionize your support! If your support engineers are drowning in clients&#x2019; tickets, hiring new employees could not be the right solution: you can try to automate their responses with this workflow!</p><p>Note that this workflow relies on knowledge from <a href="https://docs.n8n.io/integrations/builtin/trigger-nodes/n8n-nodes-base.googledrivetrigger/?ref=blog.n8n.io"><u>Google Drive</u></a>. If your knowledge base is elsewhere &#x2013; for example, in <a href="https://www.atlassian.com/software/jira?ref=blog.n8n.io"><u>Jira</u></a>, <a href="https://www.gitbook.com/?ref=blog.n8n.io"><u>GitBook</u></a>, GitHub, or whatever &#x2013; you can use the HTTP request node to set the URL where your knowledge is stored, trigger from time to time with the Schedule Trigger node, store the result into any database you&#x2019;d like, and use the OpenAI chat node to verify if any changes occurred.</p>
<!--kg-card-begin: html-->
<script>
  workflowBanner(2929, document.currentScript);
</script>
<!--kg-card-end: html-->
<h3 id="ai-agent-for-company-documents">AI agent for company documents</h3><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfH9WSlFz9WKUCRF6m69WQuBq01BLllKM3Pae0dENSNgjY391bZVNWQHGuNdDk1nt_z8dvEzmmy2TRWJBrP5GKtJzJqUag9o7m38vqTw2Dvy6F0UJjUZj7Mwf3PvPHynY8Wnd6DFQ?key=Lgp4bKPxlxcRjHKSwFeh61Q8" class="kg-image" alt="15 Practical AI Agent Examples to Scale Your Business in 2025" loading="lazy" width="602" height="227"><figcaption><span style="white-space: pre-wrap;">AI agent for company documents by n8n</span></figcaption></figure><p>Large companies are generally accompanied by a high number of documents, often frustrating employees that are searching for answers in large documentation base. This workflow comes in handy as it implements a RAG chatbot that answers employee questions based on company documents stored in Google Drive.&#xA0;</p><p><strong>Why we like it</strong></p><p>Sometimes, the documentation base can only increase over time, regardless of the fact that they do so with or without a structured strategy. This AI-powered workflow can save you tons of hours searching for answers in large documentation bases, especially if there is no ownership of them and your colleagues just update and add new documents in it, and you have the sense of losing control over your company knowledge.</p><p>Try this workflow now to speed up your questioning on your documentation base:</p>
<!--kg-card-begin: html-->
<script>
  workflowBanner(2753, document.currentScript);
</script>
<!--kg-card-end: html-->
<h3 id="ai-agent-to-automate-siem-alert-enrichment-with-mitre-attck">AI agent to automate SIEM alert enrichment with MITRE ATT&amp;CK</h3><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfYQO-S2Bdzepb_7wNRwm80IJvuWebwRLT45v8elYuhTpD_IWWn8o3-KS5BDM3JI49ErMgNi1aT6MO9vhh6Hq6hNpL3zlSw4mbWeZcFkUrvsqdA2SEKYXuSxL4AzhT2Fkwnvyrllg?key=Lgp4bKPxlxcRjHKSwFeh61Q8" class="kg-image" alt="15 Practical AI Agent Examples to Scale Your Business in 2025" loading="lazy" width="602" height="109"><figcaption><span style="white-space: pre-wrap;">AI security agent by n8n</span></figcaption></figure><p>In 2025, cybersecurity concerns are at the core of all companies. Security teams receive large volumes of raw SIEM alerts that lack actionable context, and investigating every alert manually is time-consuming. This workflow solves this problem by:</p><ul><li>Automatically enriching SIEM (Security Information and Event Management) alerts with <a href="https://attack.mitre.org/?ref=blog.n8n.io"><u>MITRE ATT&amp;CK</u></a> TTPs (Tactics, Techniques, and Procedures).</li><li>Tagging and classifying alerts based on known attack techniques.</li><li>Providing remediation steps to guide the response team.</li><li>Enhancing security tickets in Zendesk with relevant threat intelligence.&#xA0;</li></ul><p><strong>Why we like it</strong></p><p>Security is really important today, and the actual added value of this workflow is that it incorporates MITRE ATT&amp;CK TTPs. This means that you can be beneficial for your company even if you don&#x2019;t have a dedicated security team. Note that, in this case, the alerts come from <a href="https://docs.n8n.io/integrations/builtin/app-nodes/n8n-nodes-base.zendesk/?ref=blog.n8n.io"><u>Zendesk tickets</u></a>, but you can modify this by getting them from other sources, like a chatbot or whatever suits your needs.</p>
<!--kg-card-begin: html-->
<script>
  workflowBanner(2840, document.currentScript);
</script>
<!--kg-card-end: html-->
<h3 id="ai-agent-to-chat-with-github%E2%80%99s-api-documentation">AI agent to chat with GitHub&#x2019;s API documentation</h3><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfTOBwYnrG30qMhW9QxadyMH2Ja6i9H8w0XyT0XtbJoqa3cqnTrFdw5fNMNbBbsHnNWps-892FfKWWyoE5sd3h5lLOLvvIXzeGege7f6CpDsOAB0vxz_OVl9GmPl-eHBK3S7oLCwg?key=Lgp4bKPxlxcRjHKSwFeh61Q8" class="kg-image" alt="15 Practical AI Agent Examples to Scale Your Business in 2025" loading="lazy" width="602" height="239"><figcaption><span style="white-space: pre-wrap;">AI agent to chat with GitHub&#x2019;s API documentation by n8n</span></figcaption></figure><p>GitHub is surely one of the most used Git systems by IT professionals. However, it can sometimes be tricky to use its API, and this is where this workflow comes into help. This workflow creates a chatbot that lets you chat with the <a href="https://raw.githubusercontent.com/github/rest-api-description/refs/heads/main/descriptions/api.github.com/api.github.com.json?ref=blog.n8n.io"><u>GitHub API documentation</u></a> in natural language, saving you time on research, particularly if you need to use it and have little time.</p><p><strong>Why we like it</strong></p><p>You may think that each LLM today has the answers to all your questions, so you might directly prompt ChatGPT &#x2013; or any LLM &#x2013; to get answers on how to use the GitHub API. However, LLMs are not retrained very often and can miss updates. This workflow, instead, ensures you get updated responses as it passes the URL of the documentation through the HTTP request node, ensuring the LLM reasons on updated data.</p>
<!--kg-card-begin: html-->
<script>
  workflowBanner(2705, document.currentScript);
</script>
<!--kg-card-end: html-->
<h3 id="ai-agent-to-fine-tune-openai-models">AI agent to fine-tune OpenAI models</h3><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXeeLoY0GwVaP_TU3Iy3EhKb4tr725qlGVTs2Pee0ewMvjdszwTzROu830W6jSlhpKTxC2S3NEouqVHQFTfkurb_jQADmuAjmpW4AFW9Qq6YHlShmKyXq2HOIVwVzWv976xGt6mDsw?key=Lgp4bKPxlxcRjHKSwFeh61Q8" class="kg-image" alt="15 Practical AI Agent Examples to Scale Your Business in 2025" loading="lazy" width="602" height="220"><figcaption><span style="white-space: pre-wrap;">AI agent to fine-tune OpenAI models by n8n</span></figcaption></figure><p>One of the most important features of LLMs is that they can be fine-tuned to respond to specific prompts. The idea is simple: you get a model that is already trained, and you fine-tune its knowledge. This is exactly what this workflow does: it fine-tunes OpenAI models on your documents stored in Google Drive so that it can provide tailored answers based on that specific knowledge.</p><div class="kg-card kg-callout-card kg-callout-card-red"><div class="kg-callout-emoji">&#x26A0;&#xFE0F;</div><div class="kg-callout-text"><b><strong style="white-space: pre-wrap;">ATTENTION</strong></b>: The data uploaded to Google Drive must be in the <code spellcheck="false" style="white-space: pre-wrap;">.jsonl</code>: verify it matches <a href="https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset?ref=blog.n8n.io" rel="noreferrer">OpenAI&apos;s requirements</a> before start fine-tuning.</div></div><p><strong>Why we like it</strong></p><p>This workflow is straightforward to follow and, in a matter of a few minutes, you can fine-tune your model, allowing you to get tailored responses based on your own documents. However, note that it can raise security concerns, particularly for &#x201C;delicate&#x201D; documents, because you are loading your files directly into <a href="https://platform.openai.com/storage/files?ref=blog.n8n.io"><u>OpeAI&#x2019;s platform</u></a>. If you want to avoid this, you can try and adapt <a href="https://n8n.io/workflows/2766-extract-personal-data-with-self-hosted-llm-mistral-nemo/?ref=blog.n8n.io"><u>this workflow</u></a> to your particular needs: it uses <a href="https://ollama.com/?ref=blog.n8n.io"><u>Ollama</u></a> to run <a href="https://mistral.ai/news/mistral-nemo?ref=blog.n8n.io"><u>Mistral NeMo</u></a> as a self-hosted LLM to address your security concerns.</p>
<!--kg-card-begin: html-->
<script>
  workflowBanner(2781, document.currentScript);
</script>
<!--kg-card-end: html-->
<h3 id="ai-agent-for-telegram-bots">AI agent for Telegram bots</h3><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXe1K7IwlUkvcocpXv-JMgHt1V6LwlC293Me2fKRKQbQOYp7I14ZeuOD-a6ZsS5XXMmCSGc2XdAYj7qgBM6xxL4WuzdQRapjmn2XjZmjFgo5vEgy1yKZmPlKOvFbASu5zVBxhdK9pw?key=Lgp4bKPxlxcRjHKSwFeh61Q8" class="kg-image" alt="15 Practical AI Agent Examples to Scale Your Business in 2025" loading="lazy" width="602" height="384"><figcaption><span style="white-space: pre-wrap;">AI agent for Telegram bots by n8n</span></figcaption></figure><p>If you want a <a href="https://docs.n8n.io/integrations/builtin/app-nodes/n8n-nodes-base.telegram/?ref=blog.n8n.io"><u>Telegram</u></a> chatbot that uses the newly released LLM, <a href="https://www.deepseek.com/?ref=blog.n8n.io"><u>DeepSeek</u></a>, then this workflow is definitely for you. This workflow also incorporates long-term memory capabilities via <a href="https://docs.n8n.io/integrations/builtin/app-nodes/n8n-nodes-base.googledocs/?ref=blog.n8n.io"><u>Google Docs</u></a> for personalized and context-aware responses to users.</p><p><strong>Why we like it</strong></p><p>Among all the chatbots automated with n8n, this is one of the most complete ones as it manages user validation, short and long-term memories, and error management. It also uses the <a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatdeepseek/?ref=blog.n8n.io"><u>DeepSeek node</u></a>, which has been recently released, showing how n8n is at the forefront of the latest technological innovations.</p>
<!--kg-card-begin: html-->
<script>
  workflowBanner(2864, document.currentScript);
</script>
<!--kg-card-end: html-->
<h3 id="ai-agent-to-chat-with-airtable-and-analyze-data">AI agent to chat with Airtable and analyze data</h3><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXdUvw9A6Unp7se1GEQDmGsXuTTGeSjKDIATxwffTTkhRvgzdk9eh3sY-sOlREEPMY5Zrgp4-Mrd-eddVMT4QXyWQJ-u57MwTVERnRH7ZYBIgX1QYH0kt9tdbjnyMEO32x1MiYwbWQ?key=Lgp4bKPxlxcRjHKSwFeh61Q8" class="kg-image" alt="15 Practical AI Agent Examples to Scale Your Business in 2025" loading="lazy" width="602" height="200"><figcaption><span style="white-space: pre-wrap;">AI agent to chat with Airtable and analyze data by n8n</span></figcaption></figure><p>If you lost yourself navigating Airtable while striving to retrieve data from it, here&#x2019;s the good news: that time is long gone! This workflow creates an AI-powered conversational agent integrated with <a href="https://docs.n8n.io/integrations/builtin/app-nodes/n8n-nodes-base.airtable/?ref=blog.n8n.io"><u>Airtable</u></a> datasets, and it is particularly useful for users looking to enhance data interaction through chat interfaces. By conversationally interacting with Aitrable datasets, you can retrieve essential information quickly while minimizing the need for complex queries.</p><p><strong>Why we like it</strong></p><p>Navigating <a href="https://www.airtable.com/?ref=blog.n8n.io"><u>Airtable </u></a>can be really tricky when trying to retrieve data from it, and this workflow really gets you covered! Note that the memory is directly managed via the OpenAI API: a different approach with respect to the others we&#x2019;ve seen so far. Note also that the first step of the workflow requires you to manually insert different casistics and patterns related to the data you want to extract. This is often not easily manageable, as attributes are not always known a priori. To solve this, you can try <a href="https://n8n.io/workflows/2771-ai-data-extraction-with-dynamic-prompts-and-airtable/?ref=blog.n8n.io"><u>this solution</u></a> that introduces the Dynamic Prompts AI workflow.&#xA0;</p>
<!--kg-card-begin: html-->
<script>
  workflowBanner(2700, document.currentScript);
</script>
<!--kg-card-end: html-->
<h2 id="faqs">FAQs</h2><div class="kg-card kg-toggle-card" data-kg-toggle-state="close">
            <div class="kg-toggle-heading">
                <h4 class="kg-toggle-heading-text"><span style="white-space: pre-wrap;">Is ChatGPT an AI agent?</span></h4>
                <button class="kg-toggle-card-icon" aria-label="Expand toggle to read content">
                    <svg id="Regular" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                        <path class="cls-1" d="M23.25,7.311,12.53,18.03a.749.749,0,0,1-1.06,0L.75,7.311"/>
                    </svg>
                </button>
            </div>
            <div class="kg-toggle-content"><p><span style="white-space: pre-wrap;">ChatGPT is not an AI agent but rather an AI chatbot. Although it is very capable, ChatGPT is reactive, meaning that it responds to prompts but does not take action on its own as AI agents do.</span></p></div>
        </div><div class="kg-card kg-toggle-card" data-kg-toggle-state="close">
            <div class="kg-toggle-heading">
                <h4 class="kg-toggle-heading-text"><span style="white-space: pre-wrap;">Is Siri an AI agent?</span></h4>
                <button class="kg-toggle-card-icon" aria-label="Expand toggle to read content">
                    <svg id="Regular" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                        <path class="cls-1" d="M23.25,7.311,12.53,18.03a.749.749,0,0,1-1.06,0L.75,7.311"/>
                    </svg>
                </button>
            </div>
            <div class="kg-toggle-content"><p><span style="white-space: pre-wrap;">Yes, Siri can be classified as an AI agent, as it is designed to perform specific tasks, such as setting reminders, answering questions, and executing voice commands autonomously after a prompt.</span></p></div>
        </div><div class="kg-card kg-toggle-card" data-kg-toggle-state="close">
            <div class="kg-toggle-heading">
                <h4 class="kg-toggle-heading-text"><span style="white-space: pre-wrap;">Is a chatbot an AI agent?</span></h4>
                <button class="kg-toggle-card-icon" aria-label="Expand toggle to read content">
                    <svg id="Regular" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                        <path class="cls-1" d="M23.25,7.311,12.53,18.03a.749.749,0,0,1-1.06,0L.75,7.311"/>
                    </svg>
                </button>
            </div>
            <div class="kg-toggle-content"><p><span style="white-space: pre-wrap;">No, chatbots are not AI agents as they can only respond to users&#x2019; prompts without taking autonomous actions.</span></p></div>
        </div><div class="kg-card kg-toggle-card" data-kg-toggle-state="close">
            <div class="kg-toggle-heading">
                <h4 class="kg-toggle-heading-text"><span style="white-space: pre-wrap;">Is Alexa an AI agent?</span></h4>
                <button class="kg-toggle-card-icon" aria-label="Expand toggle to read content">
                    <svg id="Regular" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                        <path class="cls-1" d="M23.25,7.311,12.53,18.03a.749.749,0,0,1-1.06,0L.75,7.311"/>
                    </svg>
                </button>
            </div>
            <div class="kg-toggle-content"><p><span style="white-space: pre-wrap;">Alexa is similar to Siri so, yes, it can be classified as an AI agent. In particular, it uses AI to understand voice commands, respond to questions, and perform various tasks, such as playing music, setting alarms, and controlling smart home devices.</span></p></div>
        </div><div class="kg-card kg-toggle-card" data-kg-toggle-state="close">
            <div class="kg-toggle-heading">
                <h4 class="kg-toggle-heading-text"><span style="white-space: pre-wrap;">Are AI coding assistants AI agents?</span></h4>
                <button class="kg-toggle-card-icon" aria-label="Expand toggle to read content">
                    <svg id="Regular" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                        <path class="cls-1" d="M23.25,7.311,12.53,18.03a.749.749,0,0,1-1.06,0L.75,7.311"/>
                    </svg>
                </button>
            </div>
            <div class="kg-toggle-content"><p><span style="white-space: pre-wrap;">Yes, </span><a href="https://blog.n8n.io/ai-coding-assistants/"><u><span class="underline" style="white-space: pre-wrap;">AI coding assistants</span></u></a><span style="white-space: pre-wrap;"> can be classified as AI agents as they can interpret requests, generate code across multiple files, debug their own output, and automate coding tasks with significant autonomy. However, not all AI coding assistants are AI agents. What makes an agent is the ability to make actions on its own, and some AI coding assistants only perform static analysis, leaving you to do the final manipulation.</span></p></div>
        </div><div class="kg-card kg-toggle-card" data-kg-toggle-state="close">
            <div class="kg-toggle-heading">
                <h4 class="kg-toggle-heading-text"><span style="white-space: pre-wrap;">Are LLMs AI agents?</span></h4>
                <button class="kg-toggle-card-icon" aria-label="Expand toggle to read content">
                    <svg id="Regular" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                        <path class="cls-1" d="M23.25,7.311,12.53,18.03a.749.749,0,0,1-1.06,0L.75,7.311"/>
                    </svg>
                </button>
            </div>
            <div class="kg-toggle-content"><p><span style="white-space: pre-wrap;">No, </span><a href="https://blog.n8n.io/open-source-llm/"><u><span class="underline" style="white-space: pre-wrap;">LLMs</span></u></a><span style="white-space: pre-wrap;"> are at the core of AI agents, allowing them to understand natural language, but they are not AI agents. LLMs focus on understanding and generating human-like text based on the input they receive and, thanks to this ability, they can be used as components of AI agents.</span></p></div>
        </div><h2 id="wrap-up">Wrap up</h2><p>In this article, we discussed what AI agents are and provided the 15 best AI agents examples. In particular, we provided you with 15 n8n workflows that represent real-world examples of AI agents.</p><p>However, these are only a few possibilities among all the possible solutions provided by n8n. So, explore more and create your one AI agents:</p>
<!--kg-card-begin: html-->
<script>
  workflowBanner([3050, 3078, 3090, 28786], document.currentScript, { 
      workflowsHeader: "Workflows with AI agents powered by n8n"
  });
</script>
<!--kg-card-end: html-->
<h2 id="what%E2%80%99s-next">What&#x2019;s next?</h2><p>Expand your knowledge of AI, automation, and workflow optimization with these in-depth resources:</p><ul><li><a href="https://blog.n8n.io/best-llm-for-coding/"><u>The 20 best LLMs for coding (+ free workflow templates</u></a>): Discover the 20 best LLMs used for coding and how to leverage them with n8n.</li><li><a href="https://blog.n8n.io/open-source-llm/"><u>The best 11 open-source LLM applications</u></a>: Discover these top 11 open-source LLMs and build advanced AI workflows with n8n LangChain integration.</li><li><a href="https://blog.n8n.io/ai-agents/"><u>Building AI agents: a practical guide with real examples</u></a>: Learn how AI agents work and how they can automate complex decision-making processes.</li><li><a href="https://blog.n8n.io/ai-coding-assistants/"><u>11 best AI coding assistants: the ultimate guide in 2024</u></a>: Boost developer productivity by exploring how AI-powered coding assistants can speed up development and reduce errors.</li></ul>
<!--kg-card-begin: html-->
<div class="content-banner">
  <div>
    <h3>Create your own AI agents</h3>
    <p>Build complex automations 10x faster, without fighting APIs</p>
  </div>
  <a href="https://app.n8n.cloud/register?ref=blog.n8n.io" class="global-button blog-banner-signup">Try n8n now</a>
</div>
<!--kg-card-end: html-->
]]></content:encoded></item><item><title><![CDATA[8 best AI coding tools for developers: tested & compared!]]></title><description><![CDATA[Struggling to choose the best AI tool for coding? We tested 8 leading platforms to help you decide. Discover our top picksâ€”and see how n8n stands out by combining AI with powerful automation to streamline your development workflows!]]></description><link>https://blog.n8n.io/best-ai-for-coding/</link><guid isPermaLink="false">67d5a579e877cd0001ebf140</guid><category><![CDATA[AI]]></category><category><![CDATA[Guide]]></category><dc:creator><![CDATA[Yulia Dmitrievna]]></dc:creator><pubDate>Tue, 18 Mar 2025 12:41:24 GMT</pubDate><media:content url="https://blog.n8n.io/content/images/2025/03/11-ai-tools-coding--2---2-.png" medium="image"/><content:encoded><![CDATA[<img src="https://blog.n8n.io/content/images/2025/03/11-ai-tools-coding--2---2-.png" alt="8 best AI coding tools for developers: tested &amp; compared!"><p>Recently, we explored <a href="https://blog.n8n.io/best-llm-for-coding/"><u>the top LLMs used in modern coding tools</u></a>. While these models form the foundation of <a href="https://n8n.io/ai/?ref=blog.n8n.io"><u>AI-powered development</u></a>, you might need more than just raw LLM capabilities. Ideally, a complete, production-ready AI tool that integrates into the <a href="https://n8n.io/workflows/categories/devops/?ref=blog.n8n.io" rel="noreferrer">development workflow</a>.</p><p>We&#x2019;ve tested and reviewed 8 leading AI coding platforms, focusing on real-world development scenarios. Our evaluation examined how these AI tools for coding can increase productivity and integrate into existing development processes.</p><p>In this article, you&#x2019;ll learn:</p><ul><li>Which AI coding tools offer the best developer experience</li><li>How these platforms handle various programming tasks</li><li>Real performance insights from our hands-on testing, product reviews and user feedback</li><li>Why <a href="https://n8n.io/features/?ref=blog.n8n.io"><u>low-code platforms like n8n</u></a> are often a more reliable alternative to AI-generated code.</li></ul><h2 id="table-of-contents">Table of contents</h2><ul>
<li><a href="#how-did-we-select-the-best-ai-coding-tools-in-this-list">How did we select the best AI coding tools in this list?</a></li>
<li><a href="#what-is-the-best-ai-for-coding">What is the best AI for coding?</a>
<ul>
<li><a href="#cursor">Cursor</a></li>
<li><a href="#github-copilot">GitHub Copilot</a></li>
<li><a href="#boltnew">Bolt.new</a></li>
<li><a href="#jetbrains-ai-assistant">JetBrains AI Assistant</a></li>
<li><a href="#windsurf">Windsurf</a></li>
<li><a href="#xcode-ai-assistant">Xcode AI Assistant</a></li>
<li><a href="#cline">Cline</a></li>
<li><a href="#aider">aider</a></li>
</ul>
</li>
<li><a href="#key-takeaways-from-our-ai-coding-software-testing">Key takeaways from our AI coding software testing</a>
<ul>
<li><a href="#1-choose-tools-based-on-your-specific-needs">1. Choose tools based on your specific needs</a></li>
<li><a href="#2-consider-model-selection-and-pricing-strategy">2. Consider model selection and pricing strategy</a></li>
<li><a href="#3-context-management-matters">3. Context management matters</a></li>
<li><a href="#4-maintenance-challenges">4. Maintenance challenges</a></li>
</ul>
</li>
<li><a href="#why-low-code-platforms-often-beat-ai-generated-code">Why low-code platforms often beat AI-generated code</a></li>
<li><a href="#wrap-up">Wrap up</a></li>
<li><a href="#what%E2%80%99s-next">What&#x2019;s next?</a></li>
</ul>
<h2 id="how-did-we-select-the-best-ai-coding-tools-in-this-list">How did we select the best AI coding tools in this list?</h2><p>This is how we tested these 8 best AI tools for programming:&#xA0;</p><ul><li>Installed every tool (except Xcode16 as it requires a suitable Apple device);</li><li>Used all of them in a trial mode / free tier or with an Anthropic API key &#x2013; BYOK (Bring Your Own Code);</li><li>Tested on a sample project with approximately 30 project files in a Git repository: a Jekyll website with customized template, several external JS libraries and client-side JS scripts;</li><li>Reviewed the documentation for each tool. For Xcode AI Assistant, we additionally checked the release presentation and several external in-depth reviews.</li></ul><p>This is a summary of the best AI tools to use for coding we&#x2019;ve got:</p>
<!--kg-card-begin: html-->
<figure class="kg-card kg-video-card kg-width-wide">
<!--kg-card-end: html-->
<table>
<thead>
<tr>
<th><strong>Tool</strong></th>
<th><strong>Best for</strong></th>
<th><strong>Type</strong></th>
<th><strong>Supported LLMs</strong></th>
<th><strong>Core Features</strong></th>
<th><strong>Pricing</strong></th>
<th><strong>Unique Aspects</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#cursor">Cursor</a></td>
<td>Advanced AI coding</td>
<td>VS Code fork</td>
<td>Newest Claude 3.7<br>GPT-4<br>Custom API keys</td>
<td>Code completion<br>Chat interface<br>Multi-file context<br>Terminal<br>Image support</td>
<td>Free tier: 2K completions<br>Paid tiers from $20/mo<br>with unlimited completions</td>
<td>Composer Workspace<br>Agent mode</td>
</tr>
<tr>
<td><a href="#github-copilot">GitHub<br>Copilot</a></td>
<td>GitHub-integrated<br>development</td>
<td>Native in VS Code<br>Extensions for<br>JetBrains, Neovim, etc.<br>Web-Based UI</td>
<td>GPT-4o<br>Claude 3.5 / 3.7<br>Gemini 2.0<br>Model switching</td>
<td>Code completion<br>Chat interface<br>Multi-file context<br>Terminal<br>PR summaries<br>Web search<br>Image support</td>
<td>Free tier: 2K completions<br>$10/mo: unlimited</td>
<td>GitHub integration<br>Mobile support<br>14 core languages</td>
</tr>
<tr>
<td><a href="#boltnew">Bolt.new</a></td>
<td>Web app prototyping</td>
<td>Web-based</td>
<td>Claude 3.7</td>
<td>Code completion<br>Chat interface<br>Multi-file context<br>Terminal<br>Live preview<br>npm integration</td>
<td>Free: 150K daily tokens<br>$20/mo: higher limits</td>
<td>WebContainer tech<br>One-click deploy<br><a href="https://x.com/boltdotnew/status/1892620446106886396?ref=blog.n8n.io">Live app inspector</a><br>Native android apps</td>
</tr>
<tr>
<td><a href="#jetbrains-ai-assistant">JetBrains<br>AI Assistant</a></td>
<td>JetBrains IDE-based<br>projects and Kotlin<br>programming</td>
<td>Native integration<br>with JetBrains IDEs</td>
<td>OpenAI<br>Google<br>Anthropic<br>JetBrains Mellum<br>Local via Ollama</td>
<td>Code completion<br>Chat interface<br>Multi-file context<br>Documentation gen<br>Commit messages<br>Test generation</td>
<td>7-day trial<br>Paid tier from 10$/month<br>Requires IDE subscription</td>
<td>Cross-language conversion<br>Custom Mellum LLM<br>Focus on data privacy</td>
</tr>
<tr>
<td><a href="#windsurf">Windsurf</a></td>
<td>Research-driven<br>development</td>
<td>Standalone IDE</td>
<td>GPT-4o<br>Claude 3.5 / 3.7<br>DeepSeek-V3</td>
<td>Code completion<br>Chat interface<br>Multi-file context<br>Terminal<br>Web search<br>Image support</td>
<td>Free: Base model<br>$15/mo: credit-based</td>
<td>Advanced web search<br>Super Complete<br>Custom rules</td>
</tr>
<tr>
<td><a href="#xcode-ai-assistant">Xcode AI</a></td>
<td>Apple ecosystem<br>development</td>
<td>Native integration<br>with xcode 16</td>
<td>Local Apple<br>model</td>
<td>Code completion<br>Basic refactoring<br>SwiftUI suggestions</td>
<td>Free with Xcode 16+<br>Requires Apple Silicon</td>
<td>Offline operation<br>Privacy-focused<br>Swift/SwiftUI only</td>
</tr>
<tr>
<td><a href="#cline">Cline</a></td>
<td>Custom model<br>integration</td>
<td>VS Code extension</td>
<td>OpenRouter API<br>AWS Bedrock<br>GCP Vertex<br>Local models</td>
<td>Code completion<br>Chat interface<br>Multi-file context<br>Terminal<br>MCP server support<br>Screenshot analysis</td>
<td>Free extension<br>Pay for API usage</td>
<td>Memory Bank system<br>MCP integration</td>
</tr>
<tr>
<td><a href="#aider">aider</a></td>
<td>Git-centric<br>CLI development</td>
<td>Command Line tool<br>Browser UI (beta)</td>
<td>OpenAI<br>Anthropic<br>DeepSeek<br>Local via Ollama</td>
<td>Git operations<br>Multi-file edits<br>Terminal<br>Voice input<br>Image support<br>(local files only)<br>Web search</td>
<td>Free tool<br>Pay for API usage</td>
<td>Git-native workflow<br>Voice commands<br>Multiple edit modes</td>
</tr>
</tbody>
</table>
<p>The prices for the individual tools are very different and each has its own strengths and pitfalls:</p><ul><li><strong>Flat-rate</strong> is probably the cheapest option, but raises questions about sustainability in the long run.</li><li><strong>Credit-based</strong> pricing offers optimal cost-per-token ratio, however, it may be less transparent.</li><li><strong>Bring-your-own-API-key</strong> pricing can drive up costs very quickly, especially when working in a team.</li><li><strong>Local LLM support</strong> looks compelling but requires deployment skills for comfortable teamwork.</li></ul><h2 id="what-is-the-best-ai-for-coding">What is the best AI for coding?</h2><p>Modern AI coding platforms combine three essential components:</p><ol><li>Professional IDE capabilities: A full-featured development environment with debugging, version control, and standard coding tools.</li><li>AI interaction interface: Contextual AI assistance via chat, commands, or intelligent agents.</li><li><a href="https://n8n.io/integrations/categories/ai/?ref=blog.n8n.io"><u>Advanced LLM integration</u></a>: Powerful language models that understand both code and natural language.</li></ol><p>Many tools claim to revolutionize coding with AI, but few successfully deliver a complete package that empowers rather than disrupts established development practices.</p><p>Let&#x2019;s dive into our findings!</p><h3 id="cursor">Cursor</h3><p><strong>Use cases</strong>: Code development, refactoring, debugging and documentation in a VS Code-like environment with advanced AI capabilities</p><p><strong>Overview</strong>: <a href="https://www.cursor.com/?ref=blog.n8n.io"><u>Cursor</u></a> is an AI-first code editor built on VS Code that tightly integrates with LLMs.</p><p>While feature-rich tools like Windsurf offer similar functionality with a smoother onboarding experience, Cursor takes a more technical approach that might require some initial time to master its various modes and features.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXd7ziVlp5L_ZeJy2kjBnvVS56ir9W1tHOik-6-2l3jtlD7au9DZNE1MRtXr4ZcEptPPL5Zh8bSbUX3hZxra2lyMDCBaeA_B1ZDTHCsb_XCy25izlqfr1xjxM2p_T2jU01W2YNHC-A?key=GJkKLb4fde_5f2ejpxgwoeEz" class="kg-image" alt="8 best AI coding tools for developers: tested &amp; compared!" loading="lazy" width="602" height="333"><figcaption><span style="white-space: pre-wrap;">Cursor IDE interface showing split view with code editor and AI chat</span></figcaption></figure><p><strong>Key features:</strong></p>
<ol>
<li>Intelligent code assistance:
<ul>
<li>AI-powered code completion with context awareness</li>
<li>Natural language chat for code explanations and debugging</li>
<li>Inline code edits using natural language prompts</li>
<li>Intelligent codebase indexing for better suggestions</li>
<li>Support for images and screenshots</li>
</ul>
</li>
<li>Multiple AI interaction modes:
<ul>
<li>Standard editor with AI tab commands</li>
<li>Interactive chat interface</li>
<li>Composer workspace for complex code generation</li>
<li>Agent mode for automated problem-solving</li>
</ul>
</li>
<li>Advanced development tools:
<ul>
<li>Terminal commands generation</li>
<li>Automated test generation</li>
<li>Documentation writing</li>
<li>Multi-file refactoring</li>
<li>Custom rules for AI behavior</li>
</ul>
</li>
<li>Model flexibility:
<ul>
<li>Built-in support for Claude 3.5 Sonnet and GPT-4</li>
<li>Option to add custom API keys</li>
<li>Privacy mode for sensitive code in the Business plan</li>
</ul>
</li>
</ol>
<p><strong>Pricing</strong>:</p><ul><li>Free tier: 2,000 completions, 50 premium requests</li><li>Paid tiers from $20/month: Unlimited completions, 500 quick premium requests</li></ul><h3 id="github-copilot">GitHub Copilot</h3><p><strong>Use cases</strong>: Real-time code support, pair programming, code review, documentation generation and debugging across multiple development environments</p><p><strong>Overview</strong>: <a href="https://github.com/features/copilot?ref=blog.n8n.io"><u>GitHub Copilot</u></a> is an AI pair programmer tool developed by GitHub and OpenAI. It combines real-time code suggestions with interactive chat capabilities, including web search support, image upload, voice entry and others.</p><p>Unlike other AI coding assistants, Copilot is deeply integrated with the GitHub ecosystem and supports multiple development environments.</p><figure class="kg-card kg-video-card kg-width-regular kg-card-hascaption" data-kg-thumbnail="https://blog.n8n.io/content/media/2025/03/02-copilot_thumb.jpg" data-kg-custom-thumbnail>
            <div class="kg-video-container">
                <video src="https://blog.n8n.io/content/media/2025/03/02-copilot.mp4" poster="https://img.spacergif.org/v1/2496x1474/0a/spacer.png" width="2496" height="1474" playsinline preload="metadata" style="background: transparent url(&apos;https://blog.n8n.io/content/media/2025/03/02-copilot_thumb.jpg&apos;) 50% 50% / cover no-repeat;"></video>
                <div class="kg-video-overlay">
                    <button class="kg-video-large-play-icon" aria-label="Play video">
                        <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                            <path d="M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z"/>
                        </svg>
                    </button>
                </div>
                <div class="kg-video-player-container">
                    <div class="kg-video-player">
                        <button class="kg-video-play-icon" aria-label="Play video">
                            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                                <path d="M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z"/>
                            </svg>
                        </button>
                        <button class="kg-video-pause-icon kg-video-hide" aria-label="Pause video">
                            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                                <rect x="3" y="1" width="7" height="22" rx="1.5" ry="1.5"/>
                                <rect x="14" y="1" width="7" height="22" rx="1.5" ry="1.5"/>
                            </svg>
                        </button>
                        <span class="kg-video-current-time">0:00</span>
                        <div class="kg-video-time">
                            /<span class="kg-video-duration">0:08</span>
                        </div>
                        <input type="range" class="kg-video-seek-slider" max="100" value="0">
                        <button class="kg-video-playback-rate" aria-label="Adjust playback speed">1&#xD7;</button>
                        <button class="kg-video-unmute-icon" aria-label="Unmute">
                            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                                <path d="M15.189 2.021a9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h1.794a.249.249 0 0 1 .221.133 9.73 9.73 0 0 0 7.924 4.85h.06a1 1 0 0 0 1-1V3.02a1 1 0 0 0-1.06-.998Z"/>
                            </svg>
                        </button>
                        <button class="kg-video-mute-icon kg-video-hide" aria-label="Mute">
                            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                                <path d="M16.177 4.3a.248.248 0 0 0 .073-.176v-1.1a1 1 0 0 0-1.061-1 9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h.114a.251.251 0 0 0 .177-.073ZM23.707 1.706A1 1 0 0 0 22.293.292l-22 22a1 1 0 0 0 0 1.414l.009.009a1 1 0 0 0 1.405-.009l6.63-6.631A.251.251 0 0 1 8.515 17a.245.245 0 0 1 .177.075 10.081 10.081 0 0 0 6.5 2.92 1 1 0 0 0 1.061-1V9.266a.247.247 0 0 1 .073-.176Z"/>
                            </svg>
                        </button>
                        <input type="range" class="kg-video-volume-slider" max="100" value="100">
                    </div>
                </div>
            </div>
            <figcaption><p><span style="white-space: pre-wrap;">GitHub Copilot interface demonstrating code suggestions and chat panel</span></p></figcaption>
        </figure><p><strong>Key features:</strong></p>
<ol>
<li>Intelligent code generation:
<ul>
<li>Context-aware code completion</li>
<li>Multiple suggestion alternatives</li>
<li>Next edit prediction</li>
<li>Support for 14 programming languages</li>
<li>Automated test generation</li>
<li>Documentation writing assistance</li>
</ul>
</li>
<li>Interactive development support:
<ul>
<li>Copilot Chat for code explanations</li>
<li>Debugging assistance</li>
<li>Security remediation suggestions</li>
<li>Command generation for CLI</li>
<li>Pull request summaries</li>
<li>Code review assistance</li>
</ul>
</li>
<li>Multi-environment integration:
<ul>
<li>Natively supported in VS Code</li>
<li>JetBrains IDEs</li>
<li>Neovim, Xcode</li>
<li>Azure Data Studio, Visual Studio</li>
<li>GitHub.com Web and GitHub Mobile</li>
<li>Windows Terminal &amp; Github CLI</li>
</ul>
</li>
<li>Enterprise features:
<ul>
<li>Knowledge base integration</li>
<li>Custom model fine-tuning</li>
<li>Policy management &amp; security features</li>
<li>Content exclusion controls</li>
</ul>
</li>
<li>AI model flexibility:
<ul>
<li>GPT-4o (default)</li>
<li>Claude 3.5 Sonnet</li>
<li>Gemini 2.0 Flash</li>
<li>OpenAI o1 and o3-mini</li>
<li>Model switching in chat interface</li>
</ul>
</li>
</ol>
<p><strong>Pricing</strong>:</p><ul><li>Free: 2,000 completions, 50 chat messages per month</li><li>Special free versions for verified students, teachers and maintainers of popular open-source projects</li><li>Paid tiers start at $10/month: Unlimited usage, all models</li></ul><h3 id="boltnew">Bolt.new</h3><p><strong>Use cases</strong>: Full-stack web application development, rapid prototyping and AI-powered coding in a browser-based environment</p><p><strong>Overview</strong>: <a href="https://bolt.new/?ref=blog.n8n.io"><u>Bolt.new</u></a> is a browser-based AI development environment powered by WebContainers technology. It combines the convenience of cloud IDEs with powerful AI support to help developers build and deploy web applications through natural language interaction.</p><p>While most other AIs for Coding offer more customization options, Bolt.new provides a straightforward, zero-setup experience that&#x2019;s particularly effective for web development projects. The platform supports popular JavaScript frameworks such as React, Vue, Angular, Svelte and others. With the recent support of Expo framework, Bolt.new users can also create native Android apps too.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXcjgldiGhfkmFIJJqCaT6LdbUMt6a0eeiGJohZuBmQdjWWx0s3-mJGlYgESXhBI8siOHS34XNAZXDFthgnWVicw3RmZPYzqqKaGGu_E1C17DaQDHyCYq4XHVyGHc8eUqMrrXf9WFw?key=GJkKLb4fde_5f2ejpxgwoeEz" class="kg-image" alt="8 best AI coding tools for developers: tested &amp; compared!" loading="lazy" width="602" height="361"><figcaption><span style="white-space: pre-wrap;">Bolt.new browser-based coding AI tools with split view, code editor and AI chat for rapid web development</span></figcaption></figure><p><strong>Key features:</strong></p>
<ol>
<li>AI development environment:
<ul>
<li>Natural language code generation and editing</li>
<li>Npm packages installation right in the browser</li>
<li>Real-time preview with hot reload</li>
<li>Built-in file system management</li>
<li>Multi-file context understanding</li>
<li>Integrated terminal</li>
</ul>
</li>
<li>Project management:
<ul>
<li>One-click Netlify deployment</li>
<li>Project versioning and rollbacks</li>
<li>File locking and targeting</li>
<li>Customizable project templates</li>
<li>GitHub repository import</li>
</ul>
</li>
<li>Collaboration tools:
<ul>
<li>Shareable project links</li>
<li>Team workspaces</li>
<li>Project history tracking</li>
<li>Chat history preservation</li>
<li>Export to StackBlitz</li>
</ul>
</li>
<li>AI integration:
<ul>
<li>Powered by Claude 3.5 Sonnet</li>
<li>Context-aware code suggestions</li>
<li>Error detection and fixing</li>
<li>Custom system prompts</li>
<li>Token usage optimization</li>
</ul>
</li>
</ol>
<p><strong>Pricing</strong>:</p><ul><li>Free tier: 150K daily tokens, 1M monthly tokens</li><li>Paid tiers start from $20/month</li><li>Enterprise plans available</li></ul><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text">If you&#x2019;re looking for an open-source alternative, check out <a href="https://github.com/stackblitz-labs/bolt.diy?ref=blog.n8n.io"><u>bolt.diy</u></a>, a community-driven project that allows you to run your own instance of Bolt with custom LLM backends and full control over your development environment.</div></div><h3 id="jetbrains-ai-assistant">JetBrains AI Assistant</h3><p><strong>Use cases</strong>: AI-powered development in JetBrains IDEs, code generation and refactoring, documentation writing and intelligent code completion</p><p><strong>Overview</strong>: <a href="https://www.jetbrains.com/ai/?ref=blog.n8n.io"><u>JetBrains AI Assistant</u></a> integrates AI capabilities directly into multiple JetBrains professional IDEs, including IntelliJ IDEA and PyCharm.</p><p>While tools like GitHub Copilot offer IDE-agnostic solutions, JetBrains AI Assistant provides deeper integration with JetBrains IDEs, supports in-house coding LLM Mellum and has direct access to JetBrains documentation.</p><figure class="kg-card kg-video-card kg-width-regular kg-card-hascaption" data-kg-thumbnail="https://blog.n8n.io/content/media/2025/03/04-jetbrains-ai_thumb.jpg" data-kg-custom-thumbnail>
            <div class="kg-video-container">
                <video src="https://blog.n8n.io/content/media/2025/03/04-jetbrains-ai.mp4" poster="https://img.spacergif.org/v1/1920x1080/0a/spacer.png" width="1920" height="1080" playsinline preload="metadata" style="background: transparent url(&apos;https://blog.n8n.io/content/media/2025/03/04-jetbrains-ai_thumb.jpg&apos;) 50% 50% / cover no-repeat;"></video>
                <div class="kg-video-overlay">
                    <button class="kg-video-large-play-icon" aria-label="Play video">
                        <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                            <path d="M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z"/>
                        </svg>
                    </button>
                </div>
                <div class="kg-video-player-container">
                    <div class="kg-video-player">
                        <button class="kg-video-play-icon" aria-label="Play video">
                            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                                <path d="M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z"/>
                            </svg>
                        </button>
                        <button class="kg-video-pause-icon kg-video-hide" aria-label="Pause video">
                            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                                <rect x="3" y="1" width="7" height="22" rx="1.5" ry="1.5"/>
                                <rect x="14" y="1" width="7" height="22" rx="1.5" ry="1.5"/>
                            </svg>
                        </button>
                        <span class="kg-video-current-time">0:00</span>
                        <div class="kg-video-time">
                            /<span class="kg-video-duration">0:12</span>
                        </div>
                        <input type="range" class="kg-video-seek-slider" max="100" value="0">
                        <button class="kg-video-playback-rate" aria-label="Adjust playback speed">1&#xD7;</button>
                        <button class="kg-video-unmute-icon" aria-label="Unmute">
                            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                                <path d="M15.189 2.021a9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h1.794a.249.249 0 0 1 .221.133 9.73 9.73 0 0 0 7.924 4.85h.06a1 1 0 0 0 1-1V3.02a1 1 0 0 0-1.06-.998Z"/>
                            </svg>
                        </button>
                        <button class="kg-video-mute-icon kg-video-hide" aria-label="Mute">
                            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                                <path d="M16.177 4.3a.248.248 0 0 0 .073-.176v-1.1a1 1 0 0 0-1.061-1 9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h.114a.251.251 0 0 0 .177-.073ZM23.707 1.706A1 1 0 0 0 22.293.292l-22 22a1 1 0 0 0 0 1.414l.009.009a1 1 0 0 0 1.405-.009l6.63-6.631A.251.251 0 0 1 8.515 17a.245.245 0 0 1 .177.075 10.081 10.081 0 0 0 6.5 2.92 1 1 0 0 0 1.061-1V9.266a.247.247 0 0 1 .073-.176Z"/>
                            </svg>
                        </button>
                        <input type="range" class="kg-video-volume-slider" max="100" value="100">
                    </div>
                </div>
            </div>
            <figcaption><p><span style="white-space: pre-wrap;">JetBrains AI Assistant interface integrated within JetBrains IDE</span></p></figcaption>
        </figure><p><strong>Key features:</strong></p>
<ol>
<li>IDE integration and code understanding:
<ul>
<li>Supports most of the JetBrains IDEs</li>
<li>Context-aware code completion and generation</li>
<li>Natural language chat interface</li>
<li>Project-wide code analysis</li>
<li>Direct editor actions for AI support</li>
</ul>
</li>
<li>AI-powered development tools:
<ul>
<li>Advanced code completion with multiple models</li>
<li>Local models support via Ollama</li>
<li>Documentation, Commit message and test generation</li>
<li>Terminal command suggestions</li>
<li>Cross-language file conversion</li>
</ul>
</li>
<li>Multiple interaction methods:
<ul>
<li>Chat window for general queries</li>
<li>Editor context menu actions</li>
<li>Inline AI prompts</li>
<li>File-wide code generation</li>
<li>Refactoring suggestions</li>
</ul>
</li>
<li>Model selection and privacy:
<ul>
<li>OpenAI, Google</li>
<li>Anthropic Claude (via AWS Bedrock)</li>
<li>JetBrains Mellum model</li>
<li>Local model support via Ollama</li>
</ul>
</li>
</ol>
<p><strong>Pricing:</strong></p><ul><li>7-day free trial</li><li>AI-Assistant subscription starts at10$/month</li><li>Requires paid JetBrains IDE subscription</li><li>Enterprise plans available</li></ul><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text">JetBrains recently announced <a href="https://www.jetbrains.com/junie/?ref=blog.n8n.io"><u>Junie</u></a>, a new AI coding agent focused on task delegation and code quality verification. Currently in Early Access for IntelliJ IDEA Ultimate and PyCharm Professional.</div></div><h3 id="windsurf">Windsurf</h3><p><strong>Use cases</strong>: Full-featured AI-native IDE for coding, debugging and project management</p><p><strong>Overview</strong>: <a href="https://codeium.com/windsurf?ref=blog.n8n.io"><u>Windsurf</u></a> is the next generation of Codeium&apos;s AI IDE designed to maintain developer flow. It combines traditional IDE features with advanced AI capabilities through its Cascade AI assistant. Unlike previous Codeium extensions for popular IDEs, Windsurf provides a fully integrated development environment optimized for AI-powered coding.</p><figure class="kg-card kg-video-card kg-width-regular kg-card-hascaption" data-kg-thumbnail="https://blog.n8n.io/content/media/2025/03/05-windsurf_thumb.jpg" data-kg-custom-thumbnail>
            <div class="kg-video-container">
                <video src="https://blog.n8n.io/content/media/2025/03/05-windsurf.mp4" poster="https://img.spacergif.org/v1/1920x1192/0a/spacer.png" width="1920" height="1192" playsinline preload="metadata" style="background: transparent url(&apos;https://blog.n8n.io/content/media/2025/03/05-windsurf_thumb.jpg&apos;) 50% 50% / cover no-repeat;"></video>
                <div class="kg-video-overlay">
                    <button class="kg-video-large-play-icon" aria-label="Play video">
                        <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                            <path d="M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z"/>
                        </svg>
                    </button>
                </div>
                <div class="kg-video-player-container">
                    <div class="kg-video-player">
                        <button class="kg-video-play-icon" aria-label="Play video">
                            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                                <path d="M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z"/>
                            </svg>
                        </button>
                        <button class="kg-video-pause-icon kg-video-hide" aria-label="Pause video">
                            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                                <rect x="3" y="1" width="7" height="22" rx="1.5" ry="1.5"/>
                                <rect x="14" y="1" width="7" height="22" rx="1.5" ry="1.5"/>
                            </svg>
                        </button>
                        <span class="kg-video-current-time">0:00</span>
                        <div class="kg-video-time">
                            /<span class="kg-video-duration">0:30</span>
                        </div>
                        <input type="range" class="kg-video-seek-slider" max="100" value="0">
                        <button class="kg-video-playback-rate" aria-label="Adjust playback speed">1&#xD7;</button>
                        <button class="kg-video-unmute-icon" aria-label="Unmute">
                            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                                <path d="M15.189 2.021a9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h1.794a.249.249 0 0 1 .221.133 9.73 9.73 0 0 0 7.924 4.85h.06a1 1 0 0 0 1-1V3.02a1 1 0 0 0-1.06-.998Z"/>
                            </svg>
                        </button>
                        <button class="kg-video-mute-icon kg-video-hide" aria-label="Mute">
                            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                                <path d="M16.177 4.3a.248.248 0 0 0 .073-.176v-1.1a1 1 0 0 0-1.061-1 9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h.114a.251.251 0 0 0 .177-.073ZM23.707 1.706A1 1 0 0 0 22.293.292l-22 22a1 1 0 0 0 0 1.414l.009.009a1 1 0 0 0 1.405-.009l6.63-6.631A.251.251 0 0 1 8.515 17a.245.245 0 0 1 .177.075 10.081 10.081 0 0 0 6.5 2.92 1 1 0 0 0 1.061-1V9.266a.247.247 0 0 1 .073-.176Z"/>
                            </svg>
                        </button>
                        <input type="range" class="kg-video-volume-slider" max="100" value="100">
                    </div>
                </div>
            </div>
            <figcaption><p><span style="white-space: pre-wrap;">Windsurf IDE interface showcasing Cascade AI assistant</span></p></figcaption>
        </figure><p><strong>Key features:</strong></p>
<ol>
<li>Cascade AI Assistant:
<ul>
<li>Several LLMs available (GPT-4o, Claude 3.5 Sonnet, DeepSeek-V3, etc.)</li>
<li>Collaboration with AI in real time</li>
<li>Context-aware code understanding</li>
<li>Terminal integration and package management</li>
<li>Image support for GPT-4o and Claude 3.5 Sonnet (drag &amp; drop or paste screenshots)</li>
</ul>
</li>
<li>Development environment:
<ul>
<li>Full IDE capabilities via the forked VS Code editor</li>
<li>Git integration</li>
<li>Multi-language support</li>
<li>SSH and Dev Container support (beta)</li>
<li>Web search to load external pages into the Cascade&#x2019;s context</li>
</ul>
</li>
<li>AI workflow features:
<ul>
<li>Autocomplete and Super Complete: predict the next text at the cursor position vs. predict the intent in the current source code file</li>
<li>Natural language commands</li>
<li>Code explanations and refactoring</li>
<li>Project-wide context awareness</li>
<li>Custom rules and memories system</li>
</ul>
</li>
</ol>
<p><strong>Pricing</strong>:</p><ul><li>Free: Limited access with Cascade Base model</li><li>Paid tiers starting at $15/month, credit-based usage system.</li></ul><h3 id="xcode-ai-assistant">Xcode AI Assistant</h3><p><strong>Use cases</strong>: Swift development for iOS/macOS, basic code completion and generation using natural language prompts and a custom local LLM.</p><p><strong>Overview</strong>: <a href="https://developer.apple.com/videos/play/wwdc2024/10135/?time=33&amp;ref=blog.n8n.io"><u>Xcode&#x2019;s AI features</u></a> are Apple&#x2019;s first step into AI-powered development, introduced with Xcode 16. It&#x2019;s a built-in solution running on custom local models optimized for the Apple development ecosystem.</p><p>While the assistant excels at basic Swift and SwiftUI tasks, developers who need more comprehensive AI support might want to consider Xcode extensions such as GitHub Copilot or Codeium that offer broader language support and advanced features.</p><figure class="kg-card kg-video-card kg-width-regular kg-card-hascaption" data-kg-thumbnail="https://blog.n8n.io/content/media/2025/03/06-Xcode_optimized_thumb.jpg" data-kg-custom-thumbnail>
            <div class="kg-video-container">
                <video src="https://blog.n8n.io/content/media/2025/03/06-Xcode_optimized.mp4" poster="https://img.spacergif.org/v1/1920x1080/0a/spacer.png" width="1920" height="1080" playsinline preload="metadata" style="background: transparent url(&apos;https://blog.n8n.io/content/media/2025/03/06-Xcode_optimized_thumb.jpg&apos;) 50% 50% / cover no-repeat;"></video>
                <div class="kg-video-overlay">
                    <button class="kg-video-large-play-icon" aria-label="Play video">
                        <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                            <path d="M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z"/>
                        </svg>
                    </button>
                </div>
                <div class="kg-video-player-container">
                    <div class="kg-video-player">
                        <button class="kg-video-play-icon" aria-label="Play video">
                            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                                <path d="M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z"/>
                            </svg>
                        </button>
                        <button class="kg-video-pause-icon kg-video-hide" aria-label="Pause video">
                            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                                <rect x="3" y="1" width="7" height="22" rx="1.5" ry="1.5"/>
                                <rect x="14" y="1" width="7" height="22" rx="1.5" ry="1.5"/>
                            </svg>
                        </button>
                        <span class="kg-video-current-time">0:00</span>
                        <div class="kg-video-time">
                            /<span class="kg-video-duration">0:19</span>
                        </div>
                        <input type="range" class="kg-video-seek-slider" max="100" value="0">
                        <button class="kg-video-playback-rate" aria-label="Adjust playback speed">1&#xD7;</button>
                        <button class="kg-video-unmute-icon" aria-label="Unmute">
                            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                                <path d="M15.189 2.021a9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h1.794a.249.249 0 0 1 .221.133 9.73 9.73 0 0 0 7.924 4.85h.06a1 1 0 0 0 1-1V3.02a1 1 0 0 0-1.06-.998Z"/>
                            </svg>
                        </button>
                        <button class="kg-video-mute-icon kg-video-hide" aria-label="Mute">
                            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                                <path d="M16.177 4.3a.248.248 0 0 0 .073-.176v-1.1a1 1 0 0 0-1.061-1 9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h.114a.251.251 0 0 0 .177-.073ZM23.707 1.706A1 1 0 0 0 22.293.292l-22 22a1 1 0 0 0 0 1.414l.009.009a1 1 0 0 0 1.405-.009l6.63-6.631A.251.251 0 0 1 8.515 17a.245.245 0 0 1 .177.075 10.081 10.081 0 0 0 6.5 2.92 1 1 0 0 0 1.061-1V9.266a.247.247 0 0 1 .073-.176Z"/>
                            </svg>
                        </button>
                        <input type="range" class="kg-video-volume-slider" max="100" value="100">
                    </div>
                </div>
            </div>
            <figcaption><p><span style="white-space: pre-wrap;">Xcode AI coding assistant for Swift developers</span></p></figcaption>
        </figure><p><strong>Key features:</strong></p>
<ol>
<li>Native integration:
<ul>
<li>Built-in code completion powered by local AI models</li>
<li>Optimized for Apple Silicon processors</li>
<li>Deep integration with Swift and SwiftUI</li>
<li>No setup or configuration required</li>
</ul>
</li>
<li>Code generation capabilities:
<ul>
<li>Boilerplate code generation</li>
<li>Preview data creation</li>
<li>Basic implementation suggestions</li>
<li>Comment-driven code generation</li>
</ul>
</li>
<li>Context-aware features:
<ul>
<li>Understanding the existing codebase</li>
<li>Pattern recognition for similar code blocks</li>
<li>SwiftUI view structure suggestions</li>
<li>Basic refactoring suggestions</li>
</ul>
</li>
<li>Privacy-first approach:
<ul>
<li>Local model execution</li>
<li>No code sharing with external services</li>
<li>Offline operation support</li>
<li>Built-in security features</li>
</ul>
</li>
</ol>
<p><strong>Pricing</strong>:</p><ul><li>Free: Included in Xcode 16+</li><li>Requirements: Apple Silicon Mac</li><li>Extensions: Additional costs may apply for third-party AI extensions</li></ul><h3 id="cline">Cline</h3><p><strong>Use cases</strong>: AI-powered coding assistant with a focus on tool integration and project context management</p><p><strong>Overview</strong>: <a href="https://cline.bot/?ref=blog.n8n.io"><u>Cline</u></a> is a VS Code extension that combines IDE capabilities with AI support. Unlike simple code completion tools, Cline maintains the project context and offers a set of development tools through its Plan and Act modes.</p><figure class="kg-card kg-video-card kg-width-regular kg-card-hascaption" data-kg-thumbnail="https://blog.n8n.io/content/media/2025/03/07-cline_optimized_thumb.jpg" data-kg-custom-thumbnail>
            <div class="kg-video-container">
                <video src="https://blog.n8n.io/content/media/2025/03/07-cline_optimized.mp4" poster="https://img.spacergif.org/v1/1596x1080/0a/spacer.png" width="1596" height="1080" playsinline preload="metadata" style="background: transparent url(&apos;https://blog.n8n.io/content/media/2025/03/07-cline_optimized_thumb.jpg&apos;) 50% 50% / cover no-repeat;"></video>
                <div class="kg-video-overlay">
                    <button class="kg-video-large-play-icon" aria-label="Play video">
                        <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                            <path d="M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z"/>
                        </svg>
                    </button>
                </div>
                <div class="kg-video-player-container">
                    <div class="kg-video-player">
                        <button class="kg-video-play-icon" aria-label="Play video">
                            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                                <path d="M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z"/>
                            </svg>
                        </button>
                        <button class="kg-video-pause-icon kg-video-hide" aria-label="Pause video">
                            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                                <rect x="3" y="1" width="7" height="22" rx="1.5" ry="1.5"/>
                                <rect x="14" y="1" width="7" height="22" rx="1.5" ry="1.5"/>
                            </svg>
                        </button>
                        <span class="kg-video-current-time">0:00</span>
                        <div class="kg-video-time">
                            /<span class="kg-video-duration">0:29</span>
                        </div>
                        <input type="range" class="kg-video-seek-slider" max="100" value="0">
                        <button class="kg-video-playback-rate" aria-label="Adjust playback speed">1&#xD7;</button>
                        <button class="kg-video-unmute-icon" aria-label="Unmute">
                            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                                <path d="M15.189 2.021a9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h1.794a.249.249 0 0 1 .221.133 9.73 9.73 0 0 0 7.924 4.85h.06a1 1 0 0 0 1-1V3.02a1 1 0 0 0-1.06-.998Z"/>
                            </svg>
                        </button>
                        <button class="kg-video-mute-icon kg-video-hide" aria-label="Mute">
                            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                                <path d="M16.177 4.3a.248.248 0 0 0 .073-.176v-1.1a1 1 0 0 0-1.061-1 9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h.114a.251.251 0 0 0 .177-.073ZM23.707 1.706A1 1 0 0 0 22.293.292l-22 22a1 1 0 0 0 0 1.414l.009.009a1 1 0 0 0 1.405-.009l6.63-6.631A.251.251 0 0 1 8.515 17a.245.245 0 0 1 .177.075 10.081 10.081 0 0 0 6.5 2.92 1 1 0 0 0 1.061-1V9.266a.247.247 0 0 1 .073-.176Z"/>
                            </svg>
                        </button>
                        <input type="range" class="kg-video-volume-slider" max="100" value="100">
                    </div>
                </div>
            </div>
            <figcaption><p><span style="white-space: pre-wrap;">Cline: VS Code extension for AI-powered coding</span></p></figcaption>
        </figure><p><strong>Key features:</strong></p>
<ol>
<li>Context management:
<ul>
<li>Memory bank system to maintain project knowledge across sessions</li>
<li>Support for multiple file context windows</li>
<li>Project-specific rules through .clinerules files</li>
</ul>
</li>
<li>Development tools:
<ul>
<li>File operations (create, edit, search)</li>
<li>Terminal command execution</li>
<li>Checkpoint system for safe experimentation</li>
<li>MCP server integration for extended capabilities</li>
<li>Screenshot analysis for UI troubleshooting</li>
</ul>
</li>
<li>Flexible model selection:
<ul>
<li>Support for cloud services via Openrouter API (Claude, DeepSeek, Gemini)</li>
<li>Custom configurations for AWS Bedrock and GCP Vertex AI</li>
<li>Local model options through Ollama or LM Studio</li>
</ul>
</li>
</ol>
<p><strong>Pricing</strong>:</p><ul><li>Free: Core VS Code extension</li><li>Paid: Cloud model usage based on the selected provider (OpenRouter, AWS Bedrock, etc.)</li></ul><h3 id="aider">aider</h3><p><strong>Use cases</strong>: local development, Git repository management, AI pair programming in the terminal</p><p><strong>Overview</strong>: <a href="https://aider.chat/?ref=blog.n8n.io"><u>aider</u></a> is a unique open-source command-line tool that turns your terminal into an AI pair programming environment.</p><p>Unlike most AI coding assistants that operate within IDEs, aider works directly with your local Git repositories, providing a powerful combination of AI assistance and version control.</p><p>In addition to the CLI interface, aider has two working modes. It can silently watch source code files and start working as soon as a special comment line is entered. An experimental browser UI is also available.</p><figure class="kg-card kg-video-card kg-width-regular kg-card-hascaption" data-kg-thumbnail="https://blog.n8n.io/content/media/2025/03/08-aider_optimized_thumb.jpg" data-kg-custom-thumbnail>
            <div class="kg-video-container">
                <video src="https://blog.n8n.io/content/media/2025/03/08-aider_optimized.mp4" poster="https://img.spacergif.org/v1/1328x1080/0a/spacer.png" width="1328" height="1080" playsinline preload="metadata" style="background: transparent url(&apos;https://blog.n8n.io/content/media/2025/03/08-aider_optimized_thumb.jpg&apos;) 50% 50% / cover no-repeat;"></video>
                <div class="kg-video-overlay">
                    <button class="kg-video-large-play-icon" aria-label="Play video">
                        <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                            <path d="M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z"/>
                        </svg>
                    </button>
                </div>
                <div class="kg-video-player-container">
                    <div class="kg-video-player">
                        <button class="kg-video-play-icon" aria-label="Play video">
                            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                                <path d="M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z"/>
                            </svg>
                        </button>
                        <button class="kg-video-pause-icon kg-video-hide" aria-label="Pause video">
                            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                                <rect x="3" y="1" width="7" height="22" rx="1.5" ry="1.5"/>
                                <rect x="14" y="1" width="7" height="22" rx="1.5" ry="1.5"/>
                            </svg>
                        </button>
                        <span class="kg-video-current-time">0:00</span>
                        <div class="kg-video-time">
                            /<span class="kg-video-duration">1:04</span>
                        </div>
                        <input type="range" class="kg-video-seek-slider" max="100" value="0">
                        <button class="kg-video-playback-rate" aria-label="Adjust playback speed">1&#xD7;</button>
                        <button class="kg-video-unmute-icon" aria-label="Unmute">
                            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                                <path d="M15.189 2.021a9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h1.794a.249.249 0 0 1 .221.133 9.73 9.73 0 0 0 7.924 4.85h.06a1 1 0 0 0 1-1V3.02a1 1 0 0 0-1.06-.998Z"/>
                            </svg>
                        </button>
                        <button class="kg-video-mute-icon kg-video-hide" aria-label="Mute">
                            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                                <path d="M16.177 4.3a.248.248 0 0 0 .073-.176v-1.1a1 1 0 0 0-1.061-1 9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h.114a.251.251 0 0 0 .177-.073ZM23.707 1.706A1 1 0 0 0 22.293.292l-22 22a1 1 0 0 0 0 1.414l.009.009a1 1 0 0 0 1.405-.009l6.63-6.631A.251.251 0 0 1 8.515 17a.245.245 0 0 1 .177.075 10.081 10.081 0 0 0 6.5 2.92 1 1 0 0 0 1.061-1V9.266a.247.247 0 0 1 .073-.176Z"/>
                            </svg>
                        </button>
                        <input type="range" class="kg-video-volume-slider" max="100" value="100">
                    </div>
                </div>
            </div>
            <figcaption><p><span style="white-space: pre-wrap;">aider: Command-line AI coding tool for programmers</span></p></figcaption>
        </figure><p><strong>Key features:</strong></p>
<ol>
<li>Git-native workflow:
<ul>
<li>Automatic local git commits with descriptive messages</li>
<li>Built-in commands for diff review and change management</li>
<li>Integration with existing repositories: just start aider in the repo folder</li>
</ul>
</li>
<li>Advanced context management:
<ul>
<li>Repository mapping using tree-sitter</li>
<li>Multi-file editing support</li>
<li>Web search integration with <code>/web</code> command</li>
<li>Multimodal support for images (local files)</li>
</ul>
</li>
<li>Multiple operation modes:
<ul>
<li>Code mode for direct changes</li>
<li>Architect mode for planning before implementation</li>
<li>Different &quot;editing formats&quot;: whole file edits or diff-like changes</li>
<li>Ask mode for codebase exploration</li>
<li>Help mode for tool assistance</li>
<li>Voice input support</li>
</ul>
</li>
<li>Developer-friendly customization:
<ul>
<li>Extensive command-line options</li>
<li>Support for customised linting and testing</li>
<li>Configuration via files</li>
<li>Can be scripted via command line or Python</li>
</ul>
</li>
</ol>
<p><strong>Pricing</strong>:</p><ul><li>Open-source: free to use</li><li>Requires API keys for LLMs:<ul><li>Works with various providers (OpenAI, Anthropic, DeepSeek)</li><li>Supports local models through Ollama</li><li>Works with most OpenAI-API-compatible services</li></ul></li></ul><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text">aider is not the only CLI tool for coding. Anthropic has released an early version of the <a href="https://docs.anthropic.com/en/docs/agents-and-tools/claude-code/overview?ref=blog.n8n.io"><u>open-source Claude Code</u></a>. This agentic coding tool helps with common programming tasks, but the usability and installation process is less polished compared to aider.</div></div><h2 id="key-takeaways-from-testing-ai-coding-software">Key takeaways from testing AI coding software</h2><p>After thoroughly testing various AI coding platforms, here are our main findings to help you make an informed decision:</p><h3 id="1-choose-tools-based-on-your-specific-needs">1. Choose tools based on your specific needs</h3><p>There&#x2019;s no universal AI coding assistant that works perfectly for every scenario. Each tool has its own strengths:</p><ul><li>Language-specific solutions (e.g. AI assistant for JetBrains IDEs)</li><li>Tech stack specialization (Xcode&#x2019;s AI features for Swift, bolt.new for JS frameworks)</li><li>General-purpose coding assistants (GitHub Copilot, Cursor, Windsurf, Cline, aider)</li></ul><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text">We recommend testing several tools that align with your programming language and project types before settling on one, the most suitable solution.</div></div><h3 id="2-consider-model-selection-and-pricing-strategy">2. Consider model selection and pricing strategy</h3><p>We identified two different approaches to LLM integration:</p><p>Pre-selected models with flat-rate pricing:</p><ul><li>Optimized integration with specific models</li><li>Often suggests discounted token usage</li><li>More predictable monthly costs</li><li>Potential privacy considerations with cloud-only solutions</li></ul><p>Flexible model selection:</p><ul><li>Freedom to use your own API keys</li><li>Option to run local models</li><li>More control over data privacy</li><li>Requires expertise in model selection</li><li>Higher per-token costs for cloud models</li></ul><h3 id="3-context-management-matters">3. Context management matters</h3><p>Different tools handle project context in various ways:</p><ul><li>Project-wide analysis (i.e. aider&#x2019;s <a href="https://aider.chat/docs/repomap.html?ref=blog.n8n.io"><u>repository map</u></a>)</li><li>Multi-file in context (supported by most tools)</li><li>Customizable prompts (i.e. Cursor rules)</li><li>Built-in web-search (i.e. Windsurf)</li></ul><p>How a tool manages context greatly affects its effectiveness in understanding and modifying your codebase.</p><h3 id="4-maintenance-challenges">4. Maintenance challenges</h3><p>Our research has identified different types of maintenance challenges depending on the developer&apos;s experience.</p><p>For experienced developers, coding AI tools present specific technical hurdles:</p><ul><li>Inconsistent naming conventions in the generated code</li><li>Outdated patterns that don&#x2019;t reflect the latest language features</li><li>Framework-specific best practices are being overlooked without explicit prompting</li><li>Integration challenges with existing codebases (i.e. unexpectedly deleted blocks of code)</li></ul><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXcdGWgd3gTwGxXN-kPgSxbky9ORBvmyQUWtbjKbmxx1aWGky0nmkqSFGiroBmAGiFeC9vCVEXXXuRYbXGKcagV9kJGWpKLuMRgsL_NBhpYOPKywqKMYJHI7YR40M28JpxVsLSuVQA?key=GJkKLb4fde_5f2ejpxgwoeEz" class="kg-image" alt="8 best AI coding tools for developers: tested &amp; compared!" loading="lazy" width="388" height="966"><figcaption><span style="white-space: pre-wrap;">A recent review of cursor vs Windsurf revealed certain LLM drawbacks</span></figcaption></figure><p>For developers new to programming, the challenges can be more fundamental:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXdT8iRFoedvKuUvKLfTsdZF0kYGCa87U8XPEkLcJfQBnLaIswkBTWfYJx4eOYXwXPIosTF35y9KOChz7UgFOi4pxdLMKIvAZyXrHgkXGfDuKxemAZHKxiiGkeGvei6WWlOWun7Rdw?key=GJkKLb4fde_5f2ejpxgwoeEz" class="kg-image" alt="8 best AI coding tools for developers: tested &amp; compared!" loading="lazy" width="602" height="415"><figcaption><span style="white-space: pre-wrap;">Another feedback from a user who claims to have no prior Python knowledge</span></figcaption></figure><h2 id="why-low-code-platforms-often-beat-ai-generated-code">Why low-code platforms often beat AI-generated code</h2><p>AI coding tools offer exciting possibilities to speed up development but often struggle with creating consistent, maintainable systems at scale. For Sec/IT/DevOps teams, <strong>reliability and the ability to orchestrate complex workflows across multiple systems</strong> are paramount.&#xA0;</p><p>Low-code platforms like n8n address this need by combining solid engineering principles with the convenience of visual development.</p><p>n8n team has spent years building a workflow automation platform that many developers enjoy using and trust for live applications. With native support for 400+ services and an active developer community, n8n helps teams build reliable automation without agonizing over AI-generated code.</p><p>Three key strengths make n8n particularly relevant in the age of AI:</p><ol><li><strong>Battle-tested workflow engine</strong>: instead of cobbling together AI-generated code, you get a production-ready foundation that handles complex scenarios like parallel execution, error handling, and state management.</li><li><strong>AI-native architecture</strong>: n8n offers native integrations with popular AI services and LLMs, allowing you to build AI-powered workflows and LangChain agents without complex API implementations or token management.</li><li><strong>Flexible integration layer</strong>: connect to databases, APIs and various services using pre-built nodes or write custom integration code when needed. n8n handles authentication, rate limiting, queues and data transformation.</li></ol><p>Here&#x2019;s what you get:</p><table>
<thead>
<tr>
<th><strong>Aspect</strong></th>
<th><strong>Benefits</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>Production foundation</td>
<td>&#x2022; Pre-written, reviewed and publicly available codebase<br>&#x2022; Regular security updates and bug fixes<br>&#x2022; Active community support<br>&#x2022; <a href="https://n8n.io/integrations/?ref=blog.n8n.io">Integrations with 400+ services</a><br>(or configure connection via the <a href="https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.httprequest/?ref=blog.n8n.io">HTTP Request Node</a><br>to virtually any other service)</td>
</tr>
<tr>
<td>Good engineering practice</td>
<td>&#x2022; Built-in error handling and retries<br>&#x2022; <a href="https://docs.n8n.io/hosting/configuration/environment-variables/?ref=blog.n8n.io">Environment variable</a> management<br>&#x2022; Logging and monitoring<br>&#x2022; Workflow versioning<br>&#x2022; Clear change history</td>
</tr>
<tr>
<td>Runtime features</td>
<td>&#x2022; <a href="https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.webhook/?ref=blog.n8n.io">Webhook</a> management<br>&#x2022; CRON scheduling<br>&#x2022; <a href="https://docs.n8n.io/hosting/scaling/queue-mode/?ref=blog.n8n.io">Queue</a> handling<br>&#x2022; Rate limiting<br>&#x2022; API endpoint generation</td>
</tr>
<tr>
<td>Enterprise features</td>
<td>&#x2022; Advanced <a href="https://docs.n8n.io/api/authentication/?ref=blog.n8n.io">authentication and authorization</a><br>&#x2022; Secure <a href="https://docs.n8n.io/credentials/?ref=blog.n8n.io">credential</a> storage<br>&#x2022; <a href="https://docs.n8n.io/source-control-environments/understand/environments/?ref=blog.n8n.io">Multi-environment</a> support<br>&#x2022; Audit logging<br>&#x2022; Role-based access control</td>
</tr>
<tr>
<td>Development flexibility</td>
<td>&#x2022; Visual workflow builder<br>&#x2022; <a href="https://docs.n8n.io/code/code-node/?ref=blog.n8n.io">JavaScript/Python code integration</a><br>&#x2022; Custom node development<br>&#x2022; External library support (self-hosted)<br>&#x2022; AI support through <a href="https://n8n.io/integrations/my-askai/?ref=blog.n8n.io">AskAI</a> (cloud)</td>
</tr>
<tr>
<td>Resource optimization</td>
<td>&#x2022; No integration code maintenance<br>&#x2022; Reduced debugging time<br>&#x2022; <a href="https://n8n.io/case-studies/dedatech/?ref=blog.n8n.io">Faster time-to-market</a><br>&#x2022; Lower technical debt<br>&#x2022; Predictable <a href="https://n8n.io/pricing/?ref=blog.n8n.io">pricing</a></td>
</tr>
<tr>
<td>Team collaboration</td>
<td>&#x2022; Easy knowledge transfer<br>&#x2022; Built-in sharing and permissions<br>&#x2022; Documentation generation<br>&#x2022; Workflow templates</td>
</tr>
</tbody>
</table>
<p>n8n is not meant to replace your entire development stack. It&#x2019;s a tool that works best for:</p><ul><li>Building automation workflows</li><li>Creating AI-powered applications and LangChain AI agents</li><li>Integrating multiple services and APIs</li><li>Processing and transforming data</li></ul>
<!--kg-card-begin: html-->
<script>
  workflowBanner([3123, 3025, 3078, 3005], document.currentScript, { 
      workflowsHeader: "Implement these AI workflows without coding"
  });
</script>
<!--kg-card-end: html-->
<h2 id="wrap-up">Wrap up</h2><p>In this article, we&apos;ve explored 8 AI-powered coding tools, highlighting that the &quot;best&quot; solution depends on your specific development needs and project requirements.</p><p>In our experience, the most valuable AI coding assistants are those that integrate naturally with your development environment rather than forcing you to adapt to entirely new ways of working. We&#x2019;ve found that tools offering a thoughtful balance of convenience and capability could deliver more value than those with the most cutting-edge features but steeper learning curves.</p><p>To build stable automation workflows and integrate different services &#x2013; especially in AI-driven applications &#x2013; consider the reliability and visual clarity of low-code platforms like n8n.</p><p>n8n provides a production-ready foundation that allows you to apply the power of AI without having to deal with the complexities of AI-only generated code.</p>
<!--kg-card-begin: html-->
<div class="content-banner">
  <div>
    <h3>Start building with n8n today</h3>
    <p>Build complex AI automations 10x faster, without fighting APIs</p>
  </div>
  <a href="https://app.n8n.cloud/register?ref=blog.n8n.io" class="global-button blog-banner-signup">Try n8n now</a>
</div>
<!--kg-card-end: html-->
<h2 id="what%E2%80%99s-next">What&#x2019;s next?</h2><p>The landscape of coding AI tools is evolving rapidly, and new solutions are constantly emerging. We encourage you to experiment with the tools we&#x2019;ve covered and explore how they might fit into your workflow.</p><p>Almost every tool has several common features and unique, detailed settings. Dig into each tool&#x2019;s documentation and test it for a few days before making your final decision. If you haven&apos;t found anything of interest at the moment, it may be worth checking back in a few months.</p><p>To further improve your development process and build reliable AI-powered automation right now, we recommend exploring n8n:</p><ul><li>Get started with n8n: <a href="https://app.n8n.cloud/register?ref=blog.n8n.io"><u>sign up for a free n8n cloud account</u></a>.</li><li>Discover n8n&#x2019;s AI capabilities: <a href="https://n8n.io/ai/?ref=blog.n8n.io"><u>explore n8n&#x2019;s AI features and integrations</u></a>.</li></ul><p>Find inspiration for your next automation: <a href="https://n8n.io/workflows/?ref=blog.n8n.io"><u>browse n8n workflow templates</u></a>.</p></figure>]]></content:encoded></item><item><title><![CDATA[LlamaIndex vs LangChain: Which RAG tool is right for you?]]></title><description><![CDATA[LlamaIndex vs LangChain: Which is best for your LLM application? This guide compares these frameworks, highlighting their strengths and limitations for RAG use cases. We also introduce n8n as a low-code alternative that combines LangChain's flexibility with a user-friendly interface.]]></description><link>https://blog.n8n.io/llamaindex-vs-langchain/</link><guid isPermaLink="false">67baed236eff130001084b1e</guid><category><![CDATA[AI]]></category><category><![CDATA[Guide]]></category><dc:creator><![CDATA[Mihai Farcas]]></dc:creator><pubDate>Thu, 13 Mar 2025 10:28:43 GMT</pubDate><media:content url="https://blog.n8n.io/content/images/2025/03/llamaindex-vs-langchain2-8--1-.png" medium="image"/><content:encoded><![CDATA[<img src="https://blog.n8n.io/content/images/2025/03/llamaindex-vs-langchain2-8--1-.png" alt="LlamaIndex vs LangChain: Which RAG tool is right for you?"><p>Retrieval-Augmented Generation (RAG) is essential for building LLM applications that can access and reason over up-to-date, proprietary, or domain-specific information. By using RAG, LLMs can overcome the limitations of relying solely on their pre-trained knowledge.</p><p>Two popular frameworks for building RAG chatbots are LlamaIndex and LangChain.</p><p>This article provides a comparative analysis of LlamaIndex and LangChain, highlighting their core strengths, key differences, and ideal use cases. We will then introduce <a href="https://n8n.io/ai/?ref=blog.n8n.io" rel="noreferrer">n8n</a> as <a href="https://blog.n8n.io/langchain-alternatives/" rel="noreferrer">a LangChain alternative</a>. n8n is a powerful, low-code automation software, particularly well-suited for RAG workflows that require extensive integrations and visual workflow design.</p><p>So let&apos;s get straight into it!</p><h2 id="llamaindex-vs-langchain-a-comparative-analysis">LlamaIndex vs LangChain: A comparative analysis</h2><p>Here&apos;s a comparative table to summarize the key differences between LlamaIndex and LangChain:</p><table>
    <tbody><tr>
        <td>Criteria</td>
        <td><strong>LlamaIndex</strong></td>
        <td><strong>LangChain</strong></td>
    </tr>
    <tr>
        <td><strong>Primary focus</strong></td>
        <td>Data connection, indexing, <br>and querying for RAG.</td>
        <td>Building and orchestrating <br>complex LLM workflows, <br>including agents and chains.</td>
    </tr>
    <tr>
        <td><strong>Ease of use</strong></td>
        <td>Easier to learn and use, <br>especially for beginners. <br>High-level API simplifies <br>common tasks.</td>
        <td>Steeper learning curve. <br>Requires a deeper understanding <br>of LLM concepts.</td>
    </tr>
    <tr>
        <td><strong>Data ingestion</strong></td>
        <td>Extensive data connectors <br>through LlamaHub (APIs, PDFs, <br>databases, etc.). Streamlined <br>data loading and indexing.</td>
        <td>Supports data loading, <br>but focus is more on <br>data transformation within <br>the pipeline.</td>
    </tr>
    <tr>
        <td><strong>Querying</strong></td>
        <td>Sophisticated querying <br>capabilities, including <br>subqueries and multi-document <br>summarization. Optimized <br>for retrieval.</td>
        <td>Flexible querying, <br>but often requires more <br>manual configuration.</td>
    </tr>
    <tr>
        <td><strong>Flexibility</strong></td>
        <td>Less flexible, more <br>opinionated. Good for <br>standard RAG use cases.</td>
        <td>Highly flexible and modular. <br>Allows swapping LLMs, <br>customizing prompts, <br>and building complex chains <br>using various LangChain <br>chain types.</td>
    </tr>
    <tr>
        <td><strong>Extensibility</strong></td>
        <td>Primarily through LlamaHub <br>and custom data connectors.</td>
        <td>Highly extensible through <br>custom chains, agents, <br>and tools.</td>
    </tr>
    <tr>
        <td><strong>Customization</strong></td>
        <td>Some customization options, <br>but less than LangChain.</td>
        <td>Highly customisable and <br>great degree of control.</td>
    </tr>
    <tr>
        <td><strong>Free for commercial use?</strong></td>
        <td>Yes</td>
        <td>Yes</td>
    </tr>
    <tr>
        <td><strong>Use cases</strong></td>
        <td>RAG chatbots, document <br>Q&amp;A, knowledge base <br>querying, data augmentation.</td>
        <td>Complex reasoning systems, <br>multi-agent applications, <br>applications requiring <br>integration with multiple <br>tools and APIs. You can <br>also use LangChain for <br>RAG workflows.</td>
    </tr>
    <tr>
        <td><strong>Repository</strong></td>
        <td><a href="https://github.com/run-llama/llama_index?ref=blog.n8n.io">LlamaIndex GitHub</a></td>
        <td><a href="https://github.com/langchain-ai/langchain?ref=blog.n8n.io">LangChain GitHub</a></td>
    </tr>
</tbody></table><h2 id="which-is-better-llamaindex-or-langchain">Which is better: LlamaIndex or LangChain?</h2><p>Both LlamaIndex and LangChain are powerful frameworks for building LLM-powered applications, particularly those leveraging RAG.</p><p>However, when considering LangChain vs LlamaIndex, they have distinct strengths that make them better suited for different use cases.</p><h3 id="ease-of-use">Ease of use</h3><p>LlamaIndex generally has a gentler learning curve. Its high-level API and focus on data connection and querying make it easier to get started, especially for developers new to LLMs. For example, if you need to quickly build a RAG chatbot that answers questions over a collection of PDF documents, LlamaIndex&apos;s data loaders and index structures simplify this process considerably.</p><p>LangChain, while more powerful, has a steeper learning curve. Its modularity and flexibility require a deeper understanding of LLM concepts and the various components involved.</p><h3 id="data-handling-and-indexing">Data handling and indexing</h3><p>LlamaIndex excels in this area. It provides various indexing strategies optimized for different types of data and retrieval needs. For instance, you can easily load data from APIs, databases, and local files, and choose between vector, tree, or keyword-based indexes.</p><p>LlamaIndex has a user-friendly approach to data ingestion, primarily through <a href="https://llamahub.ai/?ref=blog.n8n.io"><u>LlamaHub</u></a>. This central repository offers a wide array of data connectors for common sources like APIs, PDFs, documents, and databases. This extensive and easily accessible collection of connectors significantly simplifies and speeds up the process of integrating diverse data sources into your RAG pipeline.</p><p>LangChain, in contrast, does not enforce a specific indexing approach but instead allows users to structure their own pipelines based on their preferred tools. This flexibility makes it suitable for developers who want more control over their retrieval strategies, though it may require additional setup compared to LlamaIndex&#x2019;s built-in indexing mechanisms.</p><p>LangChain also supports data loading with its own set of document loaders. While it might not have a single, unified hub like LlamaHub, LangChain&apos;s data loaders are flexible and can be customized. This approach provides greater control over the data loading process, which is advantageous for developers who need to implement highly specific or custom data ingestion logic.</p><h3 id="flexibility">Flexibility</h3><p>LangChain offers significantly more flexibility and control. Its modular architecture allows you to swap out different LLMs, customize prompt templates, and chain together multiple tools and agents. This is crucial if you&apos;re building complex applications, such as a multi-step reasoning system or an application that needs to interact with multiple external services.</p><p>LlamaIndex, while offering some customization, is more opinionated in its approach, prioritizing ease of use over fine-grained control.</p><h3 id="querying-capabilities">Querying capabilities</h3><p>LlamaIndex is optimized for sophisticated querying within RAG systems. It supports advanced querying techniques like subqueries (querying across multiple documents or indexes) and multi-document summarization.</p><p>LangChain offers flexible querying options, but often requires more manual configuration to achieve advanced querying patterns. You have the building blocks to create complex query chains, but you need to assemble them yourself.</p><h3 id="memory-management">Memory management</h3><p>LlamaIndex offers basic context retention capabilities, allowing for simple conversational interactions. This is sufficient for straightforward RAG chatbots where maintaining short-term conversation history is needed for context.</p><p>LangChain&apos;s advanced memory management is crucial for building sophisticated conversational AI applications that require extensive context retention, understanding of conversation history, and complex multi-turn reasoning.</p><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text">If your primary need is to quickly connect LLMs to your data and build RAG applications with minimal complexity, LlamaIndex is an excellent choice. If you need maximum flexibility, control, and the ability to build complex, multi-step LLM workflows, LangChain is the more powerful option.</div></div><h2 id="can-i-use-langchain-and-llamaindex-together">Can I use LangChain and LlamaIndex together?</h2><p>Yes, you can absolutely use LangChain and LlamaIndex together! In fact, combining them can be a powerful way to leverage the strengths of each framework. Here&apos;s why and how:</p><h3 id="use-llamaindex-for-data-management">Use LlamaIndex for data management</h3><p>You can use LlamaIndex&apos;s powerful data connectors and indexing capabilities to efficiently load, structure, and index your data from various sources. This creates a robust knowledge base for your RAG system. As we mentioned earlier, while LangChain connectors are also available, LlamaIndex excels in this area.</p><h3 id="use-langchain-for-orchestration">Use LangChain for orchestration</h3><p>Utilize LangChain&apos;s chains, agents, and LangChain tools to build the overall logic and workflow of your application. Integrate LlamaIndex&apos;s query engine as a tool within your LangChain workflow, allowing you to retrieve relevant information from your indexed data.</p><h2 id="what-are-the-limitations-of-llamaindex-and-langchain">What are the limitations of LlamaIndex and LangChain?</h2><h3 id="llamaindex-limitations">LlamaIndex limitations</h3><ul><li>Primarily focused on data retrieval, making it less suitable for:<ul><li>Highly complex LLM applications with intricate, multi-step workflows</li><li>Applications requiring interactions with numerous external services</li></ul></li><li>Supports only basic context retention, which may be insufficient for:<ul><li>Applications needing extensive conversational memory</li><li>Complex reasoning across multiple turns.</li></ul></li></ul><h3 id="langchain-limitations">LangChain limitations</h3><ul><li>High flexibility comes with:<ul><li>A steep learning curve, especially for developers new to LLMs</li><li>More intricate initial setup and configuration</li></ul></li><li>Increased debugging and maintenance overhead, particularly for sophisticated applications</li><li>Frequent breaking changes between versions, often requiring ongoing code adjustments.</li></ul><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text">Unlike LlamaIndex&#x2019;s focus on data retrieval and LangChain&#x2019;s steep learning curve, n8n provides <b><strong style="white-space: pre-wrap;">scalable orchestration</strong></b> with built-in connectors and <b><strong style="white-space: pre-wrap;">easier maintenance</strong></b> across evolving LLM applications.</div></div><h2 id="an-alternative-to-llamaindex-or-langchain-n8n">An alternative to LlamaIndex or LangChain: n8n</h2><p>While LangChain and LlamaIndex are powerful tools for building LLM applications, they primarily focus on a code-centric approach.</p><p>n8n offers a compelling alternative by providing a low-code environment that seamlessly integrates with LangChain. This means you can get the power and flexibility of LangChain without the complexity of managing its underlying code directly.</p><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text">By providing an abstraction layer over LangChain, n8n simplifies the development process while retaining the core flexibility that LangChain offers.</div></div><h3 id="why-choose-n8n-over-llamaindex-and-langchain">Why choose n8n over LlamaIndex and LangChain?</h3><ul><li>You want LangChain&apos;s power, but prefer <strong>low-code</strong>! <a href="https://n8n.io/integrations/agent/?ref=blog.n8n.io" rel="noreferrer">n8n&apos;s AI Agent node</a> allows you to leverage LangChain&apos;s features, such as agents and memory, without writing complex Python code.</li><li><strong>Extensive integrations:</strong> <a href="https://n8n.io/integrations/?ref=blog.n8n.io"><u>n8n boasts 400+ integrations with various apps and services</u></a> such as databases, CRMs, marketing platforms, communication tools, and virtually any service with an API. This is a significant advantage over LangChain and LlamaIndex, which primarily focus on LLM interactions. With n8n it&#x2019;s also very easy to integrate <a href="https://n8n.io/integrations/?q=vector&amp;ref=blog.n8n.io"><u>vector databases</u></a>, such as Pinecone, with LangChain.</li><li><strong>Visual workflow builder:</strong> n8n provides a user-friendly, <a href="https://n8n.io/features/?ref=blog.n8n.io"><u>drag-and-drop interface for building workflows</u></a>, making it accessible to both technical and non-technical users. This can be a significant advantage over the code-heavy approach of LangChain and LlamaIndex.</li><li><strong>Native AI capabilities:</strong> <a href="https://docs.n8n.io/advanced-ai/langchain/langchain-n8n/?ref=blog.n8n.io"><u>n8n has built-in support for LangChain</u></a>, including integrations with tools like <a href="https://blog.n8n.io/local-llm/"><u>LangChain Ollama for local LLM usage</u></a>, allowing you to <a href="https://n8n.io/ai/?ref=blog.n8n.io"><u>incorporate LLM interactions into your workflows</u></a>. You configure your LangChain chains and agents within the node, and n8n handles execution and integration with the rest of your workflow. This way, you leverage LangChain&apos;s advanced features (agents, memory, custom chains) without writing intricate Python.</li></ul><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://blog.n8n.io/content/images/2025/02/n8n_ai_agent.webp" class="kg-image" alt="LlamaIndex vs LangChain: Which RAG tool is right for you?" loading="lazy" width="1985" height="1200" srcset="https://blog.n8n.io/content/images/size/w600/2025/02/n8n_ai_agent.webp 600w, https://blog.n8n.io/content/images/size/w1000/2025/02/n8n_ai_agent.webp 1000w, https://blog.n8n.io/content/images/size/w1600/2025/02/n8n_ai_agent.webp 1600w, https://blog.n8n.io/content/images/2025/02/n8n_ai_agent.webp 1985w" sizes="(min-width: 720px) 720px"><figcaption><span style="white-space: pre-wrap;">n8n example of AI Agent workflow</span></figcaption></figure><ul><li><strong>Rapid prototyping and iteration:</strong> you can quickly experiment with different RAG approaches, connect to various data sources, and test different LLM configurations.</li><li><strong>Simplified configuration:</strong> While you can use advanced LangChain features, the visual interface simplifies configuration using the built-in LangChain templates. You set up prompts, input variables, and output handling within the LangChain node&apos;s settings.</li></ul><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://blog.n8n.io/content/images/2025/02/n8n_ai_node_configuration.webp" class="kg-image" alt="LlamaIndex vs LangChain: Which RAG tool is right for you?" loading="lazy" width="1154" height="1292" srcset="https://blog.n8n.io/content/images/size/w600/2025/02/n8n_ai_node_configuration.webp 600w, https://blog.n8n.io/content/images/size/w1000/2025/02/n8n_ai_node_configuration.webp 1000w, https://blog.n8n.io/content/images/2025/02/n8n_ai_node_configuration.webp 1154w" sizes="(min-width: 720px) 720px"><figcaption><span style="white-space: pre-wrap;">Configuring the AI Agent n8n node</span></figcaption></figure><ul><li><strong>Hybrid approach:</strong> you can combine the ease of visual workflow design with the power of custom code using <a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.code/?ref=blog.n8n.io" rel="noreferrer">n8n&apos;s LangChain code node</a>.</li></ul><h2 id="examples-of-rag-workflows-built-with-n8n">Examples of RAG workflows built with n8n</h2><p>Let&apos;s explore some real-world workflow examples that illustrate the versatility of n8n for RAG and Agentic AI!</p><h3 id="ai-powered-rag-workflow-for-stock-earnings-report-analysis">AI-Powered RAG workflow for stock earnings report analysis</h3>
<!--kg-card-begin: html-->
<script>
  workflowBanner(2741, document.currentScript);
</script>
<!--kg-card-end: html-->
<p>This n8n workflow creates a financial analysis tool that generates reports on a company&apos;s quarterly earnings using <a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatopenai/?ref=blog.n8n.io" rel="noreferrer">OpenAI GPT-4o-mini</a>, <a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatgooglegemini/?ref=blog.n8n.io" rel="noreferrer">Google&apos;s Gemini AI</a>, and <a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.vectorstorepinecone/?ref=blog.n8n.io" rel="noreferrer">Pinecone&apos;s vector search</a>. The workflow fetches earnings PDFs, parses them, generates embeddings, and stores them in Pinecone. An AI agent orchestrates the process, using Pinecone and LLMs to analyze data and generate the report, which is then saved to <a href="https://docs.n8n.io/integrations/builtin/app-nodes/n8n-nodes-base.googledrive/?ref=blog.n8n.io" rel="noreferrer">Google Drive</a>.</p><h3 id="complete-business-whatsapp-ai-powered-rag-chatbot-using-openai">Complete business WhatsApp AI-powered RAG chatbot using OpenAI</h3>
<!--kg-card-begin: html-->
<script>
  workflowBanner(2845, document.currentScript);
</script>
<!--kg-card-end: html-->
<p>This workflow allows you to create an AI-powered chatbot for WhatsApp Business that uses RAG to provide accurate and relevant information to customers. The workflow sets up <a href="https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.webhook/?ref=blog.n8n.io" rel="noreferrer">webhooks </a>to handle incoming messages, processes them, and utilizes an AI agent with a predefined system message to ensure appropriate responses. It accesses a knowledge base stored in <a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.vectorstoreqdrant/?ref=blog.n8n.io" rel="noreferrer">Qdrant </a>(a vector database like Pinecone), generates responses using OpenAI&apos;s GPT model, and sends them back to the user.</p><h3 id="effortless-email-management-with-ai-powered-summarization-review">Effortless email management with AI-powered summarization &amp; review</h3>
<!--kg-card-begin: html-->
<script>
  workflowBanner(2862, document.currentScript);
</script>
<!--kg-card-end: html-->
<p>This workflow automates the handling of incoming emails, summarizes their content, generates responses using RAG, and obtains approval before sending replies. It listens for new emails, summarizes them, generates responses, and sends drafts for human review via <a href="https://docs.n8n.io/integrations/builtin/app-nodes/n8n-nodes-base.gmail/?ref=blog.n8n.io" rel="noreferrer">Gmail</a>. If approved, the email is sent; otherwise, it&apos;s edited or handled manually. A text classifier categorizes feedback to guide the process.</p><h3 id="rag-chatbot-for-company-documents-using-google-drive-and-gemini">RAG chatbot for company documents using Google Drive and Gemini</h3>
<!--kg-card-begin: html-->
<script>
  workflowBanner(2753, document.currentScript);
</script>
<!--kg-card-end: html-->
<p>This workflow implements a Retrieval Augmented Generation (RAG) chatbot that answers employee questions based on company documents stored in <a href="https://docs.n8n.io/integrations/builtin/app-nodes/n8n-nodes-base.googledrive/?ref=blog.n8n.io" rel="noreferrer">Google Drive</a>. It automatically indexes new or updated documents in a <a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.vectorstorepinecone/?ref=blog.n8n.io" rel="noreferrer">Pinecone vector database</a>, allowing the chatbot to provide accurate and up-to-date information. The workflow uses <a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatgooglegemini/?ref=blog.n8n.io" rel="noreferrer">Google&apos;s Gemini AI</a> for both embeddings and response generation. When a new or updated document is detected, the workflow downloads it, splits it into chunks, embeds the chunks using Gemini, and stores them in Pinecone. The chatbot receives questions, retrieves relevant information from Pinecone based on the question, and generates answers using the Gemini chat model.</p><h2 id="langchain-vs-llamaindex-vs-n8n-faq">LangChain vs LlamaIndex vs n8n FAQ</h2><div class="kg-card kg-toggle-card" data-kg-toggle-state="close">
            <div class="kg-toggle-heading">
                <h4 class="kg-toggle-heading-text"><span style="white-space: pre-wrap;">Which is better for building autonomous AI agents, Auto-GPT or LangChain?</span></h4>
                <button class="kg-toggle-card-icon" aria-label="Expand toggle to read content">
                    <svg id="Regular" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                        <path class="cls-1" d="M23.25,7.311,12.53,18.03a.749.749,0,0,1-1.06,0L.75,7.311"/>
                    </svg>
                </button>
            </div>
            <div class="kg-toggle-content"><p><span style="white-space: pre-wrap;">Auto-GPT is better for fully autonomous agents that operate with minimal human input, while LangChain offers greater flexibility for building custom workflows and integrating multiple external tools and APIs.</span></p></div>
        </div><div class="kg-card kg-toggle-card" data-kg-toggle-state="close">
            <div class="kg-toggle-heading">
                <h4 class="kg-toggle-heading-text"><b><strong style="white-space: pre-wrap;">Which tool is best for retrieval-augmented generation (RAG): LangChain, LlamaIndex, or Haystack?</strong></b></h4>
                <button class="kg-toggle-card-icon" aria-label="Expand toggle to read content">
                    <svg id="Regular" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                        <path class="cls-1" d="M23.25,7.311,12.53,18.03a.749.749,0,0,1-1.06,0L.75,7.311"/>
                    </svg>
                </button>
            </div>
            <div class="kg-toggle-content"><p><span style="white-space: pre-wrap;">Haystack is the best choice for search-heavy RAG applications, LlamaIndex excels at indexing and querying large datasets, and LangChain is ideal for orchestrating complex LLM workflows that involve both retrieval and external integrations.</span></p></div>
        </div><div class="kg-card kg-toggle-card" data-kg-toggle-state="close">
            <div class="kg-toggle-heading">
                <h4 class="kg-toggle-heading-text"><b><strong style="white-space: pre-wrap;">When should I use LangChain, LlamaIndex, or Hugging Face for an LLM project?</strong></b></h4>
                <button class="kg-toggle-card-icon" aria-label="Expand toggle to read content">
                    <svg id="Regular" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                        <path class="cls-1" d="M23.25,7.311,12.53,18.03a.749.749,0,0,1-1.06,0L.75,7.311"/>
                    </svg>
                </button>
            </div>
            <div class="kg-toggle-content"><p dir="ltr"><span style="white-space: pre-wrap;">Use LangChain for complex workflows and multi-step logic, LlamaIndex for efficient data retrieval, and Hugging Face for accessing and fine-tuning pre-trained LLMs across a wide range of tasks.</span></p></div>
        </div><div class="kg-card kg-toggle-card" data-kg-toggle-state="close">
            <div class="kg-toggle-heading">
                <h4 class="kg-toggle-heading-text"><span style="white-space: pre-wrap;">Can LangChain be used with Python only?</span></h4>
                <button class="kg-toggle-card-icon" aria-label="Expand toggle to read content">
                    <svg id="Regular" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                        <path class="cls-1" d="M23.25,7.311,12.53,18.03a.749.749,0,0,1-1.06,0L.75,7.311"/>
                    </svg>
                </button>
            </div>
            <div class="kg-toggle-content"><p><span style="white-space: pre-wrap;">LangChain offers official libraries for both Python and JavaScript. While the Python library was initially more mature, both libraries are now actively developed and maintained, offering comparable features and functionality. You can choose either language based on your preference and project requirements.</span></p><p><span style="white-space: pre-wrap;">There are community-driven adaptations of LangChain for Java and Golang. Additionally, platforms like n8n provide a visual interface and pre-built nodes for LangChain.</span></p></div>
        </div><div class="kg-card kg-toggle-card" data-kg-toggle-state="close">
            <div class="kg-toggle-heading">
                <h4 class="kg-toggle-heading-text"><span style="white-space: pre-wrap;">Can you use LangChain with Ollama local LLMs?</span></h4>
                <button class="kg-toggle-card-icon" aria-label="Expand toggle to read content">
                    <svg id="Regular" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                        <path class="cls-1" d="M23.25,7.311,12.53,18.03a.749.749,0,0,1-1.06,0L.75,7.311"/>
                    </svg>
                </button>
            </div>
            <div class="kg-toggle-content"><p><span style="white-space: pre-wrap;">Yes, LangChain provides official components for integrating with Ollama. This can be beneficial for various reasons, including privacy, security, and cost-effectiveness.</span></p></div>
        </div><div class="kg-card kg-toggle-card" data-kg-toggle-state="close">
            <div class="kg-toggle-heading">
                <h4 class="kg-toggle-heading-text"><span style="white-space: pre-wrap;">Can you use LangChain with Pinecone or other vector databases?</span></h4>
                <button class="kg-toggle-card-icon" aria-label="Expand toggle to read content">
                    <svg id="Regular" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                        <path class="cls-1" d="M23.25,7.311,12.53,18.03a.749.749,0,0,1-1.06,0L.75,7.311"/>
                    </svg>
                </button>
            </div>
            <div class="kg-toggle-content"><p><span style="white-space: pre-wrap;">LangChain is designed to work seamlessly with Pinecone and other vector databases. Integrating a vector database like Pinecone with LangChain is a common practice for building efficient and scalable RAG applications.</span></p></div>
        </div><div class="kg-card kg-toggle-card" data-kg-toggle-state="close">
            <div class="kg-toggle-heading">
                <h4 class="kg-toggle-heading-text"><span style="white-space: pre-wrap;">What is LangSmith?</span></h4>
                <button class="kg-toggle-card-icon" aria-label="Expand toggle to read content">
                    <svg id="Regular" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                        <path class="cls-1" d="M23.25,7.311,12.53,18.03a.749.749,0,0,1-1.06,0L.75,7.311"/>
                    </svg>
                </button>
            </div>
            <div class="kg-toggle-content"><p><span style="white-space: pre-wrap;">LangSmith is a platform designed specifically for debugging, testing, and evaluating LLM applications. It helps developers improve the performance and reliability of their LangChain projects by providing tools to trace workflow execution and evaluate accuracy.</span></p></div>
        </div><h2 id="wrap-up">Wrap up</h2><p>In this article, we provided a comparative analysis of LlamaIndex and LangChain, two powerful frameworks for building RAG systems. We highlighted their strengths, limitations, and use cases, and also introduced n8n as a compelling alternative for those seeking a low-code, integration-heavy solution.</p><p>Choosing the right framework for your LLM application depends on your specific needs and priorities.</p><p>If you need a simple and efficient solution for data-centric tasks, LlamaIndex is a great choice. If you require greater flexibility and control for complex workflows, LangChain might be a better fit. And if you&apos;re looking for a broader automation platform that seamlessly integrates with LLMs, n8n offers a compelling alternative.</p>
<!--kg-card-begin: html-->
<div class="content-banner">
  <div>
    <h3>Create your RAG workflows with n8n</h3>
    <p>Get started today and unlock flexible, scalable AI automation!</p>
  </div>
  <a href="https://app.n8n.cloud/register?ref=blog.n8n.io" class="global-button blog-banner-signup">Try n8n now</a>
</div>
<!--kg-card-end: html-->
<h2 id="what%E2%80%99s-next">What&#x2019;s next?</h2><p>To further enhance your understanding of RAG and LLM application development, check out these resources on the n8n blog:</p><ul><li><a href="https://blog.n8n.io/llm-agents/"><strong><u>LLM agents in 2025</u></strong></a><strong>:</strong> Learn about the latest advances in LLM agents and how they are being used in enterprise environments.</li><li><a href="https://blog.n8n.io/rag-chatbot/"><strong><u>RAG chatbots</u></strong></a><strong>:</strong> Learn how to build a RAG chatbot that can access and process information from your documents or knowledge base using n8n.</li><li><a href="https://blog.n8n.io/local-llm/"><strong><u>Use n8n to integrate LangChain with local LLMs</u></strong></a><strong>:</strong> Learn how to run LLMs like Deepseek locally on your own machine using n8n and Ollama.</li><li><a href="https://blog.n8n.io/ai-agentic-workflows/"><strong><u>AI-agentic workflows</u></strong></a><strong>:</strong> Learn how AI agents can be used to automate tasks and make decisions in n8n workflows.</li><li><a href="https://blog.n8n.io/mlops-tools/"><strong><u>MLOps tools</u></strong></a><strong>:</strong> Explore the different MLOps tools available and how they can be used to manage the entire lifecycle of your ML models.</li></ul>]]></content:encoded></item><item><title><![CDATA[AI Workflows for the Cautious Enterprise]]></title><description><![CDATA[<p>We designed this guide for the risk-sensitive enterprises that need to start considering their AI adoption strategy to remain competitive, but have little tolerance for data integrity or privacy-related risks. It outlines a range of techniques, such as optimizing LLM accuracy, adding guardrails, running AI models locally in the workflow</p>]]></description><link>https://blog.n8n.io/ai-workflows-for-the-cautious-enterprise/</link><guid isPermaLink="false">67b87b996eff130001084aff</guid><category><![CDATA[AI]]></category><category><![CDATA[ITOps]]></category><dc:creator><![CDATA[Andrew Green]]></dc:creator><pubDate>Fri, 21 Feb 2025 14:41:48 GMT</pubDate><media:content url="https://blog.n8n.io/content/images/2025/02/post_02.png" medium="image"/><content:encoded><![CDATA[<img src="https://blog.n8n.io/content/images/2025/02/post_02.png" alt="AI Workflows for the Cautious Enterprise"><p>We designed this guide for the risk-sensitive enterprises that need to start considering their AI adoption strategy to remain competitive, but have little tolerance for data integrity or privacy-related risks. It outlines a range of techniques, such as optimizing LLM accuracy, adding guardrails, running AI models locally in the workflow automation tool, scalability, and other considerations that can bring AI to an enterprise-grade standard.</p><p>Some workflow automation tools - like n8n - can integrate AI within the automation logic. Executing AI as part of a wider customizable workflow is the best way for enterprises to mitigate the inherent risks of large language models, computer vision, and other AI algorithms.&#xA0;</p><p>Running AI as part of an automation workflow has three main considerations:</p><ol><li>The workflow automation tool can embed AI locally, or it can call external services.</li><li>AI agents are just one component of the workflow, so additional logic can be defined for both the AI input and output.</li><li>Automation logic can easily integrate AI with proprietary tools and legacy stack.</li></ol><p>When workflow-based automation tools act as a wrapper around AI workloads such as large language models, organizations can address some of the most pressing AI-related challenges, which include:</p><ul><li><strong>Data privacy</strong> - the AI models can either be run locally or in a trusted location. Additional privacy and data loss prevention mechanisms can be implemented before data is sent to the AI agent and after the response is generated.</li><li><strong>Insufficient talent and lack of skills to integrate AI</strong> - workflow-based automation tools offer intuitive graphical user interfaces that allow both developer and non-developer audiences to build automation logic that implements AI.</li><li><strong>Minimizing hallucinations</strong> - these refer to non-factual or nonsensical LLM responses, which must be subject to output controls that can detect errors or noncompliant responses.</li><li><strong>Sufficient and organized data for Small Language Models (SLM) or contextual responses</strong> - workflow automation tools can access disparate data sets and normalize data before for the AI model to generate responses.</li></ul><p></p><h2 id="types-of-ai-and-ml-models">Types of AI and ML models</h2><p>Since 2023, the term AI has been used interchangeably with large language models (LLMs) and text-based generative AI, courtesy of the viral popularity of ChatGPT. However, it&#x2019;s important to distinguish between different types of production-ready AI workloads</p><ul><li><strong>Generative AI </strong>- consists of large and small language models, image generation, and video generation, among others.&#xA0;<ul><li><strong>Large language models</strong> - Neural networks trained on vast text datasets, capable of understanding context, generating human-like text, code, and performing complex reasoning tasks (e.g., GPT-4, Claude, PaLM). For example, you can create a <a href="https://n8n.io/workflows/2457-multi-agent-pdf-to-blog-content-generation/?ref=blog.n8n.io"><u>Multi-Agent PDF-to-Blog Content Generation</u></a></li><li><strong>Small/Specialized language models</strong> - these models are trained for specific tasks like text completion, sentiment analysis, or domain-specific generation, with significantly fewer parameters than LLMs.</li><li><strong>Image generation</strong> - Models that create new images from text descriptions or modify existing images (e.g., DALL-E, Midjourney, Stable Diffusion). <a href="https://n8n.io/workflows/2417-flux-ai-image-generator/?ref=blog.n8n.io"><u>Here is one use case for AI-based image generation.</u></a></li><li><strong>Video generation</strong> - AI systems that can create or edit video content from text prompts or existing footage (e.g., Runway Gen-2, Google Image Video, Meta&apos;s Make-A-Video).</li><li><strong>Speech generation</strong> - A model that converts text to audio, such as <a href="https://n8n.io/workflows/2092-convert-text-to-speech-with-openai/?ref=blog.n8n.io"><u>this workflow that uses the OpenAI TTS mode</u></a>l.</li></ul></li><li><strong>Computer vision</strong> - can be used for object detection and recognition in images/video, facial recognition and analysis. <a href="https://n8n.io/workflows/2420-automate-image-validation-tasks-using-ai-vision/?ref=blog.n8n.io"><u>Here is one case for Automate Image Validation Tasks using AI Vision</u></a>.</li><li><strong>Speech recognition</strong> - can be used to convert audio to text in near real-time and across multiple languages.</li><li><strong>Time series analysis -</strong> can be used for analyzing and forecasting trends, detecting seasonal patterns, identifying anomalies, and making predictions based on sequential, time-dependent data.</li></ul><p>Based on the above, some achievable and production-ready use cases that implement AI today include agent support and Slack Bots, scheduling appointments, summarizing and chatting with internal PDFs, web scraping and webpage summarization, adding memory to AI agents, automating competitor research, image captioning, and customer support issue resolution using text classifier. A <a href="https://n8n.io/workflows/categories/ai/?ref=blog.n8n.io"><u>full library of AI templates can be found here.</u></a></p><h1 id="optimizing-llm-accuracy">Optimizing LLM Accuracy</h1><p>Out of all AI models available today, large language models have the highest potential of delivering value for enterprises in the short-term. As such, this section of the article will focus on optimizing these for specific use cases and proactively addressing hallucination-related challenges.</p><p>LLM optimization typically consists of prompt engineering, retrieval-augmented generation (RAG), and model fine-tuning. These address different optimization use cases and are typically used together. We will also discuss guardrail mechanisms that protect against issues such as prompt injection and data leaks.</p><figure class="kg-card kg-image-card"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXeVifFw4DR_FcFYImLi4HuTQPSQNpDtu2MFYjnV9P33_erhAJm58PqrAFWSiaCKnjhMOQZ87-v-sMPbccMrTfmGbdWuBetYxijQp7_SXXuWsYHiPof5eRHMUp27VmkpnINhPcWd?key=5Bu_i2rT_sZgQ-_nz7V586fH" class="kg-image" alt="AI Workflows for the Cautious Enterprise" loading="lazy" width="624" height="351"></figure><p><em>Source: https://platform.openai.com/docs/guides/optimizing-llm-accuracy/</em></p><p>In the above graphic, context optimization refers to the model lacking contextual knowledge if data was missing from the training set, its knowledge is out of date, or if it requires knowledge of proprietary information. LLM optimization refers to the consistency of the behavior, and must be considered if the model - given suitable prompts - is producing inconsistent results with incorrect formatting, the tone or style of speech is not correct, or the reasoning is not being followed consistently.&#xA0;</p><h2 id="prompt-engineering">Prompt Engineering</h2><p>Prompt engineering is the adjustment of the input request made to the LLM, and is often the only method needed for use cases like summarization, translation, and code generation where a zero-shot approach can reach production levels of accuracy and consistency.</p><p>Basic prompt engineering techniques look at aligning the input prompt to produce a desired output. Some guidelines recommend starting with a simple prompt and an expected output in mind, and then optimizing the prompt by adding context, instructions, or examples.</p><p>We recommend this<a href="https://platform.openai.com/docs/guides/prompt-engineering?ref=blog.n8n.io"><u> OpenAI Guide on Prompt Engineering.</u></a> At a high level, the guide suggests the following strategies:</p><ul><li>Provide reference text</li><li>Split complex tasks into simpler subtasks</li><li>Give the model time to &quot;think&quot;</li><li>Use external tools</li><li>Test changes systematically</li></ul><p>You can also follow prompt engineering guidelines from <a href="https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/overview?ref=blog.n8n.io"><u>Anthropic</u></a> and <a href="https://docs.mistral.ai/guides/prompting_capabilities/?ref=blog.n8n.io"><u>Mistral</u></a>.</p><h2 id="retrieval-augmented-generation-rag">Retrieval-Augmented Generation (RAG)</h2><p>RAG is the process of fetching relevant content to provide additional context for an LLM before it generates an answer. It is used to give the model access to domain-specific context to solve a task.</p><p>For example, if you need an LLM to produce answers that contain statistics, it can do so by retrieving information from a relevant database. When users ask a question, the prompt is embedded and used to retrieve the most relevant content from the knowledge base. This is presented to the model, which answers the question.</p><p>While this is a great technique for referencing hard data, RAG also introduces a new dimension to consider - retrieval. If the LLM is supplied the wrong context, it cannot answer correctly, and if it is supplied too much irrelevant context, it may increase hallucinations.</p><p>Retrieval itself must be optimized, which consists of tuning the search to return the right results, tuning the search to include less noise, and providing more information in each retrieved result. Libraries like LlamaIndex and LangChain are useful tools to optimize RAG.&#xA0;</p><p><a href="https://community.n8n.io/t/no-code-week-2024-from-gpts-to-custom-tailored-rag/48754?ref=blog.n8n.io"><u>This presentation</u></a> offers a good overview of retrieval-augmented generation.</p><h2 id="fine-tuning">Fine-Tuning</h2><p>Fine-tuning is the process of continuing the training process of the LLM on a smaller, domain-specific dataset to optimize it for the specific task. Fine-tuning is typically performed to improve model accuracy on a specific task by providing many examples of that task being performed correctly, and to improve model efficiency by achieving the same accuracy for fewer tokens or by using a smaller model.</p><p>The most important step in the fine-tuning process is preparing a dataset of training examples, which contains clean, labeled, and unbiased data.</p><h2 id="guardrails">Guardrails</h2><p>Guardrails refer to controlling the LLM input and output controls that detect, quantify and mitigate the presence of specific types of risks, such as prompt injection. There&#x2019;s an <a href="https://github.com/guardrails-ai/guardrails?ref=blog.n8n.io"><u>eponymous open source</u></a> project that provides a Python framework for implementing these additional protection mechanisms.&#xA0;</p><p>These can be used to check whether the generated text is toxic, that responses are provided in a neutral or positive tone, that responses do not contain any financial advice in line with FINRA guidelines, to prevent user&apos;s personal data from being leaked in the response, to prevent mentions of competitors and replace with alternate phrasing, and other similar use cases.</p><h1 id="deployment-models-for-ai-enhanced-workflow-automation">Deployment Models for AI-Enhanced Workflow Automation</h1><p>There are two options to run AI models within a workflow automation platform, namely to run the AI model natively in the tool, or to run the AI model as a standalone service and make requests over the network.&#xA0;</p><p><strong>AI Natively Integrated in the workflow automation tool</strong></p><ul><li><strong>Pros</strong>: No dependency on an external AI service, no data leaves the tool, no network-induced latency, and no per-request cost incurred.</li><li><strong>Cons</strong>: More complex setup and configuration, harder to change models.</li></ul><p><strong>Standalone AI model</strong></p><ul><li><strong>Pros</strong>: Easy setup and configuration, wide choice of models.</li><li><strong>Cons</strong>: Privacy and data loss concerns as data leaves the automation tool, induces network latency, incurs per-request cost.</li></ul><p>Both of these components - the AI model and the workflow tool - can either be deployed in an as-a-service model, where it is run and managed by the vendor or third party, or can be self-hosted.</p><p></p>
<!--kg-card-begin: html-->
<table style="border:none;border-collapse:collapse;table-layout:fixed;width:468pt"><colgroup><col><col><col></colgroup><tbody><tr style="height:0pt"><td style="border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><br></td><td style="border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:11pt;font-family:Arial,sans-serif;color:#000000;background-color:transparent;font-weight:700;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">AI Natively Integrated in the Workflow automation tool</span></p></td><td style="border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:11pt;font-family:Arial,sans-serif;color:#000000;background-color:transparent;font-weight:700;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Standalone AI model</span></p></td></tr><tr style="height:0pt"><td style="border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:11pt;font-family:Arial,sans-serif;color:#000000;background-color:transparent;font-weight:700;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Self-hosted</span></p></td><td style="border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:11pt;font-family:Arial,sans-serif;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Enterprise manages and runs the whole platform in their environment, whether on-premises or in the cloud</span></p></td><td style="border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:11pt;font-family:Arial,sans-serif;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Enterprise manages and runs the LLM in their environment (e.g., Ollama), </span><span style="font-size:11pt;font-family:Arial,sans-serif;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">whether on-premises or in the cloud</span></p></td></tr><tr style="height:0pt"><td style="border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:11pt;font-family:Arial,sans-serif;color:#000000;background-color:transparent;font-weight:700;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">As-a-service</span></p></td><td style="border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:11pt;font-family:Arial,sans-serif;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Platform run by the vendor in the Cloud</span></p></td><td style="border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:11pt;font-family:Arial,sans-serif;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">LLM run in the Cloud and integrated via API requests (e.g., ChatGPT)</span></p></td></tr></tbody></table>
<!--kg-card-end: html-->
<p>Out of the deployment models described above, the one that is uncommon and is worth further exploration is the self-hosted version of a workflow automation tool with AI natively integrated. We describe this in further detail below.</p><h2 id="self-hosting-workflow-automation-tools-with-integrated-ai">Self-Hosting Workflow Automation Tools with Integrated AI</h2><figure class="kg-card kg-image-card"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXdAZ-4mMp2B6v04knnnw3-GMGx5XTWjhiR9QUdlszogp1kQzlHEWbWpL2ySmNdU3xyPgUjLI1TLCy30LVMSjL61nBrm-CpUn8WyWqQwwcy3s5zNgKLkSZ-bHwlMmTX_XH2GoeN5?key=5Bu_i2rT_sZgQ-_nz7V586fH" class="kg-image" alt="AI Workflows for the Cautious Enterprise" loading="lazy" width="624" height="351"></figure><p>This model offers enterprises more control over how the AI model is run and managed, but entails a more hands-on approach compared to sending API requests to ChatGPT. Some of the difficulties in running AI locally include the choice of models, vector stores, and frameworks and configuring these components to work together.&#xA0;</p><p>To address this high entry barrier, n8n has released a <a href="https://blog.n8n.io/self-hosted-ai/"><u>Self-hosted AI Starter Kit </u></a>since August 2024. It consists of an open-source Docker Compose template that can initialize a local AI and low-code development environment. It includes the n8n workflow automation platform and a selection of best-in-class local AI tools, designed to be the fastest way to start building self-hosted AI workflows. As a virtual container-based appliance, it can be deployed both on-premises and in customer-managed cloud environments.</p><p>The kit uses Ollama as the API to interact with language models locally, Qdrant as a vector database, and PostgreSQL as a relational database. It also contains preconfigured AI workflow templates.&#xA0;</p><p>The starter kit also provides networking configurations to deploy locally or in cloud instances such as Digital Ocean and runpod.io. The starter kit is also designed to help organizations access local files by creating a shared folder which is mounted to the n8n container and allows n8n to access files on disk.</p><h1 id="integrating-ai-in-automation-workflows">Integrating AI in Automation workflows</h1><p>AI-based workflows typically focus on the capabilities delivered by the AI model, such as interpreting natural language commands, object recognition and categorization, or unstructured data analysis. AI-based workflows have custom logic defined before the AI model, such as the conditions when the workflow is triggered and fetching the right data, and after the AI model, such as validating responses and preventing data leaks.</p><p>When considering the time-to-value associated with automation tools that implement AI, organizations need to evaluate the vendor&#x2019;s portfolio of out-of-the-box workflows and the workflow designer itself.</p><p><strong>Ready-built workflows</strong> - the vendor can provide a marketplace or library of pre-built, pre-configured, and pre-validated AI templates that organizations can deploy with minimal configuration. These workflows need to be documented and modular such that any necessary changes dictated by the customer&#x2019;s technology stack can be easily implemented. These templates can either be developed directly by the vendor, or they can open the marketplace to allow members of the community to publish workflows. As an example,<a href="https://n8n.io/workflows/categories/ai/?ref=blog.n8n.io"><u> n8n offers a library of &gt;160 AI-based workflows</u></a>, many of which are free to use.&#xA0;</p><p><strong>Workflow designer</strong> - to support customers in writing new AI-based workflows, the vendor must provide adequate documentation that explains how the AI functionality is implemented in the automation logic. Further, it needs to provide development and staging environments, where customers can test the workflows before deploying these in production. Lastly, validation tools can identify any misconfigurations and security concerns in the playbooks, such as data which is not the expected format or calls to external services on unsecured channels.</p><h1 id="running-an-ai-workflow-tool-in-production">Running an AI Workflow Tool in Production&#xA0;</h1><p>Once the AI-based automation workflows have been designed, you need to consider how the tool will behave in production with respect to inference engines, scalability, monitoring, troubleshooting, authorization, and access.</p><h2 id="inference-engine">Inference Engine</h2><p>To run LLMs in production environments, you can choose between a range of inference engines. These run inference on trained machine learning or deep learning models across frameworks (PyTorch, Scikit-Learn,TensorFlow, etc.) or processors (GPU, CPU, etc). Most inference engines are open-source software that can standardize AI model deployment and execution.&#xA0;</p><p>Some of the most widely deployed inference engines include:</p><ul><li><a href="https://github.com/vllm-project/vllm?ref=blog.n8n.io"><u>vLLM</u></a></li><li><a href="https://github.com/PygmalionAI/aphrodite-engine?ref=blog.n8n.io"><u>Aphrodite-Engine</u></a></li><li><a href="https://github.com/triton-inference-server/server?ref=blog.n8n.io"><u>triton-inference-server</u></a></li><li><a href="https://github.com/huggingface/text-generation-inference?ref=blog.n8n.io"><u>Hugging Face TGI</u></a></li></ul><h2 id="scalability">Scalability</h2><p>Scalability considerations for running AI-enhanced automation workflows includes both the AI model&#x2019;s scalability and the workflow tool&#x2019;s.</p><p>For the workflow tool, scalability can consist of</p><ul><li>Dynamic scaling: This involves adding more resources dynamically as the amount of data ingested increases. While cloud-based solutions can provision these resources automatically, the self-hosted equivalent involves adding more instances for horizontal scalability with minimal disruption or additional configuration.</li><li>Absolute scale limits: These can be hard limits such as the number of concurrent workflows, maximum file sizes, maximum number of actions per playbook.</li><li>Support considerations: Smaller vendors with a scalable product may struggle to provide in-house enterprise-grade support for very large deployments, which includes support tickets and incident management. Furthermore, they may not have yet developed partnerships with third-party services providers that can help with large operations.</li><li>Pricing considerations: Some vendor pricing mechanisms may lock customers out of large or growing deployments, which forces organizations to compromise on the types of data they ingest, store, or analyze.</li></ul><p>For AI models hosted in the cloud by third parties (i.e. ChatGPT), main scalability concerns revolve around pricing, where the cost of large numbers of requests outweigh any efficiencies gained by implementing AI.</p><p>For self-hosted AI models scalability, considerations include maximum data input volume, maximum output, rate of errors, and mean time to get an output. Compute infrastructure is the main factor for scaling AI models, where the underlying hardware must have enough processing power to support requests and also support for horizontal scaling. When choosing to host the model in the cloud, horizontal scalability is not generally a concern, but with on-premises deployments there is a hard limit on the number of servers available at any given time. The scale of deployment directly correlates with the model&apos;s size and complexity, with smaller models (1-3 billion parameters) requiring substantially less compute infrastructure compared to large language models with 30-70 billion parameters.</p><p>Self-hosted models also have some control over response times. Model choice once again may have an impact, where small models can respond in 100-500 milliseconds, while larger models might require 1-5 seconds per inference. This can further be tuned with techniques such as model quantization, distributed inference, batch processing, intelligent caching, and hardware acceleration.&#xA0;</p><p>In instances such as n8n&#x2019;s AI Starter Kit, using Kubernetes to orchestrate the containers running the workflow tool and large language model can help deliver horizontal scalability based on request demand. Besides horizontal scalability, using Kubernetes can also help with load balancing and request handling.</p><h3 id="gpu-requirements-for-self-hosting">GPU Requirements for Self-hosting</h3><p>To calculate how much GPU memory is required to run an LLM on-premises, you can use the following formula:</p><figure class="kg-card kg-image-card"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXd2O6INZEWhxEDKmagzxn_bXNWUOhlooQskVUbyDSeC4bjRDwmXi0f7jzzNHND5MyjBygDMgIm_Szn3A4qA0A4j49FJIZt_fMP_4jqCWAkdUTHyOewzcahtCyQBExFYDEVnDXw_oA?key=5Bu_i2rT_sZgQ-_nz7V586fH" class="kg-image" alt="AI Workflows for the Cautious Enterprise" loading="lazy" width="231" height="86"></figure><p><em>Source: https://ksingh7.medium.com/calculate-how-much-gpu-memory-you-need-to-serve-any-llm-67301a844f21</em></p><p>Where:</p><ul><li>M = GPU memory in GB</li><li>P = number of parameters</li><li>4B = 4 bytes per parameter</li><li>32 = 32 bits for the 4 bytes</li><li>Q = number of bits used for loading the model</li><li>1.2 = 20% overhead allocation</li></ul><p>As an example, applying this formula for Llama-3.1-70b, which has 70 Billion Parameters, we get a total of 168GB or GPU memory. This would require&#xA0; two NVIDIA A-100 80GB memory models to run.</p><p>In instances where computational power for hosting AI is limited, you can reduce the compute and memory costs using <a href="https://huggingface.co/docs/optimum/en/concept_guides/quantization?ref=blog.n8n.io#quantization"><u>quantization</u></a>. It is a technique that enables the AI model to operate with less memory storage, consume less energy (in theory), and perform operations like matrix multiplication faster. It does so by representing the weights and activations with low-precision data types like 8-bit integers instead of the usual 32-bit floating point.</p><p>Applying this quantization technique to the above calculation for Llama 70B, using float16 precision instead of float32 would cut the memory requirement in half.</p><h2 id="authorization-and-authentication">Authorization and Authentication</h2><p>As AI-enhanced workflows can have multiple business owners and access various data resources, authorization and role based access controls can help segregate access to reduce privacy concerns and attack surface.</p><p><strong>User access controls</strong> refers to how permissions are granted and managed to administrators, developers, and non-developers that have access to the workflow designer.</p><p><strong>Service access controls</strong> refers to how the workflow automation tool can access other services and databases, such as providing API keys or JWT tokens, allowing access only through specific ports, requiring encryption, and the like.</p><h2 id="monitoring-and-error-handling">Monitoring and Error Handling</h2><p>Workflow automation tools can implement monitoring capabilities for each step or action that takes place within the workflow, including any AI agents. These can report on execution times, errors, API codes, and generate logs.&#xA0;</p><p>To monitor the performance of AI agents, tools can track performance against:</p><ul><li>Latency - How quickly an LLM can provide a response after receiving an input. Faster response times enhance user satisfaction and engagement.</li><li>Throughput - The number of tasks or queries an LLM can handle within a given time frame, for assessing the model&apos;s capability to serve multiple requests simultaneously. This is important for scalability and performance in production environments.</li><li>Resource Utilization - How efficiently an LLM uses computational resources, such as CPU and GPU memory. Optimal resource utilization ensures that the model runs efficiently, enabling cost-effective scaling and sustainability in deployment.</li></ul><p>Based on the reported metrics, organizations can implement multiple layers of validation, including:</p><ul><li>Input preprocessing and sanitization</li><li>Confidence threshold monitoring</li><li>Fallback mechanisms for low-confidence predictions, such as implementing human agents in the loop</li></ul><p></p><h1 id="n8n-for-building-ai-based-workflows">n8n for Building AI-based Workflows</h1><p>Secure and privacy-first AI is a core strategy for n8n, so we have developed a range of features that make use of AI. At n8n, we use AI-enhanced workflows internally for a variety of use cases, which include:</p><ul><li>Battlecard bot</li><li>Our own AI assistant for errors</li><li>Template reviews&#xA0;</li><li>Classifying and assigning bugs&#xA0;</li><li>Classifying forum posts</li></ul><p>We are also building a library of community-built AI content, which<a href="https://n8n.io/workflows/categories/ai/?ref=blog.n8n.io"><u> you can explore here</u></a>. We encourage members of the community to <a href="https://n8n.notion.site/n8n-Creator-hub-7bd2cbe0fce0449198ecb23ff4a2f76f?ref=blog.n8n.io"><u>become creators</u></a> and submit their own templates.</p>]]></content:encoded></item><item><title><![CDATA[How to make an AI chatbot: A step-by-step guide]]></title><description><![CDATA[Learn how to build an AI chatbot step by step using n8n. From defining your chatbotâ€™s purpose to integrating LLMs, external data, and memory for contextâ€”this guide covers everything you need to create a powerful, automated chatbot.]]></description><link>https://blog.n8n.io/how-to-make-ai-chatbot/</link><guid isPermaLink="false">67b0abe9793d5b0001a322c8</guid><category><![CDATA[AI]]></category><category><![CDATA[Tutorial]]></category><dc:creator><![CDATA[Bela Wiertz]]></dc:creator><pubDate>Thu, 20 Feb 2025 09:18:57 GMT</pubDate><media:content url="https://blog.n8n.io/content/images/2025/02/Slide-16_9---81--1-.png" medium="image"/><content:encoded><![CDATA[<img src="https://blog.n8n.io/content/images/2025/02/Slide-16_9---81--1-.png" alt="How to make an AI chatbot: A step-by-step guide"><p><a href="https://blog.n8n.io/best-ai-chatbot/" rel="noreferrer">AI chatbots</a> are rapidly reshaping the way businesses and individuals interact with technology. These intelligent virtual assistants can handle customer inquiries, provide recommendations, and even automate complex workflows.</p><p>As a result, approximately 65% of organizations report <a href="https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai?ref=blog.n8n.io" rel="noreferrer">regular use of generative AI in at least one business function</a>, nearly double the percentage from ten months prior.</p><p><strong>Wondering how hard it is to make an AI chatbot?</strong></p><p>AI chatbot development is now more accessible than ever. Thanks to advancements in machine learning and user-friendly development platforms, businesses of all sizes can build an AI chatbot without requiring extensive technical expertise or resources.</p><p>In this article, you&#x2019;ll learn the seven key steps to building an AI chatbot, from defining its purpose to deployment. You&apos;ll also get a step-by-step guide to creating one <a href="https://n8n.io/ai/?ref=blog.n8n.io" rel="noreferrer">using n8n</a>, including chat triggers, AI integration, memory handling, and external data connections.</p><h2 id="7-key-steps-to-build-an-ai-chatbot">7 key steps to build an AI chatbot</h2><p>Now, the real work begins as you are about to find out how to create your AI chatbot. To make an AI chatbot from scratch, we take only 7 main steps:</p><h3 id="step-1-define-your-chatbot%E2%80%99s-purpose">Step 1: Define your chatbot&#x2019;s purpose</h3><p>Start by clearly identifying what you want your chatbot to achieve. Is it meant to assist with customer support, provide product recommendations, or automate routine tasks? Understanding the chatbot&#x2019;s role and the needs of your audience will guide all subsequent decisions.</p><h3 id="step-2-identify-your-target-audience-and-use-cases">Step 2: Identify your target audience and use cases</h3><p>Determine who will be interacting with your chatbot and in what context. Tailoring its functionality to the specific requirements of your users&#x2014;be they customers, patients, or employees&#x2014;ensures a more effective and engaging experience.</p><h3 id="step-3-choose-a-development-platform">Step 3: Choose a development platform</h3><p>Decide on the tools and platforms that best fit your requirements. With the increasing ease of AI chatbot development, there are many options available, ranging from code-based frameworks to user-friendly automation tools. This choice will influence how you design and implement your chatbot. If you prefer coding, languages like Python and JavaScript offer powerful libraries and frameworks for building AI chatbots, such as TensorFlow, Rasa, or Node.js-based solutions.</p><h3 id="step-4-design-the-conversation-flow">Step 4: Design the conversation flow</h3><p>Map out how interactions with your chatbot should progress. Outline the key conversation paths, common questions, and expected responses. A well-planned dialogue structure ensures that your chatbot can handle inquiries smoothly and intuitively.</p><h3 id="step-5-leverage-state-of-the-art-llms-for-conversational-intelligence">Step 5: Leverage state-of-the-art LLMs for conversational intelligence</h3><p>Modern AI chatbot development is powered by large language models (LLMs) that offer state-of-the-art natural language processing capabilities. Instead of relying on traditional NLP models, LLMs&#x2014;such as OpenAI&apos;s GPT series&#x2014;provide the ability to interpret user input, capture context, and generate human-like responses with remarkable fluency and adaptability. By integrating these advanced models, your chatbot can handle diverse queries, understand nuanced conversations, and offer contextually relevant replies that mimic natural dialogue.</p><h3 id="step-6-connect-to-external-data-sources-and-channels">Step 6: Connect to external data sources and channels</h3><p>Consider how your chatbot will access additional information or perform specific tasks. This might include integrating APIs, databases, or third-party services to enrich responses or trigger actions, ensuring your chatbot remains dynamic and resourceful.</p><h3 id="step-7-test-refine-and-deploy">Step 7: Test, refine, and deploy</h3><p>Finally, run thorough tests to simulate real-world interactions. Gather feedback to fine-tune conversation flows and functionality before deploying the chatbot. Monitoring its performance post-deployment will help you make ongoing improvements and keep it aligned with user needs.</p><h2 id="a-step-by-step-guide-to-creating-an-ai-chatbot-with-n8n">A step-by-step guide to creating an AI chatbot with n8n</h2><p>When it comes to building AI chatbots, n8n offers a powerful yet user-friendly solution that makes the process much easier.</p><p>Unlike traditional development approaches that involve writing complex scripts, <a href="https://app.n8n.cloud/register?ref=blog.n8n.io"><u>n8n</u></a> provides a visual workflow builder that simplifies automation <a href="https://community.n8n.io/t/how-to-build-a-chat-with-your-document-chatbot-step-by-step-tutorial/39771?ref=blog.n8n.io"><u>without requiring extensive coding knowledge</u></a>. This means you can create a chatbot faster and with more flexibility, all while maintaining full control over its functionality.</p><p>One of <a href="https://n8n.io/features/?ref=blog.n8n.io"><u>n8n&#x2019;s standout features</u></a> is its ability to seamlessly integrate with various APIs, databases, and external tools&#x2014;allowing your chatbot to pull in real-time data, store conversation history, and execute automated tasks.</p><p>Additionally, its modular, no-code approach enables both beginners and experienced developers to experiment, iterate, and scale their chatbots without technical barriers.</p><p>By leveraging n8n, you gain a powerful yet accessible way to build an AI chatbot that is both intelligent and highly customizable:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfajg-QFGBfgJ8l0TZycPMKH-U35_3MJespdqdFQXvdxN7rpF53dui4Je1mQwKq3UqkCB1voW_dd2e29Rq96fzMhFW0HotGcE_HwSrSk3U9urFhLSKgEp2Ol_WquiBWDwyBZUvnmA?key=kWUvemwgnAXIrMjXkrDepi-4" class="kg-image" alt="How to make an AI chatbot: A step-by-step guide" loading="lazy" width="485" height="271"><figcaption><span style="white-space: pre-wrap;">A step-by-step guide to creating an AI chatbot with n8n</span></figcaption></figure>
<!--kg-card-begin: html-->
<script>
  workflowBanner(1954, document.currentScript);
</script>
<!--kg-card-end: html-->
<p>This workflow leverages <a href="https://n8n.io/integrations/openai/?ref=blog.n8n.io" rel="noreferrer">OpenAI&apos;s</a> language models and <a href="https://n8n.io/integrations/serpapi/?ref=blog.n8n.io" rel="noreferrer">SerpAPI</a> to power a dynamic and intelligent conversational agent. With built-in manual chat triggers and a memory buffer, it ensures smooth, context-aware interactions, delivering accurate and responsive conversations.</p><h3 id="step-1-start-with-a-chat-trigger">Step 1: Start with a Chat Trigger</h3><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfN9gL_VMUZu5KVW6MTLnlNBTPno7RTlC_vnMCIW9Wfg-YBywVGIVAWL_Rzri_yEr_XQt9isxcJJem3ugofVm1gJM7Qi5tgC-MP1FkrwvFd_KR1sB7feSXxzU5HODf71a-67EJy4A?key=kWUvemwgnAXIrMjXkrDepi-4" class="kg-image" alt="How to make an AI chatbot: A step-by-step guide" loading="lazy" width="294" height="225"><figcaption><span style="white-space: pre-wrap;">Step 1: Start with a chat trigger</span></figcaption></figure><p>Begin by adding a <a href="https://n8n.io/integrations/chat-trigger/?ref=blog.n8n.io" rel="noreferrer">chat trigger</a> node to your workflow.</p><ul><li><strong>Purpose:</strong> This node listens for incoming messages and starts the chat as soon as the first message comes in.</li><li><strong>Configuration:</strong> You can decide whether you would like to make the chat publicly available. For testing purposes, keep this option disabled for now.</li></ul><h3 id="step-2-connect-the-chat-trigger-to-an-ai-agent-node">Step 2: Connect the Chat Trigger to an AI Agent node</h3><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXcQ3mB_SH8QLngyyx_2xgjY-uVCFnUa9WG6AySiyPq1oH9a0AuX-II8mG-KFvNAyTvb0CUwuEMHncFBoejs-Hf3sw8BUI1azjjngZ3mcU51a8zKhHlRiAN1sSQRu0i53LQouf_t5A?key=kWUvemwgnAXIrMjXkrDepi-4" class="kg-image" alt="How to make an AI chatbot: A step-by-step guide" loading="lazy" width="263" height="272"><figcaption><span style="white-space: pre-wrap;">Step 2: Connect chat trigger to an AI agent node</span></figcaption></figure><p>Connect the chat trigger to a central <a href="https://n8n.io/integrations/agent/?ref=blog.n8n.io" rel="noreferrer">AI agent node</a>.</p><ul><li><strong>Purpose:</strong> This node serves as the decision-maker that parses user input and determines which operations to execute.</li><li><strong>Configuration:</strong> The source for the prompt is our connected chat trigger node. If you want tool use, pick &#x201C;Tools Agent&#x201D;, and if you don&#x2019;t, pick &#x201C;Conversational Agent&#x201D;.</li></ul><h3 id="step-3-integrate-your-chat-model">Step 3: Integrate your Chat Model</h3><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXe20NEuQfLmfd-UC6f_dMO_M9dzSQ6F24jT_ob_E6xiSBmT1POQd3SFgfsn8HV6zVtCMbbv0tfka7Nz_XqlMFr5FMXB57WPIfN2yQ1FdgxgIMo8QcrHmZ7302rsIBk2DX6xVCGDww?key=kWUvemwgnAXIrMjXkrDepi-4" class="kg-image" alt="How to make an AI chatbot: A step-by-step guide" loading="lazy" width="264" height="213"><figcaption><span style="white-space: pre-wrap;">Step 3: Integrate your Chat Model</span></figcaption></figure><p>Add an AI chat model node (such as one powered by OpenAI) immediately after the agent.</p><ul><li><strong>Purpose:</strong> This is where the heavy lifting happens&#x2014;the model processes the text from the agent and generates a response.</li><li><strong>Configuration:</strong> Choose your favorite model provider and a suitable model for your purpose. Other than that, you can change parameters such as temperature or maximum number of tokens, but this is more important for optimization than for setup.</li></ul><h3 id="step-4-incorporate-a-memory-node-for-context">Step 4: Incorporate a Memory node for context</h3><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfV6x-hhFLrjpzy0SUuFDSA6bw8Wxvm9kIjYTIZH9_sPXqfv7Ij-4y7wohFPalI3tQ-vk_pg63Eikjx0vGfrwp7ZSa3NfuD8qr4SSfz1M4_1KShoLvXB6EPAFb03eRADkgzbo4XWw?key=kWUvemwgnAXIrMjXkrDepi-4" class="kg-image" alt="How to make an AI chatbot: A step-by-step guide" loading="lazy" width="338" height="213"><figcaption><span style="white-space: pre-wrap;">Step 4: Incorporate a Memory node for context</span></figcaption></figure><p>Include a memory storage node, like a <a href="https://n8n.io/integrations/window-buffer-memory/?ref=blog.n8n.io" rel="noreferrer">window buffer memory node</a>, in your workflow.</p><ul><li><strong>Purpose:</strong> To maintain conversational context, the node stores the last several messages (for example, the previous 5 interactions).</li><li><strong>Configuration:</strong> You should use the connected chat trigger node as session ID. The context length varies depending on your needs. Context length makes the LLM calls more expensive, so be aware. The usual range for this is between 5-20.</li></ul><h3 id="step-5-add-serpapi-for-enriched-responses">Step 5: Add SerpAPI for enriched responses</h3><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXcRZJhuVCnw8ZM8alNVdkdf2C7zdPB_PXsCudZ-KlSaePWlYQakm94_KxQMcuTRZZ2jZNpLtB9j6onziJVljMTFPpNj1qLZwywps29MZ0ra3kRTbn9N0LaL6w3wPtA2uJmonNrp9w?key=kWUvemwgnAXIrMjXkrDepi-4" class="kg-image" alt="How to make an AI chatbot: A step-by-step guide" loading="lazy" width="404" height="252"><figcaption><span style="white-space: pre-wrap;">Step 5: Add SerpAPI for enriched responses</span></figcaption></figure><p>Finally, integrate additional tools&#x2014;such as SerpAPI for web search. </p><p><strong>Purpose: </strong>These integrations allow your chatbot to fetch real-time data, ensuring that the responses are both relevant and current.</p><p><strong>Configuration:</strong> For SerpAPI you can select target country, language, and device as parameters for your queries.</p><h3 id="final-ai-chatbot-workflow-powered-by-n8n">Final AI chatbot workflow powered by n8n</h3><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXc25GzJEBdwo52jAyLhjF66G6iitQWUbjJDXtfGGEzWNYQzfWPQyZjmF0jvzJMQGafVPau1C4pZd-guhq_kJuEE5by56SgnxysJ_xjeusa0oDR0ZPk_we-npoUCIy3pHeyBcfkMvQ?key=kWUvemwgnAXIrMjXkrDepi-4" class="kg-image" alt="How to make an AI chatbot: A step-by-step guide" loading="lazy" width="602" height="357"><figcaption><span style="white-space: pre-wrap;">Final AI chatbot workflow powered by n8n</span></figcaption></figure>
<!--kg-card-begin: html-->
<script>
  workflowBanner(1954, document.currentScript);
</script>
<!--kg-card-end: html-->
<p>Now you are ready to go with a fully functioning AI Chatbot with n8n integrated with OpenAI AI models and the SerpAPI for live information retrieval.</p><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text">You can extend it with more tools from the <a href="https://n8n.io/integrations/?ref=blog.n8n.io" rel="noreferrer">extensive n8n tool library</a>, ranging from simple tools like a <a href="https://n8n.io/integrations/calculator/?ref=blog.n8n.io" rel="noreferrer">calculator</a> to making the AI Chatbot update your database with the <a href="https://n8n.io/integrations/postgres/?ref=blog.n8n.io" rel="noreferrer">Postgres tool node</a>.</div></div><h2 id="wrap-up">Wrap up</h2><p>In this guide, we&apos;ve seen how to build an AI chatbot&#x2014;from defining its purpose and target audience to choosing a platform, designing the conversation flow, and leveraging advanced LLMs for natural, context-aware responses.&#xA0;</p><p>By walking through the practical setup in n8n&#x2014;starting with a chat trigger, routing input to an AI agent, integrating an AI chat model, adding memory for conversational context, and enriching responses via SerpAPI&#x2014;you now have a complete blueprint for creating the most advanced AI chatbot.&#xA0;</p><p>If you&apos;re ready to enhance customer support, drive sales, or simply innovate your workflow, now is the perfect time to <a href="https://n8n.io/?ref=blog.n8n.io"><u>experiment with n8n</u></a> and transform your ideas into a fully operational AI chatbot.</p>
<!--kg-card-begin: html-->
<div class="content-banner">
  <div>
    <h3>Create your own AI chatbots workflows</h3>
    <p>Build complex automations 10x faster, without fighting APIs</p>
  </div>
  <a href="https://app.n8n.cloud/register?ref=blog.n8n.io" class="global-button blog-banner-signup">Try n8n now</a>
</div>
<!--kg-card-end: html-->
<h2 id="what%E2%80%99s-next">What&#x2019;s next?</h2><p>Looking to enhance your AI chatbot even further? Whether you&apos;re aiming to refine its workflow, integrate advanced tools, or scale it for larger applications, the journey doesn&#x2019;t stop here.</p><p>As AI automation continues to evolve, there are endless possibilities to explore, from optimizing performance to unlocking new capabilities.</p><ul><li><a href="https://www.youtube.com/watch?v=xQ1tCQZhLaI&amp;ab_channel=nocodecreative&amp;ref=blog.n8n.io"><u>Create a Branded AI-Powered Website Chatbot with n8n</u></a> - Go into detail with this community-created video tutorial</li><li><a href="https://www.youtube.com/watch?v=ROSdQjkOWhY&amp;ref=blog.n8n.io" rel="noreferrer">Step-by-Step YouTube Tutorial</a>: Create a Simple AI Chatbot with n8n.</li><li><a href="https://blog.n8n.io/best-ai-chatbot/" rel="noreferrer">The Best AI Chatbots</a> - Learn how to build unique assistants with n8n.</li></ul>
<!--kg-card-begin: html-->
<script>
  workflowBanner([2325, 2506, 2872, 2752], document.currentScript, { 
      workflowsHeader: "Workflows with AI chatbots powered by n8n"
  });
</script>
<!--kg-card-end: html-->
]]></content:encoded></item><item><title><![CDATA[Iterations, hallucinations, and lessons learned: Rebuilding our AI Assistant on n8n]]></title><description><![CDATA[<p>We like drinking our own champagne at n8n, so when it came to rebuilding our internal AI assistant, we decided to see if we could do it using our own tooling. And as engineers who think in code, it was an enticing challenge to step away from the command line</p>]]></description><link>https://blog.n8n.io/iterations-hallucinations-and-lessons-learned-rebuilding-our-ai-assistant-on-n8n/</link><guid isPermaLink="false">67b327f6793d5b0001a322db</guid><category><![CDATA[AI]]></category><dc:creator><![CDATA[Charley Mann]]></dc:creator><pubDate>Tue, 18 Feb 2025 08:19:20 GMT</pubDate><media:content url="https://blog.n8n.io/content/images/2025/02/rebuilding-ai-assistant1.png" medium="image"/><content:encoded><![CDATA[<img src="https://blog.n8n.io/content/images/2025/02/rebuilding-ai-assistant1.png" alt="Iterations, hallucinations, and lessons learned: Rebuilding our AI Assistant on n8n"><p>We like drinking our own champagne at n8n, so when it came to rebuilding our internal AI assistant, we decided to see if we could do it using our own tooling. And as engineers who think in code, it was an enticing challenge to step away from the command line and experiment on building with workflows. It took us a few months, but we did it, and pretty successfully too! Plus, we learned some valuable lessons along the way. If you&#x2019;re planning on building AI tools, we hope our endeavors will prove just as useful to you as they have for us.&#xA0;</p><h3 id="hard-code-hard-iterations">Hard-code, hard iterations</h3><p>We&#x2019;d been running a hard-coded internal AI Assistant for some time, but it was tricky to iterate on and far too complex for our PM colleagues to engage with. If you wanted to tweak the AI logic, improve a prompt, or just saw a potential efficiency gain, you needed to dive deep into the code. All-in-all, it was a solid piece of engineering but inaccessible to the folks who could benefit from it the most.&#xA0;</p><p>We liked the tooling we&#x2019;d used for the original AI Assistant, so we knew we&#x2019;d keep LangChain for orchestration and have everything running through GPT-4. But ultimately, we wanted to see if such a complicated AI use case could be built purely on n8n.&#xA0;</p><h3 id="the-ai-assistant">The AI Assistant</h3><p>n8n&#x2019;s Ai Assistant has three use cases:</p><ol><li>Debugging user errors</li><li>Answering natural language questions in a chat format</li><li>Helping users set up credentials&#xA0;</li></ol><p>At the backend, we run two huge vector sources that make up an internal Knowledge Base (KB) &#x2013; one is our documentation, the other is n8n&#x2019;s Forum. We instruct our assistant to read the documentation first, to prevent hallucinations, and then turn to the Forum for further insights.&#xA0;</p><p>We set up our data in chunks. Each chunk is saved with context so the assistant can understand what part of a document it&apos;s reading, and the wider context surrounding it. Of course, we automated n8n workflows to scrape the documentation three times a week to update the database. At the same time, we also scrape the Forum for questions that have corresponding answers, and couple them together in the KB. Drinking our own champagne ;-)</p><p>Both the AI Service and our internal instance where the workflows live have development and production environments, so we can work on them without changing the production versions directly.</p><p>Here&#x2019;s an overview of the main assistant components:</p><figure class="kg-card kg-image-card"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXc_O_ATF-L1_OMa2uhbmSleibIbGf87Swg9jp5tjRAjsGVdZJztFXwVjEqODpS0X1aLZFiEH1JUJi35FU6wl3mygDDHTe8kqtWQHRrMAEcF3s-FdIDqaGCSVMw9XzpPTnCyDhpQ?key=jkRWBvulaU0mlb-0kab9IZfI" class="kg-image" alt="Iterations, hallucinations, and lessons learned: Rebuilding our AI Assistant on n8n" loading="lazy" width="624" height="191"></figure><p></p><ol><li>n8n Front end: All messages sent by users from the assistant chat sidebar are first sent to our AI Service, which is a separate web service hosted internally.&#xA0;</li><li>AI Service: Handles authentication for the incoming requests and calls n8n webhook also with authentication so we make sure workflow accepts only requests from the AI Service</li><li>Assistant Workflows: Hosted on our internal instance. There is one main (Gateway) workflow that accepts webhook calls and routes to a specific agent, based on user mode.&#xA0;</li></ol><p>Under the hood we have four distinct agents that handle the Assistant&#x2019;s use cases. We chose this setup because each use case requires different input context and tooling. When a user initiates the Assistant, we route the request using n8n&apos;s Switch node to one of the four agents. The only downside of this approach is that once an agent has started a user chat, it cannot switch to another agent while in-session, so the user needs to start again.&#xA0;</p><p><strong>Debugging user errors</strong></p><p>Generic error helper: Initiated when users click Ask Assistant button from node output panel when there is an error in the node. This agent is specialized in debugging node errors, has context about the error and access to n8n documentation and forum answers</p><p>Code node error helper: Specialized in debugging errors in the Code Node. This agent is initiated when users click Ask Assistant button from node output panel when there is an error in the Code Node. It has context about user&#x2019;s code and access to n8n documentation. Beside answering questions this agent also can suggest code changes and apply them to currently open node if user chooses so.</p><p><strong>Answering natural language questions in a chat format</strong></p><p>Support agent: Responds to user requests when they just open up a chat and start asking questions. This agent has context about what users are currently seeing (workflow and nodes) and has access to n8n documentation and forum answers</p><p><strong>Helping users set up credentials&#xA0;</strong></p><p>Credentials helper: Initiated when users click on Ask Assistant button from the credentials modal. This agent has context about users&#x2019; current node and credentials they want to set up and has access to n8n documentation</p><h3 id="implementation">Implementation&#xA0;</h3><p>One of the trickiest things about working with AI is that the responses it produces can be completely unexpected. Ask a question one way, and you&#x2019;ll get a correct answer. Switch something as small as a name or number in the prompt, and you can end up with a wildly different response.&#xA0;</p><p>To mitigate this we started small, testing an agent on a user prompt like &#x201C;why am I seeing this?&#x201D;. We quickly realized that we needed to provide more context because the assistant would not necessarily digest what was on the user&#x2019;s screen before searching the KB. So we created a &#x201C;workflow info&#x201D; tool, which enables the Assistant to gather information about a specific workflow.</p><p>Now when users ask something about their workflow, or why they&apos;re seeing something specifically without explaining it, the assistant can use the &#x201C;workflow info&#x201D; tool to pull the error or the process from the context that is on the user&#x2019;s screen. Today our support chat is delivering accurate answers by looking at the schemas the user is viewing, and using this as part of its search. We&#x2019;ve included an example below, so you can see how the agent has access to different tools to debug user problems.&#xA0;</p><figure class="kg-card kg-image-card"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXdcsobtdG4fsXiwAFIjm0TGSCKaxSFe7_nY6qzsTUBAoKdDODrgXsStieQ4ff4_5u2O1p5CIWIexce-NdeSnktxVOqaCrx9-mTSJK-RVW8fr1c8mmOTLXr3UnSIQjLh0DQp8QL7wg?key=jkRWBvulaU0mlb-0kab9IZfI" class="kg-image" alt="Iterations, hallucinations, and lessons learned: Rebuilding our AI Assistant on n8n" loading="lazy" width="523" height="372"></figure><h4 id="ai-to-evaluate-ai">AI to evaluate AI</h4><p>We save executions, so all our traces are available directly in n8n, which means we have a fantastic set of internal traces for evaluating tests and prompt changes. Since we have a rich dataset of traces, we thought &#x2018;why not use AI to fast-track the iteration process?&#x2019; and rolled out an LLM to judge the responses our LLM was producing.</p><p>However, we made a rookie error in giving the same instructions to both the Assistant and the Judge:<em> make responses helpful, actionable, and brief</em>. This resulted in the Judge scoring every answer perfectly. So we iterated a bit on the framework.</p><p>Internally, we have a custom validation project set up in LangSmith where we can run the Assistant against different sample requests from our traces and get a score on answer quality. This enables us to test different prompts and models quickly. It took a lot of experimentation to arrive at a framework that works reliably, and of course, every time we change something we have to test it. But now we have almost 50 use cases and we can more accurately test how our changes are improving or decreasing the quality of responses.</p><p>Today, the LLM Judge receives a user prompt and the output from the Assistant, and it judges and scores the output against a set of instructions, such as &#x2018;should X be included, is this a high-priority, is this output actionable?&#x2019; etc. So far, the quality seems to be a bit better than our old model!</p><h3 id="lessons-learned">Lessons learned&#xA0;</h3><p><strong>Time lag is ok</strong></p><p>Something we realized early on is that users don&#x2019;t mind waiting a few seconds for useful responses. We assumed that an agent taking 10 seconds to stream a response would be a barrier to adoption, but it&apos;s not at all. So even though we&#x2019;ve noticed a slight increase in response times, we haven&#x2019;t seen a decrease in error resolution.&#xA0;&#xA0;</p><p><strong>Iterate, iterate, iterate!</strong></p><p>As engineers, we often lean on our gut feelings in code &#x2013; you can see where to make tweaks and see how the program responds. But with AI, you can try asking the same question in a different way and end up with a completely different answer. And sometimes you change a prompt to find that it proves one use case, but it makes three others worse!</p><p>AI is so much less deterministic, and the way you evaluate and evolve the responses you&#x2019;re getting has to be approached with a different mindset. Trial and error became the new normal for us as we iterated on every aspect of our assistant to see what would work. While this took some time investment, ultimately it paid off because we now have high-quality responses, and response times just keep improving.&#xA0;</p><p><strong>Be open beyond code&#xA0;</strong></p><p>We&#x2019;re engineers and it was admittedly a challenge to switch our engineering outlook to move from working in code, to working in workflows. This project completely changed our minds on low-code approaches &#x2013; it was so much easier building and migrating our AI assistant than we&#x2019;d envisaged and we&#x2019;re really impressed with how successful this project has been on such a large-scale dataset.</p><p>&#xA0;&#xA0;&#xA0;</p><h3 id="what%E2%80%99s-next">What&#x2019;s next?</h3><p>Word got out pretty quickly about our new AI Assistant, and n8n&#x2019;s Support Team is already leveraging the KB and AI workflows we built to see if they can improve the quality and speed of their responses.</p><p>We&#x2019;re now looking at how we can increase the abilities of our AI Assistant over time &#x2013; like being able to build a workflow from a prompt. And because we&#x2019;ve set everything up in n8n, we can also easily experiment with different LLMs for auxiliary actions. We&#x2019;re also considering introducing another AI Agent to the four that we currently run, so that users will be able to switch agents while in-session.</p><h4 id="give-it-a-spin">Give it a spin</h4><p>We&#x2019;re open source enthusiasts &#x2013; so of course we&#x2019;ve published AI Assistant workflows! Have a look at some of our popular templates below, and let us know what you think.&#xA0;</p><p><a href="https://n8n.io/workflows/2753-rag-chatbot-for-company-documents-using-google-drive-and-gemini/?ref=blog.n8n.io"><u>RAG Chatbot for Company Documents using Google Drive and Gemini</u></a><br>&#x1F449; This workflow implements a Retrieval Augmented Generation (RAG) chatbot that answers employee questions based on company documents stored in Google Drive. </p><p><a href="https://n8n.io/workflows/2850-bamboohr-ai-powered-company-policies-and-benefits-chatbot/?ref=blog.n8n.io"><u>BambooHR AI-Powered Company Policies and Benefits Chatbot</u></a><br>&#x1F449; This workflow enables companies to provide instant HR support by automating responses to employee queries about policies and benefits.</p><p>You can also connect with <a href="https://www.linkedin.com/in/niklashatje/?ref=blog.n8n.io">Niklas</a> and <a href="https://www.linkedin.com/in/milorad-filipovi%C4%87-47188882/?ref=blog.n8n.io">Milorad</a> on LinkedIn and learn directly from them. </p>]]></content:encoded></item><item><title><![CDATA[The 20 best LLMs for coding (+ free workflow templates)]]></title><description><![CDATA[Explore the top 20 LLMs for coding and get free n8n workflow templates to integrate AI into your development process. Optimize automation, debugging, and code generation.]]></description><link>https://blog.n8n.io/best-llm-for-coding/</link><guid isPermaLink="false">678fbaefe794960001d974e8</guid><category><![CDATA[AI]]></category><category><![CDATA[Guide]]></category><dc:creator><![CDATA[Federico Trotta]]></dc:creator><pubDate>Tue, 11 Feb 2025 11:34:46 GMT</pubDate><media:content url="https://blog.n8n.io/content/images/2025/02/11-ai-tools-coding--1-.png" medium="image"/><content:encoded><![CDATA[<img src="https://blog.n8n.io/content/images/2025/02/11-ai-tools-coding--1-.png" alt="The 20 best LLMs for coding (+ free workflow templates)"><p>It&#x2019;s not a secret that <a href="https://n8n.io/integrations/basic-llm-chain/?ref=blog.n8n.io" rel="noreferrer">LLMs</a> have attracted a lot of attention in the last two years. But let&#x2019;s be honest: this happened for a good reason!</p><p>Today, LLMs are capable of processing vast codebases, supporting multi-language development, and even assisting in secure coding practices by identifying vulnerabilities and suggesting fixes.</p><p>For this reason, we classified the 20 best LLMs for coding to help you clarify the ideas around the best models, what they do, and why they&#x2019;re interesting.</p><p>So, in this article, you&#x2019;ll read the following:</p><ul><li>An overview of the current state of the LLMs landscape, with a bit of history;</li><li>The 20 best LLMs for coding;</li><li><a href="https://n8n.io/workflows/categories/ai/?ref=blog.n8n.io" rel="noreferrer">n8n workflows that leverage AI</a> and code to help you streamline your processes and how to set them up.</li></ul><p>Whether you&apos;re an IT manager who wants to improve operations or a DevOps engineer who wants to automate complex workflows, this guide will teach you everything you need to know about leveraging LLMs for coding in your enterprise environment.</p><p>Let&#x2019;s dive in!</p><h2 id="llms-for-coding-landscape">LLMs for coding landscape </h2><figure class="kg-card kg-image-card kg-width-wide kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXcgfrWrS_ZI7h6Y4-5i096L9fYHqAUQ_EXTDNcpkl1leFyOs3TvVgJKjKeL43KMua0Y1AMv3kWRlB65gidWIY6zANXFHzSRBKpE4gvUsBUnIWO_7bxG9nxrQJgYEz5YCTKYfJ8Ipg?key=V2J9xv6PXC5DZeqc4AtWjfpF" class="kg-image" alt="The 20 best LLMs for coding (+ free workflow templates)" loading="lazy" width="602" height="384"><figcaption><span style="white-space: pre-wrap;">The LLMs for coding landscape</span></figcaption></figure><p>The image shows that LLMs for coding can be subdivided based on the license &#x2013; open-source or commercial. Between these categories, the models can be:</p><ul><li>general-purpose (they manage text, code, images, and more),</li><li>coding-specific (designed specifically for managing code),</li><li>specific for research and fine-tuning,</li><li>or designed for enterprises&#x2019; needs.&#xA0;</li></ul><p>For the classification we made, we subdivided the LLMs into families based on who developed them. What&#x2019;s interesting to note is that some families provide open-source models and others that have proprietary licenses, depending on particular needs.</p><p>Other families, instead, provide both general-purpose and coding-specific models (Ollama is an example).</p><p>This tells a lot about the state-of-the-art of the LLMs for coding: companies and teams are probably trying to strike a balance between democratizing and expanding the use of LLMs&#x2013;thus, providing open-source models&#x2013;and the need to have the right business model to continue developing the models&#x2013;thus, providing models with proprietary license.</p><h2 id="the-20-best-llms-for-coding">The 20 best LLMs for coding</h2><p>Yes, we know: this landscape is vast. This is why we&#x2019;ve prepared a list of the 20 best LLMs for coding to help you clarify contexts, use cases, and peculiarities of the current state-of-the-art models.</p><p>Let&#x2019;s discover them!</p><h3 id="the-claude-3-family">The Claude 3 family</h3><p><strong>Best for:</strong> Generating new software architecture.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXeOjwebV-O17LDaBNCMkn_9a_DYELtVOSwO7xnCzKsdkxNRG99cplJTaEbtW49OkoBt3zDEUi4ZxKybaQk7OiSwTPNct5xhHAmlfaUALw-UZkd0nkrOUtBG1R9BIUGgwl6L6bJW7g?key=V2J9xv6PXC5DZeqc4AtWjfpF" class="kg-image" alt="The 20 best LLMs for coding (+ free workflow templates)" loading="lazy" width="602" height="407"><figcaption><span style="white-space: pre-wrap;">The Claude 3 UI - screenshot taken from the Claude 3 website</span></figcaption></figure><p><a href="https://www.anthropic.com/claude?ref=blog.n8n.io"><u>Claude 3</u></a>, developed by <a href="https://www.anthropic.com/?ref=blog.n8n.io"><u>Anthropic</u></a>, is a family of three AI models. Each has different performance capabilities, allowing users to have the right balance of cost, speed, and intelligence.</p><p>This family of LLMs consists of:</p><ul><li><strong>Claude Haiku</strong>: The fastest model that can execute lightweight actions, with industry-leading speed.&#xA0; Suitable for tasks that require speed but are also cost-effective is, however, the least performing among the family.</li><li><strong>Claude Sonnet</strong>: Provides the best combination of performance and speed for efficient, high-throughput tasks. It is the middle-of-the-road model among the three and it&#x2019;s more inclined to serve enterprise tasks like data processing, quality control, and product recommendations.</li><li><strong>Claude Opus</strong>: Is the highest-performing model, and can handle complex analysis, longer tasks with many steps, and higher-order math and coding tasks. It outperforms Sonnet and Haiku on many evaluation benchmarks for AI systems.</li></ul><p><strong>License:</strong></p><p>Proprietary/Commercial</p><p><strong>Key features for coding:</strong></p><p>The Claude 3 family is a general-purpose LLM family, so is suitable for coding tasks, among others. They can work with a wide variety of programming languages and frameworks&#x2013;but they are particularly proficient with Python and JavaScript/TypeScript.</p><p>Also, the Opus model excels in complex reasoning and advanced cognitive processing, making it suitable for generating new, high-level software architectures.</p><h3 id="the-gpt-family">The GPT family</h3><p><strong>Best for:</strong> Refactoring and modifying specific parts of a program.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXc9oEM_i6rROCWpWK_PYkvwAyleCHh8Lc6ILHvRKl60R2pbqqP4D8axZ3SriSDaCpsEpi8CbTc38jeU8aA7-pLONgsI_3SdOu-3X58NFqXi-peyh3s26x9Q5EKaME67jQFzQIRh?key=V2J9xv6PXC5DZeqc4AtWjfpF" class="kg-image" alt="The 20 best LLMs for coding (+ free workflow templates)" loading="lazy" width="602" height="255"><figcaption><span style="white-space: pre-wrap;">ChatGPT UI - screenshot taken from the ChatGPT website</span></figcaption></figure><p>The GPT family&#x2013;which stands for &#x201C;Generative Pre-trained Transformers&#x201D;&#x2013;is a family of LLMs based on the transformer deep learning architecture introduced by <a href="https://openai.com/?ref=blog.n8n.io"><u>OpenAI</u></a>.</p><p>Among the different <a href="https://platform.openai.com/docs/models?ref=blog.n8n.io"><u>products and models</u></a> released by OpenAI, ChatGPT is certainly the most famous. Its latest versions are currently based on the following models:</p><ul><li><a href="https://platform.openai.com/docs/models?ref=blog.n8n.io#gpt-3-5-turbo"><u>GPT-3.5 Turbo</u></a>: This general-purpose model can understand and generate natural language or code and has been optimized for chatting by using the Chat Completions API.&#xA0;</li><li><a href="https://platform.openai.com/docs/models?ref=blog.n8n.io#gpt-4o"><u>GPT-4o/mini/audio/realtime</u></a>: This sub-family of models is versatile and highly intelligent. The GPT-4o, for example, accepts both text and image inputs, and produces text outputs. Its &#x2018;mini&#x2019; version is fast and ideal for fine-tuning. The &#x2018;Realtime&#x2019; and &#x2018;Audio&#x2019; versions, instead, respond to audio and text inputs in real time and accept audio inputs and outputs, respectively.</li><li><a href="https://platform.openai.com/docs/models?ref=blog.n8n.io#o1"><u>GPT-o1/mini</u></a>: This series of models is trained with reinforcement learning to perform complex reasoning. In particular, the o1 models&#x2019; reasoning is designed to solve hard problems across domains; the o1-mini, instead, provides a fast and affordable reasoning model for specialized tasks.</li></ul><p><strong>License:</strong></p><p>Proprietary/Commercial</p><p><strong>Key features for coding:</strong></p><p>The GPT family is a general-purpose LLM family, but it is also suitable for coding tasks and for a wide variety of programming languages and frameworks.</p><p>Its coding features that are particularly loved by developers are:</p><ul><li><strong>API</strong>: You can access OpenAI models via <a href="https://openai.com/index/openai-api/?ref=blog.n8n.io"><u>API calls</u></a>. This allows you to leverage its LLMs via your preferred programming language, allowing you to prompt its models by using the APIs. This helps you integrate the power of AI into your coding projects.</li><li><strong>Canvas</strong>: The GPT-4o provides <a href="https://openai.com/index/introducing-canvas/?ref=blog.n8n.io"><u>Canvas</u></a>. With Canvas you can highlight specific sections to indicate exactly what you want ChatGPT to focus on. This means, for example, that you can directly edit a portion of code you highlighted without asking ChatGPT to recreate it all or avoiding copy-paste it into the editor.</li></ul><h3 id="codex">Codex</h3><p><strong>Best for:</strong> Coding in Python.</p><figure class="kg-card kg-image-card"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXeDCBRZCZcQqAtlJ5RpFeOQePs5a_2ktBijR9OFoAhsdHCF27RwCpuXMcxHYH9T7uEtHflwMKCGCwKJU5qNonWTIPS6b4-iofu2nNJTo9ZCi-hqnxw8ThdSWSfqGULGR7uMUnc3FQ?key=V2J9xv6PXC5DZeqc4AtWjfpF" class="kg-image" alt="The 20 best LLMs for coding (+ free workflow templates)" loading="lazy" width="602" height="505"></figure><p><a href="https://openai.com/index/openai-codex/?ref=blog.n8n.io"><u>OpenAI Codex</u></a>&#x2013;the model that powers <a href="https://github.com/features/copilot?ref=blog.n8n.io"><u>GitHub Copilot</u></a>&#x2060;&#x2013;is an advanced AI system designed to translate natural language into code, enhancing the programming experience by allowing users to interact with software through everyday language. As a descendant of GPT-3, Codex has been trained on a vast dataset that includes both natural language and billions of lines of publicly available source code, notably from GitHub repositories. This training enables Codex to proficiently understand and generate code in over a dozen programming languages.</p><p>Codex excels at breaking down complex problems into simpler components and mapping these components to existing code libraries or functions, which is often considered one of the more tedious aspects of programming. By automating this process, Codex lowers the barrier to entry for new programmers and enhances productivity for experienced developers.</p><p><strong>License</strong>:</p><p>Proprietary/Commercial.</p><p><strong>Key features for coding:</strong></p><p>Codex is specifically fine-tuned for programming tasks, making it particularly suitable at understanding and generating code.</p><p>What makes it particularly stand out is its 14KB memory capacity for Python code. This allows it to consider more contextual information when generating code, leading to more accurate Pythonic outputs.</p><h3 id="the-llama-family">The LLaMA family</h3><p><strong>Best for:</strong> Long contexts handling.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXcejjb5UO-SsZqYiEnbnDrPCBAC00Rf2pDx1dVCoK9aeqfaqZrFZ_xeeysw3MuBdLkEPzVZNqjzPakuM3PLdlSollNe2-mqUFsVXxJg5FKb0fBuhO_mKxddAf8mvvaT8UgKDZMl?key=V2J9xv6PXC5DZeqc4AtWjfpF" class="kg-image" alt="The 20 best LLMs for coding (+ free workflow templates)" loading="lazy" width="602" height="307"><figcaption><span style="white-space: pre-wrap;">The LLaMA website</span></figcaption></figure><p>The <a href="https://www.llama.com/?ref=blog.n8n.io"><u>LLaMA</u></a> (Large Language Model Meta AI) family is a series of advanced models developed by Meta. They are designed for natural language processing (NLP) tasks such as text generation, summarization, coding, reasoning, and more.</p><p>While LLaMA 3.x models are not specifically optimized for coding tasks&#x2013;but can handle them due to their general training&#x2013;the model specifically designed for coding purposes is <a href="https://codellama.dev/about?ref=blog.n8n.io"><u>Code LLaMA</u></a>.</p><p><strong>License</strong>:</p><p>Open-source (community license: free for research and commercial use but the training datasets are not publicly available).</p><p><strong>Key features for coding:</strong></p><p>Code LLaMA is the best choice of the family for coding tasks, as it is fine-tuned for programming. It offers advanced features like long context handling and support for multiple programming languages.</p><p>CodeLLaMA is itself a family of models and <a href="https://huggingface.co/codellama/CodeLlama-7b-Python-hf?ref=blog.n8n.io"><u>it is subdivided into</u></a>:</p><ul><li><strong>Base model</strong>: General-purpose coding model.</li><li><strong>Python-specific model</strong>: Fine-tuned for Python tasks.</li><li><strong>Instruct model</strong>: Optimized for instruction-following tasks, making it better at understanding and responding to natural language prompts about code.</li></ul><p>Note that all these models can be downloaded from the Ollama <a href="https://github.com/ollama/ollama?ref=blog.n8n.io"><u>library</u></a>, available both for Python and Javascript.</p><h3 id="mistral-ai">Mistral AI</h3><p><strong>Best for:</strong> Generating code suggestions.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXcmkGEIb3Uq73v6mmqAdxHUEavgLjiToW7T_wYSJhTwOlHRGaCixNShZglDYM0UrGtDwAEOT0vQ2VOlJV1jeKOigvYT5NcErss9wvPnK85YU4rcXh1WCHYcd_O4UUXU_hy93ZtX?key=V2J9xv6PXC5DZeqc4AtWjfpF" class="kg-image" alt="The 20 best LLMs for coding (+ free workflow templates)" loading="lazy" width="602" height="189"><figcaption><span style="white-space: pre-wrap;">Mistral UI - screenshot taken from the Mistral website</span></figcaption></figure><p>Mistral is a pre-trained, general-purpose, model developed by Mistral AI. Currently, their latest model is <a href="https://mistral.ai/news/announcing-mistral-7b/?ref=blog.n8n.io"><u>Mistral 7B</u></a> which has been pre-trained with 7 billion parameters.</p><p>One of the standout features of Mistral 7B is its open-weight nature, meaning the model weights are freely available to the public. This openness has made it a popular choice among researchers, developers, and organizations looking to integrate advanced AI capabilities into their workflows without the constraints of proprietary systems.</p><p><strong>License:</strong></p><p>Open-weight model (the model weights are freely available for download and use under the Apache 2.0 license).</p><p><strong>Key features for coding:</strong></p><p>Despite being a general-purpose model, Mistral 7 B approaches the performance of specialized models like Code Llama 7 B in code-related tasks. Thanks to advanced attention mechanisms like Grouped-Query Attention (GQA) and Sliding Window Attention (SWA), which enhance its efficiency and ability to handle longer sequences, Mistral 7B has fewer parameters but is still able to perform as well as GQA and SWA.</p><p>This can be of particular interest to developers, as Mistral 7B also provides <a href="https://docs.mistral.ai/api/?ref=blog.n8n.io"><u>public APIs</u></a>. Thus, it can be integrated into development tools like IDEs, enabling real-time code suggestions and improvements. It also supports fine-tuning for specific tasks, making it adaptable to various coding needs.</p>
<!--kg-card-begin: html-->
<script>
  workflowBanner([2333, 2335], document.currentScript, { 
      workflowsHeader: "Integrate Mistral's AI into your workflows with n8n"
  });
</script>
<!--kg-card-end: html-->
<h3 id="palm-2">Palm 2</h3><p><strong>Best for:</strong> Coding into specialized programming languages.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfoSCRq_CpMUoNLEWK7JwFBbXFywqwJ01r_ux6f13JurlsguQxttIsOblMHV-csZMCLomZvcXC1-Fu8BD1T8-Gd3dDK0zUOuERZBVQf_FQR2XIO_QDLJC0SbopEJRH-4L13d00i?key=V2J9xv6PXC5DZeqc4AtWjfpF" class="kg-image" alt="The 20 best LLMs for coding (+ free workflow templates)" loading="lazy" width="602" height="501"><figcaption><span style="white-space: pre-wrap;">The PaLM website</span></figcaption></figure><p>PaLM 2 (Pathways Language Model 2) is a state-of-the-art large language model developed <a href="https://ai.google/get-started/our-models/?ref=blog.n8n.io"><u>by Google</u></a>, designed to advance natural language understanding and generation.</p><p>One of the standout features of PaLM 2 is its enhanced multilingual proficiency. It supports over 100 languages and demonstrates a deep understanding of cultural nuances, idiomatic expressions, and context-specific meanings. This makes it particularly effective for translation, cross-lingual tasks, and global applications.</p><p><strong>License:</strong></p><p>Proprietary/Commercial</p><p><strong>Key features for coding:</strong></p><p>As a general model, PaLM is also suitable for coding purposes, supporting a wide range of programming languages, including Python, JavaScript, Go, and more.</p><p>As it has been trained on a vast dataset, it can also generate code in specialized languages like Prolog, Fortran, and Verilog.&#xA0;</p><h3 id="the-gemini-family">The Gemini family</h3><p><strong>Best for:</strong> Integrating into the Google ecosystem.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXf8CNsthoHFWTOP4jJcytBh1hmcemGpfhab5fw3mhTJTNtB9R22Sn3O8ofKaJgp7ix231154bDRuTiqNYiTA4TPLn8O6zhSB7uTvlxOMk_-jDiuZK-HUfGGa6p4SDI2iBmTiKY4Qw?key=V2J9xv6PXC5DZeqc4AtWjfpF" class="kg-image" alt="The 20 best LLMs for coding (+ free workflow templates)" loading="lazy" width="602" height="275"><figcaption><span style="white-space: pre-wrap;">The Gemini website</span></figcaption></figure><p>The Gemini family, developed by <a href="https://ai.google/get-started/our-models/?ref=blog.n8n.io"><u>Google DeepMind</u></a>, represents a diverse range of capabilities tailored to various use cases, from high-performance reasoning to efficient on-device tasks.</p><p>Currently, there are the following models in this family:</p><ul><li><strong>Gemini 2.0 Flash Experimental</strong>: The latest and most advanced model in the lineup. This experimental model introduces multimodal capabilities, including native image generation, text-to-speech, and real-time interaction through the Multimodal Live API.</li><li><strong>Gemini 1.0 Ultra and Gemini 1.5 Pro</strong>: The earlier models in the Gemini family that cater to more established use cases. Gemini 1.0 Ultra is the largest model in the family, designed for highly complex tasks like advanced coding, mathematical reasoning, and multimodal problem-solving. Gemini 1.5 Pro strikes a balance between performance and versatility, offering a 2 million token context window and the ability to process large-scale data, such as hours of audio or thousands of lines of code.</li><li><strong>Gemini 1.0 Pro and Gemini 1.0 Nano</strong>: These are for more lightweight and specialized applications. Gemini 1.0 Pro, though set to be deprecated in the first months of 2025, focuses on natural language tasks, multi-turn conversations, and code generation, serving as a foundational model for text-based applications. On the other hand, Gemini 1.0 Nano is optimized for on-device tasks, offering efficient performance for mobile and embedded systems.</li></ul><p><strong>License:</strong></p><p>Proprietary/Commercial</p><p><strong>Key features for coding:</strong></p><p>Among all the models, Gemini 2.0 Flash Experimental and Gemini 1.5 Pro excel in coding tasks. In particular, they can process extensive codebases, with context windows of up to 2 million tokens. This allows them to handle large-scale projects, such as analyzing thousands of lines of code or managing complex multi-file systems.</p><p>Finally, Gemini models can be integrated into Google&apos;s ecosystem, such as Google Cloud&apos;s Vertex AI, where developers can access its coding capabilities through the <a href="https://ai.google.dev/gemini-api/docs?hl=en&amp;ref=blog.n8n.io"><u>Gemini Developer APIs</u></a>. This makes it easy to incorporate its features into development pipelines and workflows.</p>
<!--kg-card-begin: html-->
<script>
  workflowBanner([2812, 2789, 2658], document.currentScript, { 
      workflowsHeader: "Integrate Gemini's AI into your workflows with n8n"
  });
</script>
<!--kg-card-end: html-->
<h3 id="codebert">CodeBERT</h3><p><strong>Best for:</strong> Clone detection.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXezDN2S9E9M7l7EoMTxnIr2graNTW922VYr4cjYGKG8Cq3v_wOc6ini_vx437Qm3xEV16p3VKrcqwGyNL5ryfrlWFv75zRC9bbE9UThE8nyEi2fKa1YHg53bRqk5ACoQe4_2UsFlw?key=V2J9xv6PXC5DZeqc4AtWjfpF" class="kg-image" alt="The 20 best LLMs for coding (+ free workflow templates)" loading="lazy" width="602" height="301"><figcaption><span style="white-space: pre-wrap;">CodeBERT - Screenshot taken from the CodeBERT repository on GitHub</span></figcaption></figure><p><a href="https://github.com/microsoft/CodeBERT?ref=blog.n8n.io"><u>CodeBERT</u></a>, developed by Microsoft, is a pre-trained model designed for programming and natural languages. It is part of a series of models designed to improve code understanding and generation tasks.</p><p>CodeBERT is a multi-programming-lingual model trained on natural language (NL) and programming language (PL) pairs across six programming languages: Python, Java, JavaScript, PHP, Ruby, and Go. The model is particularly useful for tasks such as code search, code documentation generation, and embedding generation for NL-PL pairs.</p><p><strong>License:</strong></p><p>Open source (MIT License).</p><p><strong>Key features for coding:</strong></p><p>CodeBERT is built on the <a href="https://huggingface.co/docs/transformers/main/index?ref=blog.n8n.io"><u>Hugging Face Transformers framework</u></a>, making it easy to load and use pre-trained models. Developers can integrate it into their workflows with minimal effort using familiar tools like <code>AutoTokenizer</code> and <code>AutoModel</code>.</p><p>As is it pre-trained on natural language and programming language pairs across six popular programming languages (Python, Java, JavaScript, PHP, Ruby, and Go), this makes this model particularly specialized in those programming languages.</p><p>Also, CodeBERT generates embeddings for both code and natural language, enabling tasks like code search, where developers can search for code snippets using natural language queries. It even supports semantic understanding of code, making it useful for tasks like code classification, clone detection, and bug detection.</p><h3 id="the-command-family">The Command family</h3><p><strong>Best for:</strong> Real-time applications.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXdyoTD8qqwqcTx6d6TzRGcT-4bg0Hq7u9-L6O_BnAA5TKSLX2H7riBDeHMp6tL-2sIfsa3jnhp6vwEBpehc7qI-AHyj0UooMAT3Bjw5incA-cX_CbYM6bvOQ6nYRYB5jwWWBdpIKQ?key=V2J9xv6PXC5DZeqc4AtWjfpF" class="kg-image" alt="The 20 best LLMs for coding (+ free workflow templates)" loading="lazy" width="602" height="295"><figcaption><span style="white-space: pre-wrap;">The Command website</span></figcaption></figure><p>The<a href="https://cohere.com/command?ref=blog.n8n.io"><u> Command family of models by Cohere</u></a> is a suite of high-performance, scalable language models designed to deliver strong accuracy and efficiency. These models are tailored for enterprise use, enabling businesses to transition seamlessly from proof-of-concept stages to production-grade applications.</p><p>By balancing efficiency and accuracy, these models are ideal for businesses looking to integrate AI into their workflows for tasks like content generation, document analysis, and large-scale data processing.</p><p><strong>License:</strong></p><p>Proprietary/Commercial.</p><p><strong>Key features for coding:</strong></p><p>Command models are optimized for tool use, meaning they can interact with external tools like APIs, databases, or search engines to enhance their functionality.&#xA0;</p><p>With a context window of up to 128K tokens (in models like Command R7B), these models can process and understand large codebases, making them suitable for complex coding tasks. Also, Models like Command R7B are optimized for high throughput and low latency, making them ideal for real-time.</p><h3 id="the-falcon-family">The Falcon family</h3><p><strong>Best for:</strong> Deployment on low-resource devices.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXdgsavkL0qHNXv9f1JZEBeUEII0Gj085o6gj5B2kj8m21Pd7auqn9MWjf7F-LhNWSsu79Vkc9fKphA32_qmSpCeyvJPg46M8zRolo03Ef0_BqEUH5UpablR4oIus45FlqwSWdL5dQ?key=V2J9xv6PXC5DZeqc4AtWjfpF" class="kg-image" alt="The 20 best LLMs for coding (+ free workflow templates)" loading="lazy" width="602" height="267"><figcaption><span style="white-space: pre-wrap;">The Falcon website</span></figcaption></figure><p><a href="https://falconllm.tii.ae/?ref=blog.n8n.io"><u>The Falcon LLM models</u></a>, developed by the Technology Innovation Institute (TII) in Abu Dhabi, represent a cutting-edge suite of open-source large language models (LLMs) designed to democratize access to advanced AI.&#xA0;</p><p>This ecosystem currently includes the following models:</p><ul><li><strong>Falcon 3</strong>: Lightweight and resource-efficient model that can run on minimal infrastructure, including laptops, without sacrificing performance. It includes four scalable models optimized for multilingual and diverse applications.</li><li><strong>Falcon Mamba 7B</strong>: The first open-source State Space Language Model (SSLM), offering low memory costs and the ability to generate long text blocks efficiently. It outperforms traditional transformer models like Meta&#x2019;s Llama 3.1 8B and Mistral 7B.</li><li><strong>Falcon 2</strong>: A multilingual and multimodal model with vision-to-language capabilities. It outperforms Meta&#x2019;s Llama 3 8B and rivals Google&#x2019;s Gemma 7B, with plans to incorporate &quot;Mixture of Experts&quot; (MoE) for enhanced performance.</li><li><strong>Falcon 40B</strong>: A 40-billion-parameter model trained on one trillion tokens, designed for both research and commercial use. It was the first open-source large language model released with weights under the permissive Apache 2.0 license.</li><li><strong>Falcon 180B</strong>: A 180-billion-parameter model trained on 3.5 trillion tokens, ranking as one of the most powerful open-source LLMs globally. It is available for research and commercial use under a royalty-free license.</li></ul><p><strong>License:</strong></p><p>All Falcon models are open source, but Falcon 180B has additional licensing conditions for specific use cases, particularly for shared hosting services.</p><p><strong>Key features for coding:</strong></p><p>Falcon models are built on a transformer-based causal decoder architecture, which is well-suited for coding tasks, but they are general-purpose models.</p><p>However, the best LLM for coding in this family is Falcon 3 as it offers quantized versions, making it efficient for deployment on low-resource devices, which can be useful for lightweight coding tools.</p><h3 id="the-stability-family">The Stability family</h3><p><strong>Best for:</strong> Filling code in the middle of tasks (FIM).</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXccBMAtywKVVI2C3MkCups6rV096gZzCSZVQJxw2qi1rtFo7NAJKU6m8KoVYSSw9l_EjqKzqasRoErllowtU-qGB3GUD-0y-GjjEbPL98r3f5bTxZv6P5JPg4QSEl01jRWdumHjvw?key=V2J9xv6PXC5DZeqc4AtWjfpF" class="kg-image" alt="The 20 best LLMs for coding (+ free workflow templates)" loading="lazy" width="602" height="331"><figcaption><span style="white-space: pre-wrap;">The Stability website</span></figcaption></figure><p><a href="https://stability.ai/stable-lm?ref=blog.n8n.io"><u>Stability AI&apos;s language models</u></a>, branded under the &quot;Stable LM&quot; series, are designed for a wide range of applications, from multilingual communication to specialized tasks like coding and instruction-following. In addition to general-purpose LLMs, Stability AI offers specialized models like Stable Code 3B and Stable Code Instruct 3B, which are optimized for software development tasks such as code generation and completion.&#xA0;</p><p>Here&#x2019;s how this family of LLMs is composed:</p><ul><li><strong>Stable LM 2 12B</strong>: A 12-billion-parameter multilingual model trained in English, Spanish, German, Italian, French, Portuguese, and Dutch, available in both base and instruction-tuned versions for versatile applications.</li><li><strong>Stable LM 2 1.6B</strong>: A smaller, 1.6-billion-parameter multilingual model offering state-of-the-art performance in multiple languages, designed for lightweight and efficient deployment.</li><li><strong>Stable Code 3B</strong>: A 3-billion-parameter model optimized for accurate and responsive code completion, comparable to larger models like CodeLLaMA 7B but more efficient.</li><li><strong>Stable LM Zephyr 3B</strong>: A lightweight 3-billion-parameter chat model fine-tuned for instruction-following and Q&amp;A tasks, offering responsive and user-friendly interactions.</li><li><strong>Japanese Stable LM</strong>: A specialized model trained exclusively in Japanese, achieving top performance on various Japanese language benchmarks.</li><li><strong>Japanese Stable LM 2 1.6B</strong>: A 1.6-billion-parameter Japanese language model available in both base and instruction-tuned versions, tailored for diverse Japanese language tasks.</li><li><strong>Stable Beluga</strong>: A powerful LLM with exceptional reasoning abilities, suitable for tasks like copywriting, answering scientific questions, and generating creative ideas.</li><li><strong>Stable Code Instruct 3B</strong>: An instruction-tuned version of Stable Code 3B, capable of handling code generation, math, and other software development tasks with natural language prompts.</li></ul><p><strong>License:</strong></p><p>The base Stable LM models, such as Stable LM 2 12B and Stable LM 2 1.6B, are open source and can be freely used, modified, and adapted for various purposes.</p><p>Fine-tuned models, such as Stable LM 2 12B (Instruction-Tuned) or Stable Beluga, trained on datasets like Alpaca or GPT4All, are released under proprietary licenses.</p><p><strong>Key features for coding:</strong></p><p>Among all the stability models, the best coding LLM is Stable Code 3B. In particular, it stands out for its ability to perform FIM (Fill-in-the-Middle) tasks. This ability allows this model to generate code that fills in a missing section in the middle of an existing code snippet. This is different from traditional code completion, which typically involves generating code at the end of a snippet.</p><h3 id="starcoder">Starcoder</h3><p><strong>Best for:</strong> Inferencing AI models.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXcrYlq4GLNIDQWBRnYy8WCrPzafFHJ2UPFzH4COD1tE05Y-mqMiKS_x42KEDIOmlXRO94htLoof-BwFrmrP0vFKLWr9Y28FIsOV4jRKbkJkpnf-yEkflUwwzcWVuMHABHutSd-hQg?key=V2J9xv6PXC5DZeqc4AtWjfpF" class="kg-image" alt="The 20 best LLMs for coding (+ free workflow templates)" loading="lazy" width="602" height="272"><figcaption><span style="white-space: pre-wrap;">The Starcoder website</span></figcaption></figure><p><a href="https://github.com/bigcode-project/starcoder?ref=blog.n8n.io"><u>StarCoder</u></a> is a language model (LM) developed by the <a href="https://www.bigcode-project.org/?ref=blog.n8n.io"><u>BigCode project</u></a>, designed to handle both source code and natural language text. It has been trained on a diverse dataset that includes over 80 programming languages, as well as text from GitHub issues, commits, and notebooks and this makes it particularly adept at tasks like code generation.&#xA0;</p><p>The model is accessible through the Hugging Face Transformers library, enabling developers to integrate it into their workflows for coding assistance and generation. The model has been fine-tuned to function as a coding assistant, with a specific focus on enhancing its ability to follow instructions and align its outputs with human needs. This fine-tuning process leverages high-quality datasets, such as Q&amp;A pairs from Stack Exchange, and employs tools like Hugging Face&apos;s PEFT and bits and bytes for efficient training.</p><p><strong>License</strong>:</p><p>Open source (Apache-2.0).</p><p><strong>Key features for coding:</strong></p><p>Developers can fine-tune StarCoder on specific datasets or tasks to improve its performance in niche areas, such as domain-specific programming or unique coding styles. This flexibility allows organizations to adapt the model to their specific needs.</p><p>Furthermore, it supports efficient inference through optimizations like FP16, BF16, and 8-bit precision, which reduce memory requirements while maintaining performance. This makes it accessible for use on consumer-grade GPUs or even CPUs, depending on the task and model size.</p><h3 id="the-xgen-family">The XGen family</h3><p><strong>Best for:</strong> Analyzing large code bases.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXd3WZqRI8U9n3QHPuNzvJcqvaeVqCadV4f_9f15yADO5hN4g2vYCYZc5pBzM_uxDA54SzzsXQSr1p37Kelk8Ja0hJtPWni4TAo8C1GgCW-yWVW9Syalpu4dvpSsfG9-nNbMpdjNyw?key=V2J9xv6PXC5DZeqc4AtWjfpF" class="kg-image" alt="The 20 best LLMs for coding (+ free workflow templates)" loading="lazy" width="602" height="184"><figcaption><span style="white-space: pre-wrap;">The XGen website</span></figcaption></figure><p>The <a href="https://github.com/salesforce/xGen?ref=blog.n8n.io"><u>XGen family</u></a> of models, developed by <a href="https://www.salesforceairesearch.com/?ref=blog.n8n.io"><u>Salesforce AI Research</u></a>, represents a series of open-source large language models designed for long-sequence modeling. The flagship model, XGen-7B, is trained to handle input sequences of up to 8000 tokens, making it particularly suitable for tasks requiring extended context. Tis family includes three variants:</p><ul><li><strong>XGen-7B-4K-Base</strong> supporting 4K sequence length.</li><li><strong>XGen-7B-8K-Base</strong> supporting 8K sequence length.</li><li><strong>XGen-7B-8K-Inst</strong> fine-tuned for instruction-based tasks and intended for research purposes.</li></ul><p>These models are designed as auto-regressive samplers, enabling developers to generate text by providing a prompt and sampling from the model&apos;s output. The implementation is straightforward, utilizing the HuggingFace Transformers library for loading the models and tokenizers.</p><p><strong>License</strong>:</p><p>Open source (Apache-2.0).</p><p><strong>Key features for coding:</strong></p><p>While primarily designed for long-sequence natural language processing tasks, the XGen models are also suitable for coding-related applications.</p><p>For example, with the support for up to 8000 tokens, the XGen-7B-8K-Base model can process and generate code that spans long files or complex scripts. This feature makes it the best LLM for coding from its family when you have to manage tasks like analyzing large codebases.</p><h3 id="the-pythia-family">The Pythia family</h3><p><strong>Best for</strong>: Learning how LLM models learn and process information.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXe6poFQhGASS4Z2afcqPQtrTRHP0l5X4cSYMuFvrs0q7jy1Ig9ApmaykGJL3HaKOkOeTpGpIPTzLIqPlV-Q9XGJDzodQi2seHqteVN664pK9ks88b6wHtl7h0NX-C21YWTCcff3ow?key=V2J9xv6PXC5DZeqc4AtWjfpF" class="kg-image" alt="The 20 best LLMs for coding (+ free workflow templates)" loading="lazy" width="602" height="236"><figcaption><span style="white-space: pre-wrap;">The Pythia website</span></figcaption></figure><p>The <a href="https://github.com/EleutherAI/pythia?ref=blog.n8n.io"><u>Pythia LLM family</u></a>, developed by <a href="https://www.eleuther.ai/?ref=blog.n8n.io"><u>EleutherAI</u></a>, is a suite of autoregressive transformer models designed to facilitate research in interpretability, learning dynamics, and ethical AI practices. The project uniquely emphasizes transparency and reproducibility, offering public access to all models, data, and code.&#xA0;</p><p>This suite of LLMs includes eight model sizes, ranging from 14 million to 12 billion parameters, trained on approximately 300 billion tokens. A standout feature of Pythia is its 154 checkpoints saved throughout training, enabling researchers to study the learning dynamics of LLMs in unprecedented detail. All models were trained on the same dataset, &quot;<a href="https://pile.eleuther.ai/?ref=blog.n8n.io"><u>The Pile</u></a>,&quot; in the same order, ensuring consistency and enabling causal interventions in the training process.</p><p><strong>License</strong>:</p><p>Open source (Apache 2.0).</p><p><strong>Key features for coding:</strong></p><p>Pythia models are a general-purpose LLM family. However, its 154 training checkpoints make it particularly interesting for coding. These checkpoints are available for each model, so developers can fine-tune Pythia models for specific coding datasets or tasks, such as improving performance in a particular programming language or domain.</p><p>This particular design enables researchers to study how the models learn and process information, which can be applied to understanding how the models handle coding tasks, such as syntax generation or error detection.</p><h3 id="the-wizardlm-family">The WizardLM family</h3><p><strong>Best for</strong>: Debugging code.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXcra_Z4mE8fFO-ybGbrXvYQWA-LXAQ7WBWpX1OshlATVwod26wJ1HUPJjhYbsL5YOZp5GPzCS84BBHX3_MympT4U_0MeG8_h3mTkotBIFwA1V9tEZc_dHB6BUxf2_PI0OpPfC4kbA?key=V2J9xv6PXC5DZeqc4AtWjfpF" class="kg-image" alt="The 20 best LLMs for coding (+ free workflow templates)" loading="lazy" width="602" height="325"><figcaption><span style="white-space: pre-wrap;">The WizardLM website</span></figcaption></figure><p><a href="https://github.com/nlpxucan/WizardLM?ref=blog.n8n.io"><u>WizardLM</u></a> is a family of LLMs designed to follow complex instructions that excels in various tasks, including natural language processing, code generation, and mathematical reasoning. Built upon the Evol-Instruct framework, WizardLM leverages a method to automatically generate diverse and challenging open-domain instructions using LLMs instead of human input. This approach enhances the model&apos;s ability to handle a wide range of skills and difficulty levels, making it a versatile tool for both academic and practical applications.</p><p>The project includes several specialized models, such as WizardCoder for coding tasks and WizardMath for mathematical reasoning, each fine-tuned to achieve state-of-the-art performance in its respective domain.</p><p><strong>License</strong>:</p><p>While the WizardLM project provides access to many of its model weights and resources for academic and research purposes, not all WizardLM models are fully open-source.</p><p><strong>Key features for coding:</strong></p><p>Among the family models, the best coding LLM is the WizardCoder series, as it is designed to excel in coding-related tasks.</p><p>In particular, the WizardCoder models are optimized for multi-turn interactions, allowing them to engage in iterative problem-solving and debugging processes. This feature is useful for developers who need step-by-step assistance or clarification during coding tasks.</p><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text">During development, adding log messages is a good practice that helps you with debugging errors. To configure logging for your development workflow in n8n, <a href="https://docs.n8n.io/hosting/logging-monitoring/logging/?ref=blog.n8n.io#log-levels"><u>read about the logging feature and how to configure it</u></a>.</div></div><h3 id="the-vicuna-family">The Vicuna family</h3><p><strong>Best for</strong>:&#xA0;Understanding and managing multi-file projects.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfor7lomboiGHyMQDDbrhHZGCdKJnZaCQZPL3t4KGw_g-AY7asT7V8p7iTolSuBR0iziUP13Yv0n5Sw0qG6iMlrGHAkXNI635UcXTFY5s44SCf0jzUuEISoKgdbUDH6B9f8ZHbN9A?key=V2J9xv6PXC5DZeqc4AtWjfpF" class="kg-image" alt="The 20 best LLMs for coding (+ free workflow templates)" loading="lazy" width="602" height="409"><figcaption><span style="white-space: pre-wrap;">The Vicuna website</span></figcaption></figure><p>The <a href="https://ollama.com/library/vicuna?ref=blog.n8n.io"><u>Vicuna</u></a> family models, by the <a href="https://lmsys.org/projects/?ref=blog.n8n.io"><u>LMSYS</u></a>, are a general-purpose chat assistant built on the foundation of Llama and Llama 2 architectures. The model is offered in three sizes: 7 billion, 13 billion, and 33 billion parameters, catering to varying computational needs and performance requirements.</p><p>These models are designed to handle a wide range of general-purpose chat tasks, making them versatile tools for applications like customer support, personal assistance, and educational purposes.</p><p><strong>License</strong>:</p><p>Open-weight models (the models are built on top of the LLaMA and LLaMA 2 architectures, which are themselves released under a non-commercial license. So, their weights are publicly available for download and use but their usage is subject to the licensing terms of the underlying LLaMA and LLaMA 2 models).</p><p><strong>Key features for coding</strong>:</p><p>The Vicuna models are general-purpose conversational models, but they exhibit features that make them useful for coding-related tasks.</p><p>In particular, Vicuna excels in multi-turn conversations, which is advantageous for iterative coding tasks, so developers can engage in back-and-forth discussions with the model to refine code, troubleshoot errors, or explore alternative solutions. Also, the v1.5-16k variant of supports a context size of up to 16,000 tokens: this extended context length makes this the best LLM for coding from its family in the particular case where coding tasks involve analyzing or generating large codebases and understanding multi-file projects.</p><h3 id="the-sqlcoder-family">The SQLcoder family</h3><p><strong>Best for</strong>: Working with SQL queries.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfGZ2TWxKKn4eMpsC7O4lX8CoeS8qo_2-opRNRlzsf3ZSb-DblJMyxO9kIzGa6fYMXHEWXnDD7fS-YEcmNF7CBOpMlRScIQMCjw-8Xkd86HovE05gyqCBqgS7WbgVcjFJ8RmZSBFw?key=V2J9xv6PXC5DZeqc4AtWjfpF" class="kg-image" alt="The 20 best LLMs for coding (+ free workflow templates)" loading="lazy" width="602" height="348"><figcaption><span style="white-space: pre-wrap;">The SQLcoder UI - screenshot taken from the SQLcoder website</span></figcaption></figure><p><a href="https://github.com/defog-ai/sqlcoder?ref=blog.n8n.io"><u>SQLCoder</u></a>, developed by <a href="https://defog.ai/?ref=blog.n8n.io"><u>Defog</u></a>, is a specialized code completion model fine-tuned on the StarCoder base model, designed specifically for SQL generation tasks. It is optimized to convert natural language questions into SQL queries, making it particularly useful for database-related tasks.</p><p>The model is designed to handle complex SQL query generation by adhering to specific rules, such as using table aliases to avoid ambiguity and casting numerators as floats when creating ratios. It is capable of processing detailed database schemas and generating accurate SQL queries tailored to the schema&apos;s structure and it comes in two sizes: a 7B parameter version (4.1GB) and the full 15B parameter version (9.0GB), with the latter requiring at least 16GB of RAM for optimal performance.</p><p><strong>License</strong>:</p><p>Open source (Apache-2.0).</p><p><strong>Key coding features</strong>:</p><p>SQLCoder is fine-tuned specifically for SQL-related tasks, enabling it to convert natural language questions into accurate SQL queries. It is trained on a diverse dataset of SQL examples, allowing it to excel at simple and complex queries across various database schemas.</p><p>Also, as the models are open-source, developers can use, modify, and fine-tune them for specific use cases.</p><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text">n8n has strong support for all major SQL engines. We&#x2019;ve already posted several articles dedicated to different use cases for<a href="https://n8n.io/integrations/mysql/?ref=blog.n8n.io" target="_blank" rel="noopener">&#xA0;MySQL</a>,&#xA0;<a href="https://n8n.io/integrations/microsoft-sql/?ref=blog.n8n.io" target="_blank" rel="noopener">MS SQL</a>,&#xA0;<a href="https://n8n.io/integrations/postgres/?ref=blog.n8n.io" target="_blank" rel="noopener">PostgreSQL</a>.</div></div><h3 id="the-jamba-family">The Jamba family</h3><p><strong>Best for</strong>: REST APIs interaction.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfHOfGEJ0SSP0b4GPo-wBESz-iC7ixnwMFmfSLd5EGKHyB3-OKn0-s0zCBeODCAAhQzNFr6WmDehzV3oTmENVthctllrMjBR04_AQ3MayCrHV8eC1_QmdefWkEzUNPu-Qpfp0hx?key=V2J9xv6PXC5DZeqc4AtWjfpF" class="kg-image" alt="The 20 best LLMs for coding (+ free workflow templates)" loading="lazy" width="602" height="289"><figcaption><span style="white-space: pre-wrap;">The Jamba UI - screenshot taken from the Jamba website</span></figcaption></figure><p>The <a href="https://www.ai21.com/jamba?ref=blog.n8n.io"><u>Jamba family</u></a>, developed by AI21 Labs, represents a significant innovation in AI architecture that combines the strengths of Transformer and Mamba Structured State Space models. This hybrid architecture, known as the SSM-Transformer, addresses key limitations of traditional Transformer models, such as their large memory footprint and inefficiency with long contexts.&#xA0;</p><p>These models excel in handling extensive context windows, offering an industry-leading 256K token context length, which is particularly beneficial for tasks like document summarization, retrieval-augmented generation (RAG), and complex reasoning. This family currently includes two models&#x2013;Jamba 1.5 Mini and Jamba 1.5 Large&#x2013;both optimized for speed, quality, and resource efficiency.</p><p><strong>License</strong>:</p><p>Open-source (Apache 2.0).</p><p><strong>Key features for coding</strong>:</p><p>The Jamba family is a general-purpose one but offers interesting coding-related features.</p><p>For example, they support structured JSON output and function calls, which are essential for coding tasks. This allows developers to generate well-structured code snippets, API responses, or data outputs that can be directly integrated into applications. The ability to handle function calls also makes it easier to automate workflows and interact with APIs programmatically.</p><h3 id="the-qwen-family">The Qwen family</h3><p><strong>Best for:</strong> Enhancing coding workflows.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXcANo9H3jSWn5OPPwlZ54AkdtlIxLJOxnJXTzP_b6vpQPQVVaWDAjBelztUgaR6xzvnZqvKUSZWc1EvywOoWDS2GGvnvhgkxPzMYaI-6W-YhIJisuW0AZPYAoVubzJSsyDQWVwjJg?key=V2J9xv6PXC5DZeqc4AtWjfpF" class="kg-image" alt="The 20 best LLMs for coding (+ free workflow templates)" loading="lazy" width="602" height="212"><figcaption><span style="white-space: pre-wrap;">The Qwen website</span></figcaption></figure><p>The <a href="https://qwenlm.github.io/?ref=blog.n8n.io"><u>Qwen family,</u></a> developed by the <a href="https://www.alibabacloud.com/en/solutions/generative-ai/qwen?_p_lc=1&amp;ref=blog.n8n.io"><u>Alibaba Group&apos;s Qwen Team</u></a>, represents a cutting-edge initiative aimed at advancing AI&#x2019;s capabilities across various domains, including mathematical reasoning, coding, and multimodal understanding. The models are designed to address key challenges in AI, such as improving reasoning reliability and extending context length for better comprehension.&#xA0;</p><p>Here&#x2019;s the current model&apos;s composition:</p><ul><li><strong>Qwen2.5-Turbo</strong>: Supports an extended context length of up to 1 million tokens, enabling the processing of vast amounts of information in a single session.</li><li><strong>Qwen2.5-Coder Series</strong>: Open-source coding models with state-of-the-art coding capabilities, strong general reasoning, and mathematical skills.</li><li><strong>QVQ (Qwen Vision-Question)</strong>: Combines language and vision to enhance cognitive capabilities, mimicking human perception and reasoning.</li><li><strong>QwQ (Qwen with Questions)</strong>: A philosophically inspired model that emphasizes curiosity and deep reasoning across diverse domains.</li></ul><p><strong>License</strong>:</p><p>Many of the Qwen models, such as Qwen2.5 and its variants (e.g., Qwen2.5-Coder and Qwen2.5-Math), are open source under the Apache 2.0 license. However, exceptions include the 3B and 72B variants, which are not open-source.</p><p>Additionally, flagship models like Qwen-Plus and Qwen-Turbo are not open source but are available through <a href="https://www.alibabacloud.com/help/en/model-studio/developer-reference/use-qwen-by-calling-api?ref=blog.n8n.io"><u>APIs provided by Alibaba Cloud&apos;s Model Studio</u></a>.</p><p><strong>Key features for coding</strong>:</p><p>The Qwen family is a general-purpose one, and while they can all handle coding tasks, the best coding LLM of the group is the Qwen2.5-Coder series, as it is designed for coding.</p><p>These models are compatible with popular IDEs and can handle extensive context lengths. They also excel in generating structured outputs like JSON and enhancing its utility in coding workflows.</p><h3 id="the-codet5-family">The CodeT5 family</h3><p><strong>Best for:</strong> Deployment as AI-powered coding assistants.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXesWKN8TPBQmIgCIbrBiVA0mSFVxTEWPHXIuHxfmdb8dx8iyDUn7jVweLX3CVoDDIJQlR06nrhT5MUUIUzFkLz7Gclx-VpE8N2KhYz-jIL3M0pqV7FlxepLv8sVxkNNySiofKO63A?key=V2J9xv6PXC5DZeqc4AtWjfpF" class="kg-image" alt="The 20 best LLMs for coding (+ free workflow templates)" loading="lazy" width="602" height="201"><figcaption><span style="white-space: pre-wrap;">The CodeT5 process - Screenshot taken from the CodeT5 repository on GitHub</span></figcaption></figure><p>The <a href="https://github.com/salesforce/CodeT5?ref=blog.n8n.io"><u>CodeT5 family</u></a>, developed by <a href="https://www.salesforceairesearch.com/?ref=blog.n8n.io"><u>Salesforce Research</u></a>, consists of two large language models designed for code understanding and generation. They have been widely recognized in the research community, with their papers being accepted at prestigious conferences like EMNLP and NeurIPS.</p><p>Here&#x2019;s its current composition:</p><ul><li><strong>CodeT5</strong> model, introduced in 2021, is an identifier-aware, unified pre-trained encoder-decoder model. It was designed to handle tasks such as text-to-code generation, code autocompletion, and code summarization.</li><li><strong>CodeT5+</strong> in May 2023, which represents an evolution of the original model. CodeT5+ introduces improvements in both architecture and performance, making it more effective for complex code understanding and generation tasks. The model is part of a broader effort to create open, large-scale LLMs for code, and it has been accompanied by research papers and resources to support its adoption. CodeT5+ is designed to be accessible to the developer community, with checkpoints available on platforms like Hugging Face for easy integration into workflows.</li></ul><p><strong>License</strong>:</p><p>Open-source (BSD-3-Clause license).</p><p><strong>Key features for coding</strong>:</p><p>As these LLMs specialize in coding tasks, they&#x2019;re your best option for custom deployment to use them as coding assistant.</p><h2 id="create-llm-powered-workflows-with-n8n">Create LLM-powered workflows with n8n</h2><p>So far, we reviewed the 20 best LLMs for coding.</p><p>It&apos;s important to understand that LLMs operate in isolation, without the workflow orchestration needed to make their outputs immediately actionable.</p><p>Here&#x2019;s where <a href="https://n8n.io/ai/?ref=blog.n8n.io" rel="noreferrer">n8n</a> comes in!</p><p>n8n provides workflow integration: developers can use AI tools that don&#x2019;t just generate code but also integrate with existing tools, and processes.</p><p>As a low-code solution specifically developed for automating workflows by using its UI, you can use its prebuilt nodes as they are, but also customize some of them by using code, if you need it.</p><p>Here are the interesting nodes in this scenario:</p><ul><li><a href="https://docs.n8n.io/code/code-node/?ref=blog.n8n.io"><strong><u>The Code node</u></strong></a>: This allows you to write custom code in Python and Javascript and run it as a step in your workflows, allowing you to customize them.</li><li><a href="https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.httprequest/?utm_source=n8n_app&amp;utm_medium=node_settings_modal-credential_link&amp;utm_campaign=n8n-nodes-base.httpRequest"><strong><u>The HTTP request node</u></strong></a>: This allows you to make HTTP requests to query data from any service with REST APIs.</li><li><a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.agent/?ref=blog.n8n.io"><strong><u>The AI Agent node:</u></strong></a> This is an autonomous AI agent node that gives you six LangChain agent options, receives data, makes decisions, and acts to achieve specific goals.&#xA0;</li><li><a href="https://docs.n8n.io/code/ai-code/?ref=blog.n8n.io"><strong><u>The AI coding with GPT</u></strong></a> node: This allows you to leverage AI-generated code while building automation workflows.&#xA0;</li></ul><div class="kg-card kg-callout-card kg-callout-card-red"><div class="kg-callout-emoji">&#x26A0;&#xFE0F;</div><div class="kg-callout-text"><b><strong style="white-space: pre-wrap;">ATTENTION</strong></b>: <br>The AI coding with GPT node is currently in beta. It&#x2019;s only available to cloud users and only supports JavaScript.&#xA0;</div></div><p>So, you can use n8n to move beyond standalone AI use cases to create scalable, end-to-end automation that delivers real business impact.</p><p>Let&#x2019;s see some practical examples!</p><h3 id="how-to-use-llms-for-coding-with-n8n-streamline-code-reviews">How to use LLMs for coding with n8n: Streamline code reviews</h3><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXd0h1tymnx5RgeOK4qmKmFREJmHhZmUkEFponRBMXOJiyZ3gWSPfJVDCxZUfaX7ylnpsCei-HM0tvCVEyABSy_IhOjrC80bfdySP6_MK6AdOHwDda80SyvEth5BnsdnZBHwooZj?key=V2J9xv6PXC5DZeqc4AtWjfpF" class="kg-image" alt="The 20 best LLMs for coding (+ free workflow templates)" loading="lazy" width="602" height="133"><figcaption><span style="white-space: pre-wrap;">n8n AI-powered workflow for automatic core review</span></figcaption></figure>
<!--kg-card-begin: html-->
<script>
  workflowBanner(2167, document.currentScript);
</script>
<!--kg-card-end: html-->
<p>Let&#x2019;s be honest: code reviews take time, especially if you&#x2019;re working in a large enterprise and need to interact with different teams.</p><p>Also, sometimes, you may just need a &#x201C;second opinion&#x201D; to ensure that you gave your peers the right advice when reviewing their code.</p><p>So, fear no more: n8n is here to help you with that! We created a template useful for every engineer who wants to automate their code reviews in GitLab or (just get a 2nd opinion on their PRs). When set up, this workflow automatically reviews your changes in a Gitlab PR using AI: it&#x2019;s triggered when you comment to a Gitlab PR, makes its analysis with ChatGPT, and replies to the discussion.</p><h3 id="how-to-use-llms-for-coding-with-n8n-write-sql-queries-based-on-database-schema">How to use LLMs for coding with n8n: Write SQL queries based on database schema</h3><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXdHa1kyDlp2gusxYerBo8rMYMuQbwaXwWEa4pTVK3nm9-T-kZsKm3UJun4rX-ZyBFaj4f1iRPD7SjFCBBBfNtCKw7W5r2aVbOh6NYnPl1dxvs0hAxo04R2U6AMDPShCjo8tVh11gA?key=V2J9xv6PXC5DZeqc4AtWjfpF" class="kg-image" alt="The 20 best LLMs for coding (+ free workflow templates)" loading="lazy" width="602" height="248"><figcaption><span style="white-space: pre-wrap;">n8n AI-powered workflow for creating SQL queries based on database schema</span></figcaption></figure>
<!--kg-card-begin: html-->
<script>
  workflowBanner(2508, document.currentScript);
</script>
<!--kg-card-end: html-->
<div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text">This workflow is created with the <a href="https://docs.n8n.io/integrations/builtin/app-nodes/n8n-nodes-base.mysql/?ref=blog.n8n.io"><u>MySQL </u></a>node, but you can modify it to use any other supported relational database like <a href="https://docs.n8n.io/integrations/builtin/app-nodes/n8n-nodes-base.postgres/?ref=blog.n8n.io"><u>Postgres</u></a>, or <a href="https://docs.n8n.io/integrations/builtin/app-nodes/n8n-nodes-base.microsoftsql/?ref=blog.n8n.io"><u>Microsoft SQL</u></a>.</div></div><p>SQL queries: cross and delight of every engineer! Well, sometimes more a cross than a delight, isn&#x2019;t it? We know it, and this is why we created a workflow that generates SQL queries prompting ChatGPT that are tailored to the database schema.</p><p>In this workflow, the AI agent accesses only the database schema, not the actual data. This allows the agent to generate SQL queries based on the structure of tables and their relationships, without having to access the actual data, thus providing a secure process.</p><h3 id="how-to-use-llms-for-coding-with-n8n-create-a-chat-assistant-with-postgres-memory">How to use LLMs for coding with n8n: Create a chat assistant with Postgres memory&#xA0;</h3><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXddzLdM4f--q67Ki0PF-Kb8DxVVI9AcawBzAEq0bp4JvrXYAdYSiLZeuDl0Kxf9VN953eITSkMnZGMj33w16RzpXAgekVLmLyyIjdo6pHRxhfF7XLO5UlljYS9A5BSUaYggKhj_?key=V2J9xv6PXC5DZeqc4AtWjfpF" class="kg-image" alt="The 20 best LLMs for coding (+ free workflow templates)" loading="lazy" width="602" height="451"><figcaption><span style="white-space: pre-wrap;">n8n AI-powered workflow for creating a chat assistant with Postgres</span></figcaption></figure>
<!--kg-card-begin: html-->
<script>
  workflowBanner(2637, document.currentScript);
</script>
<!--kg-card-end: html-->
<p>This workflow is an intelligent chatbot&#x2013;that uses the OpenAI node&#x2013;integrated with a backend that supports WhatsApp Business, and it&#x2019;s designed to handle various use cases such as sales and customer support.</p><p>It also uses the <a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.memorypostgreschat/?ref=blog.n8n.io"><strong><u>Postgres Chat Memory</u></strong></a> for storing chat history and the HTTP nodes for connecting to anything that may be of help to your customers, like a knowledge base of your online shop. This powers up the interaction with the OpenAI node so that users receive contextualized responses.</p><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text"><b><strong style="white-space: pre-wrap;">TIP</strong></b>:<br>If you are not a master in writing SQL queries, you can modify this workflow by using the schema we&apos;ve described in the previous workflow that generates SQL queries based on the database schema.</div></div><h3 id="how-to-use-llms-for-coding-with-n8n-automate-chart-generation">How to use LLMs for coding with n8n: Automate chart generation </h3><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXdGZZxIe9W6Lw_IaVP6pFGhcyz0xlL6Eu1Oub-h3vSimuQnMSHp27cH-sbyYqgEvnuB3G4wIdZ4MQn8eqjtlKoCWk2MUf0EpGhiu4jqECpCFS2o587Lz6cASdC-Gk5ELWx9b26y?key=V2J9xv6PXC5DZeqc4AtWjfpF" class="kg-image" alt="The 20 best LLMs for coding (+ free workflow templates)" loading="lazy" width="602" height="383"><figcaption><span style="white-space: pre-wrap;">n8n AI-powered workflow for automating chart generation</span></figcaption></figure>
<!--kg-card-begin: html-->
<script>
  workflowBanner(2559, document.currentScript);
</script>
<!--kg-card-end: html-->
<p>Often, when you query a database the output you need is a chart. However, this process often requires interacting with different software and it might be annoying, particularly if what you need is a chart for a prototype.</p><p>Wouldn&#x2019;t it be thrilling if you could have an automated process that queries a database and provides a chart, but only if you actually need it? Yes, this is a workflow we created for you!</p><p>This workflow provides data visualization to a native SQL Agent, fostering data analysis and data visualization. It does so by connecting to a database and can query it and translate the response in a human format.</p><h2 id="wrap-up">Wrap up</h2><p>In this article, we&#x2019;ve gone through an overview of the LLMs landscape and discovered the 20 best LLMs for coding.&#xA0;&#xA0;</p><p>However, while LLMs excel at different tasks &#x2013; like writing code &#x2013; they operate in isolation, leaving users to figure out integration and execution.</p><p>This is where n8n comes into the game: it bridges this gap by allowing you to embed LLM capabilities into dynamic, multi-step workflows.</p>
<!--kg-card-begin: html-->
<div class="content-banner">
  <div>
    <h3>Create your own LLM workflows</h3>
    <p>Bridge the gap with n8n&#x2014;turn LLM outputs into action!</p>
  </div>
  <a href="https://app.n8n.cloud/register?ref=blog.n8n.io" class="global-button blog-banner-signup">Try n8n now</a>
</div>
<!--kg-card-end: html-->
<h2 id="what%E2%80%99s-next">What&#x2019;s next?</h2><p>Expand your knowledge on AI, automation, and workflow optimization with these in-depth resources:</p><ul><li><a href="https://blog.n8n.io/open-source-llm/" rel="noreferrer"><strong>The Best 11 Open-Source LLM Applications</strong></a> &#x2013; Discover these top 11 open-source LLMs and build advanced AI workflows with n8n LangChain integration.</li><li><a href="https://blog.n8n.io/ai-tools-for-business/" rel="noopener"><strong>Top AI Tools for Business</strong></a> &#x2013; Discover essential AI tools that can enhance efficiency and streamline operations.</li><li><a href="https://blog.n8n.io/ai-agents/" rel="noopener"><strong>A Guide to AI Agents</strong></a> &#x2013; Understand how AI agents work and how they can automate complex decision-making processes.</li><li><a href="https://blog.n8n.io/ai-coding-assistants/" rel="noopener"><strong>AI Coding Assistants: Boost Developer Productivity</strong></a> &#x2013; Explore how AI-powered coding assistants can speed up development and reduce errors.</li><li><a href="https://n8n.io/integrations/categories/ai/?ref=blog.n8n.io" rel="noopener"><strong>AI Integrations for Workflow Automation</strong></a> &#x2013; Browse AI-powered integrations to enhance your automation workflows in n8n.</li></ul><p>n8n also provides AI-powered workflows for all your needs that span from simple to very complicated. Give them a try:</p>
<!--kg-card-begin: html-->
<script>
  workflowBanner([2373, 2665, 1951, 2673], document.currentScript, { 
      workflowsHeader: "AI workflows powered by n8n"
  });
</script>
<!--kg-card-end: html-->
]]></content:encoded></item><item><title><![CDATA[AI Agents Explained: From Theory to Practical Deployment]]></title><description><![CDATA[This guide explains the fundamentals of AI agents and shows you how to build them using n8n, with practical examples for software developers.]]></description><link>https://blog.n8n.io/ai-agents/</link><guid isPermaLink="false">671a5a590783110001c1a7eb</guid><category><![CDATA[AI]]></category><category><![CDATA[Guide]]></category><dc:creator><![CDATA[Yulia Dmitrievna]]></dc:creator><pubDate>Mon, 10 Feb 2025 10:11:00 GMT</pubDate><media:content url="https://blog.n8n.io/content/images/2024/06/ai-chatbots-8--1---3-.png" medium="image"/><content:encoded><![CDATA[<img src="https://blog.n8n.io/content/images/2024/06/ai-chatbots-8--1---3-.png" alt="AI Agents Explained: From Theory to Practical Deployment"><p>Modern software development already <a href="https://blog.n8n.io/ai-coding-assistants/"><u>relies on AI coding assistants</u></a> that react to user inputs. Although autonomous AI agents are rapidly developing, they have the potential to revolutionize the field even further. We talk about:</p><ul><li>handling tasks without prior strict rules,</li><li>detecting anomalies,</li><li>predicting and mitigating potential issues before they arise,</li><li>providing valuable insights to novice and experienced devs.</li></ul><p>These results can be achieved with intelligent, adaptive AI agents that enhance system resilience and accelerate project timelines.</p><p>In this guide, we&apos;ll explore AI agents, provide examples and show you how to create your own AI agent with <a href="https://n8n.io/ai/?ref=blog.n8n.io"><u>n8n, a source-available AI-native workflow automation tool</u></a>!</p><p>This is&#xA0; a sneak peek of workflows with AI agents that you&apos;ll be able to build by the end of this guide:</p>
<!--kg-card-begin: html-->
<script>
  workflowBanner([2592, 2722, 2703, 2651], document.currentScript, { 
      workflowsHeader: "Workflows with AI agents powered by n8n"
  });
</script>
<!--kg-card-end: html-->
<p>Let&#x2019;s dive in!</p><h3 id="table-of-content">Table of content</h3>
<ul>
<li><a href="#what-are-ai-agents">What are AI agents?</a></li>
<li><a href="#how-do-ai-agents-work">How do AI agents work?</a>
<ul>
<li><a href="#input-processing">Input processing</a></li>
<li><a href="#decision-making">Decision-making</a></li>
<li><a href="#action-execution">Action execution</a></li>
<li><a href="#learning-and-adaptation">Learning and adaptation</a></li>
</ul>
</li>
<li><a href="#what-are-the-types-of-agents-in-ai">What are the types of agents in AI?</a>
<ul>
<li><a href="#simple-reflex-agents">Simple reflex agents</a></li>
<li><a href="#model-based-reflex-agents">Model-based reflex agents</a></li>
<li><a href="#goal-based-agents">Goal-based agents</a></li>
<li><a href="#utility-based-agents">Utility-based agents</a></li>
<li><a href="#learning-agents">Learning agents</a></li>
</ul>
</li>
<li><a href="#what-are-the-benefits-of-ai-agents">What are the benefits of AI agents?</a>
<ul>
<li><a href="#faster-information-analysis-and-decision-making">Faster information analysis and decision-making</a></li>
<li><a href="#increased-team-productivity">Increased team productivity</a></li>
<li><a href="#enhanced-customer-experience">Enhanced customer experience</a></li>
<li><a href="#accelerated-software-development">Accelerated software development</a></li>
<li><a href="#improved-data-quality-and-consistency">Improved data quality and consistency</a></li>
</ul>
</li>
<li><a href="#what-are-the-key-components-of-an-ai-agent">What are the key components of an AI agent?</a>
<ul>
<li><a href="#sensors">Sensors</a></li>
<li><a href="#actuators">Actuators</a></li>
<li><a href="#reasoning-engine-aka-the-brain">Reasoning engine (aka the &quot;brain&quot;)</a></li>
</ul>
</li>
<li><a href="#what-are-the-ai-agent-examples">What are the AI agent examples?</a>
<ul>
<li><a href="#human-activated-agents">Human-activated agents</a></li>
<li><a href="#event-activated-ambient-agents">Event-activated (ambient) agents</a></li>
</ul>
</li>
<li><a href="#how-to-create-an-ai-agent">How to create an AI agent?</a>
<ul>
<li><a href="#why-use-langchain-for-ai-agents">Why use LangChain for AI agents?</a></li>
<li><a href="#building-smart-create-your-own-intelligent-data-analyst-ai-agent-with-n8n">Building smart: Create your own intelligent data analyst AI agent with n8n</a></li>
<li><a href="#step-1-download-and-save-sqlite-file">Step 1. Download and save SQLite file</a></li>
<li><a href="#step-2-receive-the-chat-message-and-load-the-local-sqlite-file">Step 2. Receive the chat message and load the local SQLite file</a></li>
<li><a href="#step-3-add-and-configure-the-langchain-agent-node">Step 3. Add and configure the LangChain Agent node</a></li>
</ul>
</li>
<li><a href="#faq">FAQ</a>
<ul>
<li><a href="#faq-1">Can LLM act as an AI agent?</a></li>
<li><a href="#faq-2">Is ChatGPT an AI agent??</a></li>
<li><a href="#faq-3">What are multi-agent systems?</a></li>
<li><a href="#faq-4">How do AI agents learn and improve over time?</a></li>
</ul>
</li>
<li><a href="#wrap-up">Wrap up</a></li>
<li><a href="#what%E2%80%99s-next">What&#x2019;s next?</a></li>
</ul>
<h2 id="what-are-ai-agents">What are AI agents?</h2><p>An AI agent is an autonomous system that receives data, makes rational decisions, and acts within its environment to achieve specific goals.</p><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text">In this guide, we rely heavily on definitions from <a href="https://aima.cs.berkeley.edu/global-index.html?ref=blog.n8n.io"><u>AIMA</u></a> &#x2013; a book on modern Artificial Intelligence. These definitions may sound familiar to you if you&#x2019;ve studied computer science. For everyone else, we offer a greatly simplified and condensed version, but you can always refer to the original book.</div></div><p>While a simple agent perceives its environment through sensors and acts on it through actuators, a true AI agent includes a &quot;reasoning engine&quot;. This engine autonomously makes rational decisions based on the environment and its actions. According to AIMA: &#x201C;For each possible percept sequence, a rational agent should select an action that is expected to maximize its performance measure, given the evidence provided by the percept sequence and whatever built-in knowledge the agent has&#x201D;.</p><p>Large Language Models and multimodal LLMs are at the core of modern AI agents as they provide a reasoning layer and can readily measure performance. Check the FAQ section for details.</p><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text">Large Language Models can be proprietary or open-source. Take a look at our overview of various <a href="https://blog.n8n.io/open-source-llm/"><u>open-source LLMs</u></a>.</div></div><p>The most advanced AI agents can also learn and adapt their behavior over time. Not all agents need this, but sometimes it&#x2019;s mandatory:</p><figure class="kg-card kg-video-card kg-width-regular kg-card-hascaption" data-kg-thumbnail="https://blog.n8n.io/content/media/2025/02/atlas-fail-33d470de7168d99d_thumb-682416b2988f9f9a.jpg" data-kg-custom-thumbnail>
            <div class="kg-video-container">
                <video src="https://blog.n8n.io/content/media/2025/02/atlas-fail-33d470de7168d99d.webm" poster="https://img.spacergif.org/v1/1280x720/0a/spacer.png" width="1280" height="720" loop autoplay muted playsinline preload="metadata" style="background: transparent url(&apos;https://blog.n8n.io/content/media/2025/02/atlas-fail-33d470de7168d99d_thumb-682416b2988f9f9a.jpg&apos;) 50% 50% / cover no-repeat;"></video>
                <div class="kg-video-overlay">
                    <button class="kg-video-large-play-icon" aria-label="Play video">
                        <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                            <path d="M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z"/>
                        </svg>
                    </button>
                </div>
                <div class="kg-video-player-container kg-video-hide">
                    <div class="kg-video-player">
                        <button class="kg-video-play-icon" aria-label="Play video">
                            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                                <path d="M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z"/>
                            </svg>
                        </button>
                        <button class="kg-video-pause-icon kg-video-hide" aria-label="Pause video">
                            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                                <rect x="3" y="1" width="7" height="22" rx="1.5" ry="1.5"/>
                                <rect x="14" y="1" width="7" height="22" rx="1.5" ry="1.5"/>
                            </svg>
                        </button>
                        <span class="kg-video-current-time">0:00</span>
                        <div class="kg-video-time">
                            /<span class="kg-video-duration">0:03</span>
                        </div>
                        <input type="range" class="kg-video-seek-slider" max="100" value="0">
                        <button class="kg-video-playback-rate" aria-label="Adjust playback speed">1&#xD7;</button>
                        <button class="kg-video-unmute-icon" aria-label="Unmute">
                            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                                <path d="M15.189 2.021a9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h1.794a.249.249 0 0 1 .221.133 9.73 9.73 0 0 0 7.924 4.85h.06a1 1 0 0 0 1-1V3.02a1 1 0 0 0-1.06-.998Z"/>
                            </svg>
                        </button>
                        <button class="kg-video-mute-icon kg-video-hide" aria-label="Mute">
                            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                                <path d="M16.177 4.3a.248.248 0 0 0 .073-.176v-1.1a1 1 0 0 0-1.061-1 9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h.114a.251.251 0 0 0 .177-.073ZM23.707 1.706A1 1 0 0 0 22.293.292l-22 22a1 1 0 0 0 0 1.414l.009.009a1 1 0 0 0 1.405-.009l6.63-6.631A.251.251 0 0 1 8.515 17a.245.245 0 0 1 .177.075 10.081 10.081 0 0 0 6.5 2.92 1 1 0 0 0 1.061-1V9.266a.247.247 0 0 1 .073-.176Z"/>
                            </svg>
                        </button>
                        <input type="range" class="kg-video-volume-slider" max="100" value="100">
                    </div>
                </div>
            </div>
            <figcaption><p><span style="white-space: pre-wrap;">This Atlas robot needs a little bit more practice. Source: https://www.youtube.com/watch?v=EezdinoG4mk</span></p></figcaption>
        </figure><h2 id="how-do-ai-agents-work">How do AI agents work?</h2><p>Software AI agents operate through a combination of perception, reasoning and action. At their core, they use Large Language Models (LLMs) to understand inputs and make decisions, but the real power comes from the interaction of these elements:</p><h3 id="input-processing">Input processing</h3><p>The agent receives information through various channels - direct user questions, system events, or data from external sources. We&#x2019;ll explore different input types when discussing agent sensors later in this article.</p><h3 id="decision-making">Decision-making</h3><p>Unlike simple chatbots, AI agents use multi-step prompting techniques to make decisions. Through chains of specialized prompts (reasoning, tool selection), agents can handle complex scenarios that are not possible with single-shot responses. We&#x2019;ll examine this &#x201C;reasoning engine&#x201D; in detail in the components section [anchor link to the relevant section].</p><h3 id="action-execution">Action execution</h3><p>Modern LLMs generate structured outputs that serve as function calls to external systems. For a detailed look at how agents interact with external services and handle feedback loops, check our <a href="https://blog.n8n.io/ai-agentic-workflows/"><u>guide on building AI agentic workflows</u></a>.</p><h3 id="learning-and-adaptation">Learning and adaptation</h3><p>Some agents can improve over time through various mechanisms - from simple feedback loops to sophisticated model updates. We&#x2019;ll explore these learning approaches in detail in the FAQ section.</p><p>The exact implementation of these components depends on the purpose and complexity of the agent, as you&#x2019;ll see in our examples of both human-activated and event-activated agents.</p><h2 id="what-are-the-types-of-agents-in-ai">What are the types of agents in AI?</h2><p>The AIMA textbook discusses several main types of agent programs based on their capabilities:</p><h3 id="simple-reflex-agents">Simple reflex agents&#xA0;</h3><p>These agents are fairly straightforward - they make decisions based only on what they perceive at the moment, without considering the past. They do their job when the right decision can be made just by looking at the current situation.</p><h3 id="model-based-reflex-agents">Model-based reflex agents&#xA0;</h3><p>Model-based reflex agents are a little more sophisticated. They keep track of what&apos;s happening behind the scenes, even if they can&apos;t observe it directly. They use a &quot;transition model&quot; to update their understanding of the world based on what they&apos;ve seen before, and a &quot;sensor model&quot; to translate that understanding into what&apos;s actually happening around them.</p><h3 id="goal-based-agents">Goal-based agents&#xA0;</h3><p>Goal-based agents are all about achieving a specific goal. They think ahead and plan a sequence of actions to reach their desired outcome. It&apos;s if they have a map and are trying to find the best route to their destination.</p><h3 id="utility-based-agents">Utility-based agents</h3><p>These ones are even more advanced. They assign a &quot;goodness&quot; score to each possible state based on a utility function. They not only focus on a single goal but also take into account factors like uncertainty, conflicting goals and the relative importance of each goal. They choose actions that maximize their expected utility, much like a superhero trying to save the day while minimizing collateral damage.</p><h3 id="learning-agents">Learning agents</h3><p>Learning agents are the ultimate adaptors. They start with a basic set of knowledge and skills, but constantly improve based on their experiences. They have a learning element that receives feedback from a critic who tells them how well they&apos;re doing. The learning element then tweaks the agent&apos;s performance to do better next time. It&apos;s like having a built-in coach that helps the agent perform their task better and better over time.</p><p>These theoretical concepts are great for understanding the basics of AI agents, but modern software agents powered by LLMs are like a mashup of all these types. LLMs can juggle multiple tasks, plan for the future, and even estimate how useful different actions might be.</p><p>Let&#x2019;s find out if there are any documented benefits of this approach.</p><h2 id="what-are-the-benefits-of-ai-agents">What are the benefits of AI agents?</h2><p>To understand the real impact of AI agents, we looked at LangChain&#x2019;s recent&#xA0; <a href="https://www.langchain.com/stateofaiagents?ref=blog.n8n.io"><u>State of AI Agents report</u></a>. This survey of more than 1,300 professionals across a variety of industries found that 51% of companies are already using AI agents in production, with adoption rates similar across both tech and non-tech sectors.</p><p>This isn&#x2019;t just hype &#x2013; these are documented benefits that companies are already seeing from employing AI agents:</p><h3 id="faster-information-analysis-and-decision-making">Faster information analysis and decision-making</h3><p>Handle large amounts of data, extract key insights and create summaries. This frees professionals from time-consuming research tasks and helps teams make data-driven decisions faster.</p><h3 id="increased-team-productivity">Increased team productivity</h3><p>Automate routine tasks, manage schedules and optimise workflows. Teams report that they have more time for creative and strategic work when agents are busy with administrative tasks.</p><h3 id="enhanced-customer-experience">Enhanced customer experience</h3><p>Speed up response times, handle basic inquiries and 24/7 support. This improves customer satisfaction and reduces the burden on support teams.</p><h3 id="accelerated-software-development">Accelerated software development</h3><p>Help with coding tasks, debugging and documentation. This speeds up development cycles and helps maintain code quality.</p><h3 id="improved-data-quality-and-consistency">Improved data quality and consistency</h3><p>Automatically process and enrich data, ensure consistency and reduce manual data entry errors.</p><p>Despite all these benefits, often leading to an increased cost-efficiency, implementing AI agents requires an understanding of their core components and how they work together. Let&apos;s take a closer look!</p><h2 id="what-are-the-key-components-of-an-ai-agent">What are the key components of an AI agent?</h2><p>In essence, an AI agent collects data with sensors, comes up with rational solutions using a reasoning engine, performs actions with actuators and learns from mistakes through its learning system. But what does this process look like in detail?</p><p>Let&apos;s break down the steps of an LLM-powered software agent.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfdMsBvp2ylyOHrxN8s1NWJIrpiTaq9xVKH7X3VjcYm0lnLKTph3n2ZYOoeC01AoNmYxBCS2Njme5mh_4KE5_au-oqp2LbS56VtVLwQdVvx69RJKwzailcZUcie39Y9ge63bmtSXQ?key=iZuOWR6MZUpLH4MiWsJcWLV0" class="kg-image" alt="AI Agents Explained: From Theory to Practical Deployment" loading="lazy" width="602" height="457"><figcaption><span style="white-space: pre-wrap;">A simplified diagram of an AI agent, adapted from: Artificial Intelligence: A Modern Approach, 4th Global ed.</span></figcaption></figure><h3 id="sensors">Sensors</h3><p>Information about the environment usually comes in the form of text information. This can be:</p><ul><li>Plain natural language text like a user query or question;</li><li>Semi-structured information, such Markdown or Wiki formatted text;</li><li>Various diagrams or graphs in text format, such as Mermaid flowcharts;</li><li>More structured text as a JSON object or in tabular form, log streams, time series data;</li><li>Code snippets or even complete programs in many programming languages;</li></ul><p><a href="https://huggingface.co/learn/computer-vision-course/unit4/multimodal-models/a_multimodal_world?ref=blog.n8n.io"><u>Multimodal LLMs</u></a> can receive images or even audio data as input.</p><h3 id="actuators">Actuators</h3><p>Most language models can only produce textual output. However, this output can be in a structured format such as XML, JSON, short snippets of code or even complete API calls with all query and body parameters.</p><p>It&#x2019;s now the developer&apos;s job to feed the outputs from LLMs into other systems (i.e. make an actual API call or <a href="https://docs.n8n.io/workflows/?ref=blog.n8n.io"><u>run an n8n workflow</u></a>).</p><p>Action results can go back into the model to provide feedback and update the information about the environment.</p><h3 id="reasoning-engine-aka-the-brain">Reasoning engine (aka the &quot;brain&quot;)</h3><p>The &quot;brain&quot; of an LLM-powered AI agent is, well, a large language model itself. It makes rational decisions based on goals to maximize a certain performance. When necessary, the reasoning engine receives feedback from the environment, self-controls and adapts its actions.</p><p>But how exactly does it work?</p><p>Giant pre-trained models such as GPT-4, Claude 3.5, Llama 3 and many others have a &quot;baked in&apos;&apos; understanding of the world they have gained from piles of data during training. Multimodal LLMs such as GPT-4o go further and get not only text, but also images, audio and even video data for training. Further fine-tuning allows these models to perform better at specific tasks.</p><p>What are the boundaries of those tasks is largely an area of ongoing research, but we already know that large LLMs are able to:</p><ul><li>follow instructions,</li><li>analyze visual and audio inputs,</li><li>imitate human-like reasoning,</li><li>understand the implied intent just from the user commands (known as prompts),</li><li>provide replies in a structured way, which allows direct connections of LLMs to external systems (via function or API calling).</li></ul><p>All that remains is the final step: how to build a series (or chains) of prompts so that LLM can simulate autonomous behavior.</p><p>And this is exactly where LangChain comes into play!</p><h2 id="what-are-the-ai-agent-examples">What are the AI agent examples?</h2><p>Based on LangChain&#x2019;s State of AI Agents report and <a href="https://blog.langchain.dev/introducing-ambient-agents/?ref=blog.n8n.io"><u>recent developments in the field</u></a>, there are two main approaches to implementing AI agents: human-activated and event-activated (ambient) agents.</p><p>Let&#x2019;s look at examples of both.</p><h3 id="human-activated-agents">Human-activated agents</h3><p>These agents respond to direct human input via chat interfaces or structured commands:</p><ol><li><strong>Research agents (like Perplexity)</strong></li></ol><p>Process user questions to search, analyze and synthesize information from multiple sources, maintaining context across conversations.</p><ol start="2"><li><strong>Customer service agents</strong></li></ol><p>Handle customer inquiries, maintain conversation context, and make decisions about when to escalate to human agents.</p>
<!--kg-card-begin: html-->
<script>
  workflowBanner([2468, 1978, 2099], document.currentScript);
</script>
<!--kg-card-end: html-->
<ol start="3"><li><strong>Development assistants (like </strong><a href="https://aider.chat/?ref=blog.n8n.io"><strong><u>aider</u></strong></a><strong>)</strong></li></ol><p>AI pair programming agents that understand codebases, suggest improvements, and help developers write better code faster.</p><h3 id="event-activated-ambient-agents">Event-activated (ambient) agents</h3><p>These agents work in the background, responding to events and system triggers without direct human intervention:</p><ol><li><strong>Email management agents</strong></li></ol><p>Monitor inboxes, draft responses and flag important messages for human review.</p><ol start="2"><li><strong>Security monitoring agents</strong></li></ol><p>Review system logs, detect anomalies and alert teams about potential issues.</p><ol start="3"><li><strong>Data quality agents</strong></li></ol><p>Continuously check incoming data, enforce consistency rules and flag anomalies.</p><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text">n8n does a great job of implementing both types of agents. You can create human-activated agents using chat triggers and webhooks, or build event-activated agents using n8n&#x2019;s extensive collection of trigger nodes and scheduling capabilities. This flexibility allows you to choose the right approach for your specific use case.</div></div><p>For those interested in exploring advanced AI agent frameworks, several projects provide additional opportunities:</p><ul><li><a href="https://www.langchain.com/agents?ref=blog.n8n.io"><u>LangChain</u></a> for building complex agent workflows;</li><li>BabyAGI (<a href="https://yoheinakajima.com/task-driven-autonomous-agent-utilizing-gpt-4-pinecone-and-langchain-for-diverse-applications/?ref=blog.n8n.io"><u>paper</u></a>, <a href="https://github.com/yoheinakajima/babyagi?ref=blog.n8n.io"><u>GitHub</u></a>) for task management and planning;</li><li><a href="https://github.com/reworkd/AgentGPT?ref=blog.n8n.io"><u>AgentGPT</u></a> for deploying agents via a browser.</li></ul><div class="kg-card kg-callout-card kg-callout-card-purple"><div class="kg-callout-emoji">&#x1F3A5;</div><div class="kg-callout-text">In n8n, you can integrate agents with various LLMs and text to speech models. To get a grasp of the huge possibilities for agentic automation, take a look at the example where we show how to build an AI voice assistant for restaurants bookings.</div></div><figure class="kg-card kg-embed-card"><iframe width="200" height="113" src="https://www.youtube.com/embed/OSVZfSDyaYM?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen title="Studio Update #03: Barcelona, Gmail Draft AI Assistant, VAPI Restaurant Voice Receptionist AI Agent"></iframe></figure><p>As we&apos;ve seen, AI agents come in two main types: those that respond to direct human input and those that work autonomously in the background. Both approaches have their place in modern automation strategies, and the choice depends on your specific needs.</p><h2 id="how-to-create-an-ai-agent">How to create an AI agent?</h2><p>Now that we&#x2019;ve covered key AI agents theory concepts, it&#x2019;s time to build one.&#xA0;</p><p>Before you begin, define the purpose and key components of an agent, including an LLM, memory, and reasoning capabilities.&#xA0;</p><p>Choose a framework such as LangChain or LlamaIndex to integrate RAG, set up APIs and execution logic. Finally, optimize the agent with feedback loops, monitoring, and fine-tuning to improve its performance over time.</p><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text">To make your life easier, n8n has integrated <a href="https://docs.n8n.io/advanced-ai/langchain/langchain-n8n/?ref=blog.n8n.io"><u>most of the core LangChain components</u></a> as visual nodes. These nodes let you efficiently automate workflows and interact with hundreds of other apps and services.</div></div><h3 id="why-use-langchain-for-ai-agents">Why use LangChain for AI agents?</h3><p>In the context of AI agents, LangChain is a framework that lets you leverage large language models (LLMs) to design and build these agents.</p><p>Traditionally, you&#x2019;d program in code the whole sequence of actions an agent takes.</p><p>LangChain simplifies this process by providing prompt templates and tools that an agent gets access to. An LLM acts as the reasoning engine behind your agent and decides what actions to take and in which order. LangChain hides the complexity of this decision making behind its own API. Note that this is not a REST API, but rather an internal API designed specifically for interacting with these models to streamline agent development.</p><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text">n8n takes it a step further by providing a low-code interface to LangChain. In n8n, you can simply drag and drop LangChain nodes onto the canvas and configure them. Advanced users can even <a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.code/?ref=blog.n8n.io"><u>write JS code for some of the LangChain modules</u></a>. n8n supports the JavaScript implementation of LangChain. Finally, LangChain supports several prompting techniques suitable for making AI agents.</div></div><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXe9mv2-G5romTFN1cIETh1EcTeW9DP7TMXlLNqjNzc7rTLFua2PkOEByowHddC0utRV6cl7dSf2AH8gPSnGIqH2jFU4f5uSfWdWF8nQ0MbY2WW_AhmbRsnPosgwjuRzq6NS37oc8w?key=iZuOWR6MZUpLH4MiWsJcWLV0" class="kg-image" alt="AI Agents Explained: From Theory to Practical Deployment" loading="lazy" width="602" height="301"><figcaption><span style="white-space: pre-wrap;">An example of a conversation agent.</span></figcaption></figure><p>This simple conversation agent uses window buffer memory and a tool for making Google search requests. With n8n you can easily swap Language Models, provide different types of chat memory and add extra tools.</p>
<!--kg-card-begin: html-->
<script>
  workflowBanner(1954, document.currentScript);
</script>
<!--kg-card-end: html-->
<h2 id="building-smart-create-your-own-intelligent-data-analyst-ai-agent-with-n8n">Building smart: Create your own intelligent data analyst AI agent with n8n</h2><p>Let&#x2019;s build a practical example now: an intelligent data analyst agent that helps users get insights from a database using natural language.</p><p>Instead of overloading the LLM context window with raw data, our agent will use SQL to efficiently query the database - just like human analysts do. This approach combines the best of both worlds: users can ask questions in plain English, while the agent handles the technical complexities of interacting with the database behind the scenes.</p><p>In this example, we use the sample of a customer database, but the same principles apply to any business data you might have. Our agent will help answer questions like &#x201C;What are our top-selling products?&#x201D; or &#x201C;What are the sales trends by region?&#x201D; without requiring users to know SQL.</p><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text">In n8n, everything is organized as workflows - sets of interconnected nodes that process and transfer data. While simple workflows can handle basic automations, more sophisticated workflows can act as AI agents when combined with LangChain and other AI-powered nodes.</div></div><div class="kg-card kg-callout-card kg-callout-card-purple"><div class="kg-callout-emoji">&#x1F3A5;</div><div class="kg-callout-text">Here is a detailed video walkthrough to help you get started with agentic workflows in n8n and learn the core workflow components.</div></div><figure class="kg-card kg-embed-card"><iframe width="200" height="113" src="https://www.youtube.com/embed/yzvLfHb0nqE?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen title="Building AI Agents: Chat Trigger, Memory, and System/User Messages Explained [Part 1]"></iframe></figure><p>To create a workflow, sign up for a <a href="https://n8n.io/pricing/?ref=blog.n8n.io"><u>cloud n8n account</u></a> or <a href="https://docs.n8n.io/hosting/?ref=blog.n8n.io"><u>self-host your own n8n instance</u></a>.</p><p>Once you are in, find the page with the template and click &#x201C;Use workflow&#x201D;. Alternatively, create a workflow from scratch.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXdUtIHTMTX0AgZOiY8m9U8Tn82geSY8uOA_TYA-YMC4Aw80dtPfYXg-i8CZXoaykmte9tylgW0GNhTU8aXh1ELf6qLIL6-2DYBBJ2Jqtr1nT-f5vG5C3-2Y7spzufsxqEuJo8fX?key=iZuOWR6MZUpLH4MiWsJcWLV0" class="kg-image" alt="AI Agents Explained: From Theory to Practical Deployment" loading="lazy" width="602" height="484"><figcaption><span style="white-space: pre-wrap;">A simple SQL Agent to &#x201C;talk&#x201D; to the local SQLite database.</span></figcaption></figure>
<!--kg-card-begin: html-->
<script>
  workflowBanner(2292, document.currentScript);
</script>
<!--kg-card-end: html-->
<h3 id="step-1-download-and-save-sqlite-file">Step 1. Download and save SQLite file</h3><p>The top part of the workflow starts with the Manual trigger.</p><ol><li>The HTTP Request node downloads a <a href="https://www.sqlitetutorial.net/sqlite-sample-database/?ref=blog.n8n.io"><u>Chinook example database</u></a> as a zip archive;</li><li>The <a href="https://n8n.io/integrations/compression/?ref=blog.n8n.io"><u>Compression</u></a> node extracts the content using a decompress operation;</li><li>Finally, the <a href="https://n8n.io/integrations/readwrite-files-from-disk/?ref=blog.n8n.io"><u>Read/Write Files from Disk</u></a> node saves the .db file locally.</li></ol><p>Run this part manually only once.</p><h3 id="step-2-receive-the-chat-message-and-load-the-local-sqlite-file">Step 2. Receive the chat message and load the local SQLite file</h3><p>The lower part of the workflow is a bit more complex, let&#x2019;s take a closer look at how it works.</p><ol>
<li>The first node is a chat trigger. This is where you can send queries, such as &quot;What is the revenue by genre?&quot;</li>
<li>Immediately afterwards, the local chinook.db is loaded into the memory.</li>
<li>The next Set node combines the binary data with the Chat Trigger input. Select the JSON mode and provide the following expression: <code>{{ $(&apos;Chat Trigger&apos;).item.json }}</code>. Also, turn on the &quot;Include Binary File&quot; toggle (you can find it by clicking on Add Options).</li>
</ol>
<figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfAi18RHE6ANl79HtwJ7CM14TkvH1sjnS_5zk04Mbt9HOv7Rh40V4EsBm3jD9OqRXG-0FFpKmqjYbWK_GXz-LkFLANSMnYY_LzQNqf4uJyZO3aJocNnHm6JCgpKCPOi9zK4HQ2c?key=iZuOWR6MZUpLH4MiWsJcWLV0" class="kg-image" alt="AI Agents Explained: From Theory to Practical Deployment" loading="lazy" width="602" height="239"><figcaption><span style="white-space: pre-wrap;">Use the Set node to combine JSON and binary data from different sources</span></figcaption></figure><h3 id="step-3-add-and-configure-the-langchain-agent-node">Step 3. Add and configure the LangChain Agent node</h3><p>Let&#x2019;s take a look at the LangChain Agent node</p><p>Select the SQL Agent type and SQLite database source. This allows you to work with a local SQLite file without connecting to remote sources.</p><p>Make sure that the Input Binary Field name matches the binary data name.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXevCIx4oPNhq0MyDbyWlwxW3QRG4G3GpF9tKTm-ot5XVlOFmelUkXdDa44yLfRfMPwXhKe0CiegFLB-9zbDoq-0LZUvKhPbXbmpT9S1RLTuwHJRqm9ENJcU6-RricBf2VqnbK8S?key=iZuOWR6MZUpLH4MiWsJcWLV0" class="kg-image" alt="AI Agents Explained: From Theory to Practical Deployment" loading="lazy" width="602" height="257"><figcaption><span style="white-space: pre-wrap;">The LangChain SQL Agent makes several requests before providing a final response</span></figcaption></figure><p>Save the rest of the other settings, close the config window and connect 2 additional nodes: the Windows Buffer Memory node - to store past responses - and the Model node, such as the OpenAI Chat model node. Choose a model (i.e. gpt-4-turbo) and set the temperature. For coding tasks, it is better to use lower values, such as 0.3.</p><p>Now you can ask various questions about your data, even non-trivial ones! Compare the following user inputs:</p><ul><li>&quot;What are the names of the employees?&quot; requires just 2 SQL queries VS</li><li>&quot;What are the revenues by genre?&quot;, where the agent has to make several requests before arriving at a solution.</li></ul><p>This agent can still be improved, e.g. you can always pass the schema so the agent doesn&#x2019;t waste resources figuring out the structure every time.</p><div class="kg-card kg-callout-card kg-callout-card-purple"><div class="kg-callout-emoji">&#x1F3A5;</div><div class="kg-callout-text">Expand your AI agent with external services like Gmail or a message app to effectively share the query results with your team.</div></div><figure class="kg-card kg-embed-card"><iframe width="200" height="113" src="https://www.youtube.com/embed/lkudvrC3AOU?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen title="Building AI Agents: AI App Tools and Guardrails explained, Gmail Draft Agent [Part 2]"></iframe></figure>
<!--kg-card-begin: html-->
<script>
  workflowBanner([2508, 2006], document.currentScript);
</script>
<!--kg-card-end: html-->
<h2 id="faq">FAQ</h2>
<!--kg-card-begin: html-->
<details>
	<summary>
        <h4 style="display: inline-block; margin: 0 0 0.5em 0;" id="faq-1">Can LLM act as an AI agent?</h4>
    </summary>
		<p dir="ltr"><span style="white-space: pre-wrap;">While LLMs cannot act as standalone AI agents, they are one of the agents&#x2019; key components. Let&#x2019;s see why.</span></p>
		<p dir="ltr"><span style="white-space: pre-wrap;">Modern AI research revolves around neural networks. Most networks were only capable of performing a single task or a bundle of closely related tasks: a great example is </span><a href="https://deepmind.google/discover/blog/agent57-outperforming-the-human-atari-benchmark/?ref=blog.n8n.io" target="_blank" rel="noopener"><u><span class="underline" style="white-space: pre-wrap;">DeepMind&apos;s Agent57</span></u></a><span style="white-space: pre-wrap;">, which could play all 57 Atari games with a single model and achieved superhuman performance on most of them.</span></p>
		<p dir="ltr"><span style="white-space: pre-wrap;">This all changed with the advent of </span><a href="https://arxiv.org/abs/1706.03762?ref=blog.n8n.io" target="_blank" rel="noopener"><u><span class="underline" style="white-space: pre-wrap;">modern transformer-based large language models</span></u></a><span style="white-space: pre-wrap;">.</span></p>
		<p dir="ltr"><span style="white-space: pre-wrap;">Early GPT (generative pre-trained transformer) models could only serve as fancy chatbots with encyclopedic knowledge. However, as the number of model parameters increased, almost every modern LLM grasped many ideas purely from textual data. Simply put: no one specifically trained the model to translate text or fix code, and yet it got by.</span></p>
		
		<figure class="kg-card kg-video-card kg-card-hascaption"><div class="kg-video-container" style="padding-bottom: 36.375%;"><video src="https://blog.n8n.io/content/media/2024/06/llm-animated.webm" poster="https://img.spacergif.org/v1/1600x582/0a/spacer.png" width="1600" height="582" loop autoplay muted playsinline preload="metadata" style="background: transparent url(&apos;https://blog.n8n.io/content/images/2024/06/media-thumbnail-ember492.jpg&apos;) 50% 50% / cover no-repeat;"></video><div class="kg-video-overlay kg-video-hide-animated"><button class="kg-video-large-play-icon kg-video-hide-animated"><svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24"><path d="M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z"/></svg></button></div><div class="kg-video-player-container kg-video-hide kg-video-hide-animated"><div class="kg-video-player" style="--buffered-width: 100%; --seek-before-width: 0%;"><button class="kg-video-play-icon kg-video-hide"><svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24"><path d="M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z"/></svg></button><button class="kg-video-pause-icon"><svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24"><rect x="3" y="1" width="7" height="22" rx="1.5" ry="1.5"/><rect x="14" y="1" width="7" height="22" rx="1.5" ry="1.5"/></svg></button><span class="kg-video-current-time">0:00</span><div class="kg-video-time">/<span class="kg-video-duration">0:09</span></div><input type="range" class="kg-video-seek-slider" max="9" value="0"><button class="kg-video-playback-rate">1&#xD7;</button><button class="kg-video-unmute-icon kg-video-hide"><svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24"><path d="M15.189 2.021a9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h1.794a.249.249 0 0 1 .221.133 9.73 9.73 0 0 0 7.924 4.85h.06a1 1 0 0 0 1-1V3.02a1 1 0 0 0-1.06-.998Z"/></svg></button><button class="kg-video-mute-icon"><svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24"><path d="M16.177 4.3a.248.248 0 0 0 .073-.176v-1.1a1 1 0 0 0-1.061-1 9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h.114a.251.251 0 0 0 .177-.073ZM23.707 1.706A1 1 0 0 0 22.293.292l-22 22a1 1 0 0 0 0 1.414l.009.009a1 1 0 0 0 1.405-.009l6.63-6.631A.251.251 0 0 1 8.515 17a.245.245 0 0 1 .177.075 10.081 10.081 0 0 0 6.5 2.92 1 1 0 0 0 1.061-1V9.266a.247.247 0 0 1 .073-.176Z"/></svg></button><input type="range" class="kg-video-volume-slider" max="100" value="100"></div></div></div><figcaption>What an LLM can do largely depends on the number of model parameters alone. Source: https://research.google/blog/pathways-language-model-palm-scaling-to-540-billion-parameters-for-breakthrough-performance/</figcaption></figure>
		
		<p dir="ltr"><span style="white-space: pre-wrap;">Mixing a huge amount of training data and a large number of model parameters was enough to &#x201C;bake in&#x201D; many real-world ideas into the model.</span></p>
		<p dir="ltr"><span style="white-space: pre-wrap;">Through further fine-tuning, these transformer-based models were able to follow instructions even better.</span></p>
		<p dir="ltr"><span style="white-space: pre-wrap;">All this incredible progress allows you to create AI agents with just a set of sophisticated instructions called prompts.</span></p>
</details>
<!--kg-card-end: html-->

<!--kg-card-begin: html-->
<details><summary><h4 style="display: inline-block; margin: 0 0 0.5em 0;" id="faq-2">Is ChatGPT an AI agent?</h4></summary>
<!--kg-card-end: html-->
<p>ChatGPT is an impressive system that combines LLM capabilities with several built-in tools, including web browsing, data analytics, and <a href="https://help.openai.com/en/articles/10291617-scheduled-tasks-in-chatgpt?ref=blog.n8n.io">recently added scheduled tasks</a>. It exhibits some rudimental agentic behaviour, but still lacks crucial components. For example, ChatGPT is not yet fully autonomous and requires human input at each iteration.</p>
<p>The choice between ChatGPT and custom AI agents depends on your needs and usage scenarios. ChatGPT is great for general conversational AI, content creation and broad applications. For specialized tasks, real-time data processing and integrated system solutions, custom AI agents might be a better fit.</p>

<!--kg-card-begin: html-->
</details>
<!--kg-card-end: html-->
<div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text">To maximize the potential of AI in your projects, take a look at our recent articles on <a href="https://blog.n8n.io/ai-coding-assistants/"><u>AI coding assistants</u></a> and the <a href="https://blog.n8n.io/best-ai-chatbot/"><u>best AI chatbots</u></a>.</div></div>
<!--kg-card-begin: html-->
<details><summary><h4 style="display: inline-block; margin: 0 0 0.5em 0;" id="faq-3"> What are multi-agent systems?</h4></summary>
<!--kg-card-end: html-->
<p>Multi-agent systems are environments in which multiple AI agents work together, each performing specific tasks while coordinating their actions. Think of it as a team of specialists: one agent can handle customer requests, another processes data, and a third manages scheduling. These agents communicate and collaborate to achieve complex goals that would be difficult for a single agent to accomplish.</p>

<!--kg-card-begin: html-->
</details>
<!--kg-card-end: html-->
<div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text">In n8n, you can create multi-agent systems by connecting multiple workflows, each representing a specialized agent. Learn more about this approach in our guide to <a href="https://blog.n8n.io/ai-agentic-workflows/"><u>AI agentic workflows</u></a>, which covers patterns for building collaborative agent teams.</div></div>
<!--kg-card-begin: html-->
<details><summary><h4 style="display: inline-block; margin: 0 0 0.5em 0;" id="faq-4"> How do AI agents learn and improve over time?</h4></summary>
<!--kg-card-end: html-->
<p>AI agents can learn and improve in several ways without necessarily changing their underlying AI models:</p>
<ul>
<li><strong>Few-shot learning</strong> is a technique where agents learn from recent successful interactions and use them as examples for similar future cases. For instance, a customer service agent can use recent successful responses as templates for new queries.</li>
<li><strong>Retrieval-Augmented Generation (RAG)</strong> may be required to work with company-specific information. By building and accessing an expanding knowledge base, agents can provide more accurate, contextual responses over time without modifying their underlying AI models.</li>
<li><strong>Prompt optimization</strong> involves storing successful prompts and their outcomes in a vector database, then automatically adjusting prompt templates based on performance metrics. For example, if certain prompt structures consistently lead to higher user satisfaction ratings, the agent will favor these patterns.</li>
</ul>
<p>For more advanced scenarios involving LLMs, learning can happen at the model level through:</p>
<ul>
<li><strong>Continuous pre-training</strong> is the process of updating the model with new domain data to expand its knowledge in specific areas, while;</li>
<li><strong>Fine-tuning</strong> involves adjusting the model for better performance on specific tasks.</li>
</ul>
<p>However, not all AI agents need sophisticated learning capabilities. For some tasks, agents with fixed behaviours and clear performance metrics are better suited.The key is to tailor the learning approach to your specific needs.</p>

<!--kg-card-begin: html-->
</details>
<!--kg-card-end: html-->
<h2 id="wrap-up">Wrap up</h2><p>In this guide, we briefly introduced what an AI agent is and how it works, what types of AI agents exist and what the benefits of using one are.&#xA0;</p><p>We&#x2019;ve also gone through some AI agent examples and showed how to create a LangChain SQL agent in n8n that can analyze a local SQLite file and provide answers based on its contents.</p><h2 id="what%E2%80%99s-next">What&#x2019;s next?</h2><p>Now that you have an overview and a practical example of how to create AI agents, it&#x2019;s time to challenge the status quo and create an agent for <em>your</em> real-world tasks.</p><p>With n8n&#x2019;s low-code capabilities, you can focus on designing, testing and upgrading the agent. All the details are hidden under the hood, but you can of course write your own JS code in LangChain nodes if needed.</p>
<!--kg-card-begin: html-->
<script>
  workflowBanner([2559, 1963], document.currentScript, { 
      workflowsHeader: "Workflows with AI agents powered by n8n"
  });
</script>
<!--kg-card-end: html-->
<div class="kg-card kg-callout-card kg-callout-card-purple"><div class="kg-callout-emoji">&#x1F3A5;</div><div class="kg-callout-text">If you want to interact with models more effectively and get accurate and relevant results, check out our tutorial on prompt engineering.</div></div><figure class="kg-card kg-embed-card"><iframe width="200" height="113" src="https://www.youtube.com/embed/77Z07QnLlB8?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen title="Building AI Agents: Prompt Engineering for Beginners [Part 3]"></iframe></figure><p>Whether you work alone, in a small team or in an enterprise, n8n has a lot to offer. <a href="https://n8n.io/pricing/?ref=blog.n8n.io"><u>Choose from our cloud plans</u></a> and jump-start right away or explore powerful features of the <a href="https://n8n.io/enterprise/?ref=blog.n8n.io"><u>Enterprise edition</u></a>. If you&#x2019;re a small growing startup, there is a special plan for you on the pricing page.</p><p><a href="https://community.n8n.io/?ref=blog.n8n.io"><u>Join our community forum</u></a> and share your success or seek support!</p>]]></content:encoded></item><item><title><![CDATA[The 11 best open-source LLMs for 2025]]></title><description><![CDATA[Discover these top 11 open-source LLMs and build advanced AI workflows with n8n LangChain integration.]]></description><link>https://blog.n8n.io/open-source-llm/</link><guid isPermaLink="false">671a5a590783110001c1a7d0</guid><category><![CDATA[AI]]></category><category><![CDATA[Guide]]></category><dc:creator><![CDATA[Yulia Dmitrievna]]></dc:creator><pubDate>Mon, 10 Feb 2025 09:38:00 GMT</pubDate><media:content url="https://blog.n8n.io/content/images/2025/01/11-os-llm--1-.jpg" medium="image"/><content:encoded><![CDATA[<img src="https://blog.n8n.io/content/images/2025/01/11-os-llm--1-.jpg" alt="The 11 best open-source LLMs for 2025"><p>Open-source models are changing the LLM landscape, promising better security, cost-efficiency, and customization for AI deployments. While <a href="https://nerdynav.com/chatgpt-statistics/?ref=blog.n8n.io"><u>ChatGPT has over 180 million users</u></a>, on-premises solutions already control more than half of the LLM market, with <a href="https://market.us/report/large-language-model-llm-market/?ref=blog.n8n.io"><u>projections indicating continued growth</u></a> in the coming years.</p><p>The trend is clear: since early 2023, new open-source model releases have nearly doubled compared to their closed-source counterparts.</p><figure class="kg-card kg-image-card kg-width-wide kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXdk1JmwPe5tLC6-XHppDpkBwOXd1t-WL4Pu871KVEdheZm03QYtJPD4WU1OXmG_ZiQDp-zHiN9BU5CruVQslAXf4QfqZd5mYPY4oUGbONPORbmVy9AZcy0hUh3QzsiBZ5ca46m1uw?key=INQ3nGlG9V9oPWqw4SkZT1dt" class="kg-image" alt="The 11 best open-source LLMs for 2025" loading="lazy" width="624" height="215"><figcaption><span style="white-space: pre-wrap;">LLM releases by year: blue cards = pre-trained models, orange cards = instruction-tuned. Top half shows open-source models, bottom half contains closed-source ones. Source: </span><a href="https://arxiv.org/abs/2307.06435?ref=blog.n8n.io"><u><span class="underline" style="white-space: pre-wrap;">https://arxiv.org/abs/2307.06435</span></u></a></figcaption></figure><p>Today, we&#x2019;ll dive into the world of open-source LLMs and:</p><ul><li>discuss the reasons behind the surge in open-source LLM deployments;</li><li>recognize potential pitfalls and challenges;</li><li>review the 11 best open-source LLMs on the market;</li><li>show you how to easily access these powerful open-source AI models;</li><li>guide you on how to get started with open-source LLMs using <a href="https://n8n.io/integrations/categories/ai/?ref=blog.n8n.io"><u>Ollama and LangChain in n8n</u></a>.</li></ul><p>Read on to find out!</p><h2 id="are-there-any-open-source-llms">Are there any open-source LLMs?</h2><p>For this article, we&#x2019;ve selected 11 popular open-source LLM models, focusing on both widely used and available in <a href="https://ollama.com/library?ref=blog.n8n.io"><u>Ollama</u></a>.</p><p>Our review covers a range of pre-trained &#x201C;base&#x201D; models and their fine-tuned variants. These models come in various sizes, and you can either use them directly or opt for fine-tuned versions from original developers or third-party sources.</p><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text">While pre-trained models provide a strong foundation, fine-tuned versions are typically necessary for practical, task-specific applications. Many vendors offer pre-fine-tuned models, but users can create their own datasets to further fine-tune for more specialized use cases.</div></div><p>Here&apos;s our open-source LLM leaderboard:</p><table>
<thead>
<tr>
<th>Model<br>Family</th>
<th>Developer</th>
<th>Params</th>
<th>Context<br>window</th>
<th>Use-cases</th>
<th>License</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#llama3">Llama 3</a></td>
<td>Meta</td>
<td>1B, 3B, 8B,<br>70B, 405B</td>
<td>8k, 128k</td>
<td>- General text generation<br>- Multilingual tasks<br>- Code generation<br>- Long-form content<br>- Fine-tuning for specific domains</td>
<td>Llama Community License</td>
</tr>
<tr>
<td><a href="#mistral">Mistral</a></td>
<td>Mistral AI</td>
<td>3B-124B</td>
<td>32k-128k</td>
<td>- High-complexity tasks<br>- Multilingual processing<br>- Code generation<br>- Image understanding<br>- Edge computing<br>- On-device AI<br>- Function calling<br>- Efficient large-scale processing</td>
<td>Apache 2.0<br>Mistral Research License<br>Commercial License</td>
</tr>
<tr>
<td><a href="#falcon-3">Falcon 3</a></td>
<td>TII</td>
<td>1B, 3B,<br>7B, 10B</td>
<td>8k-32k</td>
<td>- General text generation<br>- Code generation<br>- Mathematical tasks<br>- Scientific knowledge<br>- Multilingual applications<br>- Fine-tuning for specific domains</td>
<td>TII Falcon License</td>
</tr>
<tr>
<td><a href="#gemma-2">Gemma 2</a></td>
<td>Google</td>
<td>2B, 9B, 27B</td>
<td>8k</td>
<td>- General text generation<br>- Question answering<br>- Summarization<br>- Code generation<br>- Fine-tuning for specific domains</td>
<td>Gemma license</td>
</tr>
<tr>
<td><a href="#phi-3x-4">Phi-3.x / 4</a></td>
<td>Microsoft</td>
<td>3.8B (mini)<br>7B (small)<br>14B (medium)<br>42B (MoE)</td>
<td>4k, 8k, 128k<br>16k (Phi-4)</td>
<td>- General text generation<br>- Multi-lingual tasks<br>- Code understanding<br>- Math reasoning<br>- Image understanding (vision model)<br>- On-device inference</td>
<td>Microsoft Research<br>License</td>
</tr>
<tr>
<td><a href="#command-r">Command R</a></td>
<td>Cohere</td>
<td>7B, 35B, 104B</td>
<td>128k</td>
<td>- Conversational AI<br>- RAG<br>- Tool use<br>- Multilingual tasks<br>- Long-form content generation</td>
<td>CC-BY-NC 4.0</td>
</tr>
<tr>
<td><a href="#stablelm">StableLM 2</a></td>
<td>Stability AI</td>
<td>1.6B, 3B, 12B</td>
<td>Up to 16k</td>
<td>- Multilingual text generation<br>- Code generation and understanding<br>- Fine-tuning for specific tasks<br>- Research and commercial applications</td>
<td>Stability AI Community<br>and Enterprise licenses</td>
</tr>
<tr>
<td><a href="#starcoder">StarCoder2</a></td>
<td>BigCode</td>
<td>3B, 7B, 15B</td>
<td>16k</td>
<td>- Code completion<br>- Multi-language programming<br>- Code understanding<br>- Fine-tuning for specific tasks</td>
<td>Apache 2.0</td>
</tr>
<tr>
<td><a href="#yi">Yi</a></td>
<td>01.AI</td>
<td>6B, 9B, 34B</td>
<td>4k, 8k, 200k</td>
<td>- Bilingual text generation<br>- Code understanding and generation<br>- Math and reasoning tasks<br>- Fine-tuning for specific domains</td>
<td>Apache 2.0</td>
</tr>
<tr>
<td><a href="#qwen25">Qwen2.5</a></td>
<td>Alibaba</td>
<td>0.5B to 72B</td>
<td>128K</td>
<td>- General text generation<br>- Multilingual tasks<br>- Code generation<br>- Mathematical reasoning<br>- Structured data processing</td>
<td>Qwen license<br>(3B and 72B size models)<br>Apache 2.0 (others)</td>
</tr>
<tr>
<td><a href="#deepseek-2x-3">DeepSeek-V2.x/V3</a></td>
<td>DeepSeek AI</td>
<td>16B, 236B,<br>671B for V3<br>(2.4B-37B<br>activated)</td>
<td>32k-128k</td>
<td>- General text generation<br>- Multilingual tasks<br>- Code generation<br>- Fine-tuning<br>- Advanced reasoning (V3)</td>
<td>DeepSeek License</td>
</tr>
</tbody>
</table>
<p>For a comprehensive list of available LLMs beyond our selection, you can explore the <a href="https://github.com/Hannibal046/Awesome-LLM?ref=blog.n8n.io"><u>Awesome-LLM GitHub repository</u></a>, which provides an extensive catalog of language models and related resources.</p><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text">Did you know that in <a href="https://n8n.io/integrations/?ref=blog.n8n.io"><u>n8n &#x2013; a workflow automation tool</u></a> &#x2013; you can use open-source LLMs in several ways. <br><br><b><strong style="white-space: pre-wrap;">First</strong></b>, there is a dedicated node to connect to Ollama models &#x2013; the easiest way to start working with locally deployed LLMs.<br><br><b><strong style="white-space: pre-wrap;">Second</strong></b>, an OpenAI node allows you to specify a custom endpoint. This way you can swap between OpenAI and open-source LLMs &#x2013; a perfect solution for working with OpenRouter.<br><br><b><strong style="white-space: pre-wrap;">Finally</strong></b>, there are several nodes to other providers, such as HuggingFace, and even a custom HTTP Request node. Thanks to the straightforward user interface in n8n, your LLM-powered workflow automations and AI-agents remain the same when you switch between models. To easily deploy a local model, begin with a <a href="https://github.com/n8n-io/self-hosted-ai-starter-kit?ref=blog.n8n.io"><u>n8n&#x2019;s self-hosted AI starter kit with Ollama</u></a> integration.</div></div><h2 id="what-are-the-advantages-and-disadvantages-of-open-source-llms">What are the advantages and disadvantages of open-source LLMs?</h2><p>Open-source LLMs offer several advantages beyond publicly available model weights and increased transparency:</p><ul><li>Full ownership ensures complete control over the model, additional training data, and practical applications.</li><li>Better fine-tuning accuracy is possible due to flexible customization of local model parameters, supported by community contributions.</li><li>Longevity is guaranteed as self-hosted models don&#x2019;t become obsolete, unlike closed-source providers who may &#x201C;retire&#x201D; older models.</li><li>Better cost estimation is possible as expenses shift from potentially volatile usage-based pricing to infrastructure costs. However, total costs may exceed subscription-based services, depending on usage patterns and infrastructure choices.</li><li>Flexibility in choosing software and hardware combinations allows for optimal resource allocation based on specific needs.</li><li>Community contributions enable model optimization through techniques like quantization and pruning, as well as the development of efficient deployment strategies and supporting tools.</li></ul><p>Despite their benefits, open-source LLMs come with some potential drawbacks:</p><ul><li>Quality may not match solutions offered by large corporations due to limited resources.</li><li>Vulnerability to attacks is a concern, as bad actors can potentially manipulate input data and interfere with the model&#x2019;s behavior in open-source environments.</li><li>License requirements vary widely. Some models use permissive licenses (like Apache 2.0), others have non-commercial restrictions, and some (like Meta Llama 3) include specific terms for commercial usage.</li></ul><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">&#x1F517;</div><div class="kg-callout-text">LLMs are commonly used for <a href="https://blog.n8n.io/open-source-chatbot/"><u>chatbots</u></a>, <a href="https://blog.n8n.io/llm-agents/"><u>AI agents</u></a> and <a href="https://blog.n8n.io/ai-agentic-workflows/"><u>workflow automations</u></a>. Check out our earlier blog articles.</div></div><h2 id="what-is-the-best-open-source-llm">What is the best open-source LLM?</h2><p>There is no single best open-source LLM.&#xA0;</p><p>And here&#x2019;s why.</p><p>There are many benchmarks for rating the models, and various research groups decide which benchmarks are suitable. This makes objective comparison rather non-trivial.</p><p>Thanks to the Hugging Face, there is a <a href="https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard?ref=blog.n8n.io"><u>public leaderboard for the open-source LLMs</u></a>.</p><p>It <a href="https://huggingface.co/docs/leaderboards/open_llm_leaderboard/about?ref=blog.n8n.io"><u>performs tests on 6 key benchmarks</u></a> using the Eleuther AI Language Model Evaluation Harness. The results are aggregated and each model receives a final score.</p><p>The leaderboard has several quick filters for consumer-grade, edge device models and so on. Several adjustable columns such as model size, quantization method, etc. are also available.</p><p>The leaderboard is an open competition and anyone can submit their model for evaluation.</p><p>Let&#x2019;s take open-source LLMs one by one and have a closer look at them!</p><h3 id="llama3">Llama3</h3><p><strong>Best for</strong>: general-purpose applications with scalability needs</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXcNs-EXXhwbBahLP_uGL0DEP8hPIEj81LWKRqUr13CS4XlEExOU3GMPZvDpZSn_mOMi9eXPjQxJqW9WxqcXU6Y56okQgEHgl-Da2YBdBomvAhusoiYvMnzyxvM-NcpbFXRpXsmA?key=INQ3nGlG9V9oPWqw4SkZT1dt" class="kg-image" alt="The 11 best open-source LLMs for 2025" loading="lazy" width="624" height="312"><figcaption><span style="white-space: pre-wrap;">Llama3 is great for general-purpose applications with scalability needs</span></figcaption></figure><p><a href="https://ai.meta.com/blog/meta-llama-3/?ref=blog.n8n.io"><u>Llama 3</u></a> is Meta&#x2019;s latest generation of open-source large language models, offering high performance across a wide range of tasks. The latest Llama 3.3 70B model offers performance comparable to the 405B parameter model at a fraction of the computational cost, making it an attractive option for developers and researchers.</p><div class="kg-card kg-callout-card kg-callout-card-red"><div class="kg-callout-emoji">&#x2699;&#xFE0F;</div><div class="kg-callout-text"><b><strong style="white-space: pre-wrap;">Llama 3 key features</strong></b></div></div><ul><li>Multiple model sizes: 1B, 3B, 8B, 70B, and 405B parameters</li><li>Multilingual and multimodal capabilities</li><li><a href="https://www.ibm.com/think/topics/grouped-query-attention?ref=blog.n8n.io"><u>Grouped Query Attention</u></a> (GQA) for improved inference efficiency</li><li>Context windows of 8k tokens for smaller models, up to 128k tokens for larger models</li><li>Responsible AI development with tools like Llama Guard 2 and Code Shield</li></ul><div class="kg-card kg-callout-card kg-callout-card-accent"><div class="kg-callout-emoji">&#x1F9BE;</div><div class="kg-callout-text"><b><strong style="white-space: pre-wrap;">Llama 3 use cases</strong></b></div></div><ul><li>General-purpose text generation and understanding</li><li>Multilingual applications across various languages</li><li>Code generation and understanding</li><li>Long-form content creation and analysis</li><li>Fine-tuning for specific domains or tasks</li><li>Assistant-like interactions in chatbots and AI applications</li></ul><h3 id="mistral">Mistral</h3><p><strong>Best for</strong>: on-device AI with function calling</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXeDPDSDS0Zu7yMbO_1NciZn8EUNfBbbvtlsb4LXxyiUOCYfLHtuzjubjNBwh9Qjt2IUVTpBuLKPgYM8lhZuctOdQug0ZwbkvMjg2-dqerMV_ggpO6eTMTMqWr-Tng7mm1yXNk3L?key=INQ3nGlG9V9oPWqw4SkZT1dt" class="kg-image" alt="The 11 best open-source LLMs for 2025" loading="lazy" width="624" height="312"><figcaption><span style="white-space: pre-wrap;">Mistral models are best for on-device AI with function calling</span></figcaption></figure><p><a href="https://mistral.ai/technology/?ref=blog.n8n.io#models"><u>Mistral AI</u></a>, a French startup, has rapidly become a major player in the open-source LLM space. Mistral&#x2019;s models are designed to cater to a wide range of applications, from edge devices to large-scale enterprise solutions. The company offers both open-source models under Apache 2.0 license and commercial models with negotiable licenses. The latest Ministral model (3B and 8B) is particularly noteworthy for its performance in edge computing scenarios, outperforming similarly-sized models from tech giants.</p><div class="kg-card kg-callout-card kg-callout-card-red"><div class="kg-callout-emoji">&#x2699;&#xFE0F;</div><div class="kg-callout-text"><b><strong style="white-space: pre-wrap;">Mistral AI key features</strong></b></div></div><ul><li>Multiple model sizes: from 3B to 124B parameters</li><li>Multilingual and multimodal capabilities</li><li>Large context windows up to 128k tokens</li><li>Native function calling support</li><li>Mixture-of-experts (MoE) architecture in some models</li><li>Efficient models for edge computing and on-device AI</li><li>Fine-tuning capabilities for specific domains or tasks</li></ul><div class="kg-card kg-callout-card kg-callout-card-accent"><div class="kg-callout-emoji">&#x1F9BE;</div><div class="kg-callout-text"><b><strong style="white-space: pre-wrap;">Mistral AI use cases</strong></b></div></div><ul><li>General-purpose text generation and understanding</li><li>High-complexity reasoning and problem-solving</li><li>Code generation and understanding</li><li>Image analysis and multimodal tasks</li><li>On-device AI for smartphones and laptops</li><li>Efficient large-scale processing with MoE models</li></ul><h3 id="falcon-3">Falcon 3</h3><p><strong>Best for</strong>: resource-constrained environments</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXf1xoWpmVt4CR8s4DA5AgxLZW7MwJnl22H-C8a7TzRSvJdLHXQEjvkh-m0zOBBpC6SdVqhNfNwI6OlyNF_pZBv7zhEi7yo5kjVa4c7WKBcZk1lCnJEXaRjlJkJZQGtN6aXkOZt3mg?key=INQ3nGlG9V9oPWqw4SkZT1dt" class="kg-image" alt="The 11 best open-source LLMs for 2025" loading="lazy" width="624" height="312"><figcaption><span style="white-space: pre-wrap;">Falcon 3 models shine in the resource-constrained environments</span></figcaption></figure><p><a href="https://falconllm.tii.ae/falcon3/index.html?ref=blog.n8n.io"><u>Falcon 3</u></a> is the latest iteration of open-source large language models developed by the Technology Innovation Institute (TII) in Abu Dhabi. This family of models demonstrates impressive performance for small LLMs while democratizing access to advanced AI by enabling efficient operation on light infrastructures, including laptops.</p><div class="kg-card kg-callout-card kg-callout-card-red"><div class="kg-callout-emoji">&#x2699;&#xFE0F;</div><div class="kg-callout-text"><b><strong style="white-space: pre-wrap;">Falcon 3 key features</strong></b></div></div><ul><li>Multiple model sizes: 1B, 3B, 7B, and 10B parameters</li><li>Trained on 14 trillion tokens, more than double its predecessor</li><li>Superior reasoning and enhanced fine-tuning capabilities</li><li>Extended context windows up to 32k tokens (except 1B model with 8k)</li><li>Multilingual support (English, French, Spanish, and Portuguese)</li><li>Falcon3-Mamba-7B variant using an alternative <a href="https://thegradient.pub/mamba-explained/?ref=blog.n8n.io"><u>State Space Model (SSM) architecture</u></a></li></ul><div class="kg-card kg-callout-card kg-callout-card-accent"><div class="kg-callout-emoji">&#x1F9BE;</div><div class="kg-callout-text"><b><strong style="white-space: pre-wrap;">Falcon 3 use cases</strong></b></div></div><ul><li>General-purpose text generation and understanding</li><li>Code generation and comprehension</li><li>Mathematical and scientific tasks</li><li>Multilingual applications</li><li>Fine-tuning for specific domains or tasks</li><li>Efficient deployment in resource-constrained environments</li></ul><h3 id="gemma-2">Gemma 2</h3><p><strong>Best for</strong>: responsible AI development and deployment</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXcfdVE34X6asO7sAQzUzSdtM0FBDxw8PQaGcKEF7ruzsDNT8I2xWG7ZL67TyaJwsgK5UBquXJdLGufM6jNawGcxEqzYgGiRLTBHsgZ0npzmwEbSwyEUxbhAsrh1KiUkmDLq_75Meg?key=INQ3nGlG9V9oPWqw4SkZT1dt" class="kg-image" alt="The 11 best open-source LLMs for 2025" loading="lazy" width="624" height="277"><figcaption><span style="white-space: pre-wrap;">Gemma 2 put emphasis on responsible AI development and deployment</span></figcaption></figure><p><a href="https://ai.google.dev/gemma?ref=blog.n8n.io"><u>Gemma 2</u></a> is Google&#x2019;s latest family of open-source LLMs, built on the same research and technology used to create the Gemini models. Offering strong performance for its size, Gemma 2 is designed with a focus on responsible AI development and efficient deployment.</p><div class="kg-card kg-callout-card kg-callout-card-red"><div class="kg-callout-emoji">&#x2699;&#xFE0F;</div><div class="kg-callout-text"><b><strong style="white-space: pre-wrap;">Gemma 2 key features</strong></b></div></div><ul><li>Multiple model sizes: 2B, 9B, and 27B parameters</li><li>Exceptional performance, with the 27B model outperforming some larger proprietary models</li><li>Optimized for efficient inference across various hardware, from edge devices to cloud deployments</li><li>Built-in safety advancements and responsible AI practices</li><li>Broad framework compatibility (Keras, JAX, PyTorch, Hugging Face, etc.)</li><li>Complementary tools: ShieldGemma for content safety and Gemma Scope for model interpretability</li></ul><div class="kg-card kg-callout-card kg-callout-card-accent"><div class="kg-callout-emoji">&#x1F9BE;</div><div class="kg-callout-text"><b><strong style="white-space: pre-wrap;">Gemma 2 use cases</strong></b></div></div><ul><li>General-purpose text generation and understanding</li><li>Question answering and summarization</li><li>Code generation and understanding</li><li>Fine-tuning for specific domains or tasks</li><li>Responsible AI research and development</li><li>On-device AI applications (especially with the 2B model)</li></ul><h3 id="phi-3x-4">Phi 3.x / 4</h3><p><strong>Best for</strong>: cost-effective AI solutions</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXcx2s-pwPKAE0xEMkPK73iN1ovTRle20iGpOwPq-UbgEDNR1EcW17aAGP1aX3hZzh2zIRsAx5h5KXIuUNj4QxUbhme3yqXJWlOVBqBp3_3Hh8rbueqW7gs02-Y9WD85IyQtbmwq?key=INQ3nGlG9V9oPWqw4SkZT1dt" class="kg-image" alt="The 11 best open-source LLMs for 2025" loading="lazy" width="624" height="312"><figcaption><span style="white-space: pre-wrap;">Phi 3.x / 4 models are best for cost-effective AI solutions</span></figcaption></figure><p><a href="https://azure.microsoft.com/en-us/products/phi/?ref=blog.n8n.io"><u>Phi-3.x / 4</u></a> is Microsoft&#x2019;s family of open-source Small Language Models (SLMs), designed to be highly capable and cost-effective. Phi-3.5 updates bring enhanced multi-lingual support, improved multi-frame image understanding, and a new MoE architecture. Phi-4, the latest model, emphasizes data quality over size. It was trained on synthetic data, filtered public content, and academic resources. The model achieves impressive performance over a range of benchmarks with just 16B parameters.</p><div class="kg-card kg-callout-card kg-callout-card-red"><div class="kg-callout-emoji">&#x2699;&#xFE0F;</div><div class="kg-callout-text"><b><strong style="white-space: pre-wrap;">Phi LLM key features</strong></b></div></div><ul><li>Multiple model sizes: 3.8B (mini), 7B (small), 14B (medium), and 42B (MoE) parameters for Phi-3.x; 16B for Phi-4</li><li>Long context window support up to 128K tokens for Phi-3.x, 16K for Phi-4</li><li>Multilingual capabilities in over 20 languages</li><li>Multi-modal support with Phi-3.5-vision for image understanding</li><li>Mixture-of-Experts (MoE) architecture for improved efficiency</li><li>Optimized for <a href="https://onnxruntime.ai/docs/?ref=blog.n8n.io"><u>ONNX Runtime</u></a> and various hardware targets</li><li>Developed with Microsoft Responsible AI Standard</li></ul><div class="kg-card kg-callout-card kg-callout-card-accent"><div class="kg-callout-emoji">&#x1F9BE;</div><div class="kg-callout-text"><b><strong style="white-space: pre-wrap;">Phi LLM use cases</strong></b></div></div><ul><li>General-purpose text generation and understanding</li><li>Multilingual applications across various languages</li><li>Code understanding and generation</li><li>Mathematical reasoning and problem-solving</li><li>On-device and offline inference scenarios</li><li>Latency-sensitive applications</li><li>Cost-effective AI solutions for resource-constrained environments</li></ul><h3 id="command-r">Command R</h3><p><strong>Best for</strong>: enterprise-level conversational AI and RAG</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXdHfb4eblhnTrB7TXUtycf_HHf-DA_6Oo-5O5VT4p89NTck4W42n1nJXMmfOJfCQR_vAmV3fjfm_Jefvc0hbAuD3jREwZbYZD759Y9uTdbH3Re43rLwPgZsuRwe5tJuDd-41uMrvw?key=INQ3nGlG9V9oPWqw4SkZT1dt" class="kg-image" alt="The 11 best open-source LLMs for 2025" loading="lazy" width="624" height="312"><figcaption><span style="white-space: pre-wrap;">Command R model allows for building enterprise-level conversational AI and RAG</span></figcaption></figure><p><a href="https://cohere.com/command?ref=blog.n8n.io"><u>Command R</u></a> is Cohere&#x2019;s flagship family of LLMs for enterprise-level applications with a focus on conversational interaction and long-context tasks. The family includes Command R, Command R+, and the compact Command R7B, each optimized for different use cases.</p><div class="kg-card kg-callout-card kg-callout-card-red"><div class="kg-callout-emoji">&#x2699;&#xFE0F;</div><div class="kg-callout-text"><b><strong style="white-space: pre-wrap;">Command R key features</strong></b></div></div><ul><li>Long context window of 128k tokens</li><li>Multilingual capabilities in 10 primary languages and 13 additional languages</li><li>Tool use and multi-step reasoning for complex tasks</li><li>Customizable safety modes for responsible AI deployment</li><li>Command R7B offers on-device inference capabilities</li></ul><div class="kg-card kg-callout-card kg-callout-card-accent"><div class="kg-callout-emoji">&#x1F9BE;</div><div class="kg-callout-text"><b><strong style="white-space: pre-wrap;">Command R use cases</strong></b></div></div><ul><li>High-performance conversational AI and chatbots</li><li>Complex RAG workflows for information retrieval and synthesis</li><li>Multi-step tool use for dynamic, reasoning-based tasks</li><li>Cross-lingual applications and translations</li><li>Code generation and understanding</li><li>Financial and numerical data analysis</li><li>On-device applications (with Command R7B)</li></ul><h3 id="stablelm">StableLM</h3><p><strong>Best for</strong>: rapid prototyping and experimentation</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXd9IioEnSbEwrhM6AtqdwvzKb80PlUqYUZV8Z0k3GpZk_Wv96Ekj1A3X-JKI9lVjXjhZsiG-cDDbzPM-nr61PI-nGe-Cwi80-Eli5vqPTmNHxJmzxx5A-maiHLu6tjIEPMb7YON?key=INQ3nGlG9V9oPWqw4SkZT1dt" class="kg-image" alt="The 11 best open-source LLMs for 2025" loading="lazy" width="624" height="296"><figcaption><span style="white-space: pre-wrap;">StableLM is great for rapid prototyping and experimentation</span></figcaption></figure><p><a href="https://stability.ai/stable-lm?ref=blog.n8n.io"><u>StableLM</u></a> is Stability AI&#x2019;s series of open-source LLMs, offering competitive performance in compact sizes. The family includes various model sizes and specializations. The 1.6B model, trained on approximately 2 trillion tokens, outperforms many models under 2B parameters on various benchmarks. Stability AI provides both base and instruction-tuned versions, along with pre-training checkpoints to facilitate further fine-tuning.</p><div class="kg-card kg-callout-card kg-callout-card-red"><div class="kg-callout-emoji">&#x2699;&#xFE0F;</div><div class="kg-callout-text"><b><strong style="white-space: pre-wrap;">StableLM key features</strong></b></div></div><ul><li>Multiple model sizes: 1.6B, 3B, and 12B parameters</li><li>Multilingual capabilities in English, Spanish, German, Italian, French, Portuguese, and Dutch</li><li>Fill in Middle (FIM) capability for flexible code generation</li><li>Long context support with sequences up to 16k tokens</li><li>Optimized for speed and performance, enabling fast experimentation</li><li>Specialized versions for code generation, Japanese and Arabic languages</li></ul><div class="kg-card kg-callout-card kg-callout-card-accent"><div class="kg-callout-emoji">&#x1F9BE;</div><div class="kg-callout-text"><b><strong style="white-space: pre-wrap;">StableLM use cases</strong></b></div></div><ul><li>General-purpose text generation and understanding in multiple languages</li><li>Code generation and understanding across various programming languages</li><li>Fine-tuning for specific domains or tasks</li><li>Research and commercial applications</li></ul><h3 id="starcoder">Starcoder</h3><p><strong>Best for</strong>: code-related tasks and multi-language programming</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXdgR2Po2mCK4FYwMKCPZyiZI3VT7ODdB_0K3elfwk-pIFN02dsbM__J93SLwB3MJ_kgd0Z9BssRo4DC0YiLOEhPEG2G2YKr6Xt17app8sT8BuWBFiYYc-JVfgnBx5_muREcQbUF?key=INQ3nGlG9V9oPWqw4SkZT1dt" class="kg-image" alt="The 11 best open-source LLMs for 2025" loading="lazy" width="624" height="312"><figcaption><span style="white-space: pre-wrap;">Starcoder is best-suited for code-related tasks and multi-language programming</span></figcaption></figure><p><a href="https://github.com/bigcode-project/starcoder2?ref=blog.n8n.io"><u>StarCoder2</u></a> is the next generation of transparently trained open-source language models for code, developed by the BigCode project. It offers high performance for code-related tasks across a wide range of programming languages. The 15B model, in particular, matches the performance of much larger 33B+ models on many evaluations, while the 3B model matches the performance of the previous 15B StarCoder model, showcasing significant improvements in efficiency and capability.</p><div class="kg-card kg-callout-card kg-callout-card-red"><div class="kg-callout-emoji">&#x2699;&#xFE0F;</div><div class="kg-callout-text"><b><strong style="white-space: pre-wrap;">StarCoder2 key features</strong></b></div></div><ul><li>Multiple model sizes: 3B, 7B, and 15B parameters</li><li>Trained on 600+ programming languages (15B model)</li><li>Large context window of 16,384 tokens with sliding window attention of 4,096 tokens</li><li>Grouped Query Attention (GQA) for improved efficiency</li><li>Fill-in-the-Middle training objective</li><li>Trained on 3+ trillion tokens (3B and 7B models) to 4+ trillion tokens (15B model)</li></ul><div class="kg-card kg-callout-card kg-callout-card-accent"><div class="kg-callout-emoji">&#x1F9BE;</div><div class="kg-callout-text"><b><strong style="white-space: pre-wrap;">StarCoder2 use cases</strong></b></div></div><ul><li>Code completion and generation across multiple programming languages</li><li>Code understanding and analysis</li><li>Fine-tuning for specific programming tasks or languages</li><li>Assisting developers in various coding scenarios</li><li>Research in code language models and AI for programming</li></ul><h3 id="yi">Yi</h3><p><strong>Best for</strong>: bilingual applications (English and Chinese)</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXd90ameeVcaYVB8AZsRbu-B0GCZdxQG8_wKMxXhQ7gcM8S4k3Nvvq6HiOz39GgxUsLt8O_ucBXUxRuefoucxUhMYGyTYtopU_vRq99uoBTLJBiGanNHaiRXZHZhRBA1WIaCnUjUoA?key=INQ3nGlG9V9oPWqw4SkZT1dt" class="kg-image" alt="The 11 best open-source LLMs for 2025" loading="lazy" width="624" height="312"><figcaption><span style="white-space: pre-wrap;">Yi LLM is great for bilingual applications (English and Chinese)</span></figcaption></figure><p><a href="https://huggingface.co/01-ai?ref=blog.n8n.io"><u>Yi is a series of open-source LLMs</u></a> developed by 01.AI, offering strong performance in both English and Chinese across a wide range of tasks. The Yi-1.5 series, an upgraded version of the original Yi models, delivers enhanced capabilities in coding, math, reasoning, and instruction-following.</p><div class="kg-card kg-callout-card kg-callout-card-red"><div class="kg-callout-emoji">&#x2699;&#xFE0F;</div><div class="kg-callout-text"><b><strong style="white-space: pre-wrap;">Yi key features</strong></b></div></div><ul><li>Multiple model sizes: 6B, 9B, and 34B parameters</li><li>Bilingual support for English and Chinese</li><li>Extended context windows up to 200k tokens for larger models</li><li>Continuous pre-training on high-quality corpus (500B tokens for Yi-1.5)</li><li>Fine-tuned on 3M diverse samples for improved instruction-following</li><li>Optimized for efficient deployment and fine-tuning</li></ul><div class="kg-card kg-callout-card kg-callout-card-accent"><div class="kg-callout-emoji">&#x1F9BE;</div><div class="kg-callout-text"><b><strong style="white-space: pre-wrap;">Yi use cases</strong></b></div></div><ul><li>Bilingual text generation and understanding</li><li>Code generation and comprehension</li><li>Mathematical problem-solving and reasoning tasks</li><li>Fine-tuning for domain-specific applications</li><li>Natural language processing in academic and commercial settings</li><li>Building chatbots and AI assistants</li></ul><h3 id="qwen25">Qwen2.5</h3><p><strong>Best for</strong>: multilingual and specialized tasks (coding and math)</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXdAM8Foi5i6zjGDAz9xWqkrM5FfulQIrrFh3DIP1mWE_XvomYoQSqom-UElQ76ofl-g_YAmUMt3KzMCPlTdgWuBlBNAPU4yA7D0qZOlcHvGHQDsa4l7wYSdG7bKI6LSSOk-hekuXA?key=INQ3nGlG9V9oPWqw4SkZT1dt" class="kg-image" alt="The 11 best open-source LLMs for 2025" loading="lazy" width="624" height="243"><figcaption><span style="white-space: pre-wrap;">Qwen2.5 works great for multilingual and specialized tasks (coding and math)</span></figcaption></figure><p><a href="https://qwenlm.github.io/blog/qwen2.5-coder-family/?ref=blog.n8n.io"><u>Qwen2.5</u></a> is Alibaba&#x2019;s latest series of open-source LLMs with a wide range of sizes and specialized variants for coding and mathematics. These models represent a significant advancement in multilingual capabilities and task-specific performance.</p><div class="kg-card kg-callout-card kg-callout-card-red"><div class="kg-callout-emoji">&#x2699;&#xFE0F;</div><div class="kg-callout-text"><b><strong style="white-space: pre-wrap;">Qwen2.5 key features</strong></b></div></div><ul><li>Multiple model sizes: 0.5B, 1.5B, 3B, 7B, 14B, 32B, and 72B parameters</li><li>Pretrained on up to 18 trillion tokens</li><li>128K token context window with generation up to 8K tokens</li><li>Multilingual support for over 29 languages</li><li>Specialized models: Qwen2.5-Coder and Qwen2.5-Math</li><li>Improved instruction following and structured data understanding</li><li>Enhanced JSON output generation</li></ul><div class="kg-card kg-callout-card kg-callout-card-accent"><div class="kg-callout-emoji">&#x1F9BE;</div><div class="kg-callout-text"><b><strong style="white-space: pre-wrap;">Qwen2.5 use cases</strong></b></div></div><ul><li>General-purpose text generation and understanding</li><li>Multilingual applications across various languages</li><li>Code generation and understanding with Qwen2.5-Coder</li><li>Mathematical reasoning and problem-solving with Qwen2.5-Math</li><li>Long-form content creation and analysis</li><li>Structured data processing and JSON output generation</li><li>Chatbot development with improved role-play capabilities</li></ul><h3 id="deepseek-2x-3">Deepseek 2.x / 3</h3><p><strong>Best for</strong>: efficient large-scale language processing</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXeMOB661VVWKZBwVvPhX8liuKnDy1tAjBZOiBXydNRDzGEs-pBAZDt3EVMDjnk-Y2J7RuwmDDiz6w2nyUUo8WB6vHif36vnyOOjNdBaqqjiRZTTnx5Up59wgMGuvVuN6VwPozP0Tg?key=INQ3nGlG9V9oPWqw4SkZT1dt" class="kg-image" alt="The 11 best open-source LLMs for 2025" loading="lazy" width="624" height="208"><figcaption><span style="white-space: pre-wrap;">Deepseek 2.x / 3 is a top LLM for efficient large-scale language processing</span></figcaption></figure><p><a href="https://www.deepseek.com/?ref=blog.n8n.io"><u>DeepSeek</u></a> is a series of powerful open-source LLMs developed by DeepSeek AI, featuring innovative architectures for efficient inference and cost-effective training. The DeepSeek-V2 and V2.5 models are available for use with Ollama. While the recently released DeepSeek-V3 offers even more impressive capabilities with its 671B parameters, it is not yet available in Ollama at the moment of writing.</p><div class="kg-card kg-callout-card kg-callout-card-red"><div class="kg-callout-emoji">&#x2699;&#xFE0F;</div><div class="kg-callout-text"><b><strong style="white-space: pre-wrap;">DeepSeek key features</strong></b></div></div><ul><li>Mixture-of-Experts (MoE) architecture for efficient parameter usage</li><li>Multi-head Latent Attention (MLA) for improved inference efficiency</li><li>Large context windows of up to 128k tokens</li><li>Multilingual capabilities, with strong performance in English and Chinese</li><li>Optimized for both general text generation and coding tasks</li></ul><div class="kg-card kg-callout-card kg-callout-card-accent"><div class="kg-callout-emoji">&#x1F9BE;</div><div class="kg-callout-text"><b><strong style="white-space: pre-wrap;">DeepSeek use cases</strong></b></div></div><ul><li>General-purpose text generation and understanding</li><li>Multilingual applications and translations</li><li>Code generation and understanding</li><li>Fine-tuning for specific domains or tasks</li><li>Assistant-like interactions in chatbots and AI applications</li><li>Long-form content creation and analysis</li></ul><h2 id="getting-started-with-langchain-and-open-source-llms-in-n8n">Getting started with LangChain and open-source LLMs in n8n</h2><p>If running an open-source LLM seems too complicated, we&#x2019;ve got great news: in n8n you can jump-start with Ollama. This powerful integration allows you to connect local models to real-world workflows and automate tasks in a meaningful way.</p><p>By combining the flexibility of open-source LLMs with the automation capabilities of n8n, you can build custom AI applications that are both powerful and efficient. LangChain (JavaScript version) is the main framework for building AI agents and LLM-powered workflows in n8n. The possibilities for customization and innovation are virtually limitless &#x2013; use hundreds of pre-built nodes or write custom JS scripts.</p><p>Let&#x2019;s explore how n8n makes creating custom LLM-powered apps and workflows easy!</p><p>There are at least 3 easy ways to build projects with open-source LLMs with n8n LangChain nodes:</p><ol><li>Run small Hugging Face models with a <a href="https://huggingface.co/docs/hub/security-tokens?ref=blog.n8n.io"><u>User Access Token</u></a> completely for free.</li><li>If you want to run larger models or need a quick response, try the Hugging Face service called <a href="https://huggingface.co/inference-endpoints?ref=blog.n8n.io"><u>Custom Inference Endpoints</u></a>.</li><li>If you have enough computing resources, run the model via <a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmollama?ref=blog.n8n.io"><u>Ollama</u></a> locally or self-hosted.</li></ol><p><a href="https://docs.n8n.io/hosting/starter-kits/ai-starter-kit/?ref=blog.n8n.io"><u>LangChain nodes in n8n + Ollama integration</u></a> make it easier to access open-source LLMs and give you handy tools for working with them. Here&#x2019;s a video with an overview of the most important aspects:</p><figure class="kg-card kg-embed-card"><iframe width="200" height="113" src="https://www.youtube.com/embed/xz_X2N-hPg0?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen title="Installing and Using Local AI for n8n"></iframe></figure><p>After you&#x2019;ve installed the self-hosted AI Starter Kit, it&#x2019;s time for a practical part!</p><p>Here is a workflow template that is particularly useful for enterprise environments where data privacy is crucial. It allows for on-premises processing of personal information.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://blog.n8n.io/content/images/2025/01/WK-Data-ext2-1.png" class="kg-image" alt="The 11 best open-source LLMs for 2025" loading="lazy" width="966" height="726" srcset="https://blog.n8n.io/content/images/size/w600/2025/01/WK-Data-ext2-1.png 600w, https://blog.n8n.io/content/images/2025/01/WK-Data-ext2-1.png 966w" sizes="(min-width: 720px) 720px"><figcaption><span style="white-space: pre-wrap;">This workflow takes an input and extracts user information in a consistent JSON format</span></figcaption></figure>
<!--kg-card-begin: html-->
<script>
  workflowBanner(2766, document.currentScript);
</script>
<!--kg-card-end: html-->
<h3 id="step-1-configure-the-basic-llm-chain-node">Step 1: Configure the Basic LLM Chain node</h3><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXdhMUK2iNl9WeDN06C2gN4ok2boEvaAAGnWx2KMEIpoa2Co6HhsaKWIfpHMHGh-BjjR0FR1Us38mdUSx9sW2ALlbq0YAVpxWxtC8GZJ3EI50ttS0pbVpTiVje5zwxhZzcFwr8Xi?key=INQ3nGlG9V9oPWqw4SkZT1dt" class="kg-image" alt="The 11 best open-source LLMs for 2025" loading="lazy" width="624" height="427"><figcaption><span style="white-space: pre-wrap;">Provide a system prompt and make sure a user message is coming for the correct input</span></figcaption></figure><p>The core of the workflow is the <a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.chainllm/?ref=blog.n8n.io"><u>Basic LLM Chain node</u></a>. Configure it as follows:</p><ul>
<li>Activate the Require Specific Output Format toggle;</li>
<li>In the Messages section, add a system message with the following content:<code>Please analyse the incoming user request. Extract information according to the JSON schema. Today is: {{ $now.toISO() }}</code>This is the main prompt with the general task.</li>
</ul>
<h3 id="step-2-add-the-chat-trigger-node">Step 2: Add the Chat Trigger node</h3><p>For this example, we&#x2019;re using a <a href="https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-langchain.chattrigger/?ref=blog.n8n.io"><u>Chat Trigger</u></a> to simulate user input.</p><p>&#x1F4A1; In a real-world scenario, this could be replaced with various data sources such as database queries, voice transcripts, or incoming Webhook data.</p><h3 id="step-3-configure-the-ollama-chat-model-node">Step 3: Configure the Ollama Chat Model node</h3><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXe_9JkZcwIFJmGTUNh6PWO1GrLrqdAVhV6FQ44st0A4lgKa4Rd7fGiIi70ZFOJN4zEG4OtOCVQrgzmeBSYDOkckKYLZt2voymt_FpVlMDBsWi9PJ_yZgydacH1iJez7Z03MkHRrYg?key=INQ3nGlG9V9oPWqw4SkZT1dt" class="kg-image" alt="The 11 best open-source LLMs for 2025" loading="lazy" width="624" height="388"><figcaption><span style="white-space: pre-wrap;">Ollama provides several additional settings that are specific to self-hosted LLMs</span></figcaption></figure><p>Connect the <a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatollama/?ref=blog.n8n.io"><u>Ollama Chat Model</u></a> node to provide the language model capabilities:</p><ul>
<li>Set the model to <code>mistral-nemo:latest</code></li>
<li>Set temperature to <code>0.1</code> for more consistent outputs</li>
<li>Set keep Alive setting to <code>2h</code> to maintain the model in memory</li>
<li>Enable the Use Memory Locking toggle for improved performance</li>
</ul>
<h3 id="step-4-ensure-consistent-structured-output">Step 4: Ensure consistent structured output</h3><ol><li>Add an <a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.outputparserautofixing/?ref=blog.n8n.io"><u>Auto-fixing Output Parser node</u></a> and connect it to the same Ollama Chat Model.</li></ol><p>Add a <a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.outputparserstructured/?ref=blog.n8n.io"><u>Structured Output Parser node</u></a> with the following JSON schema:</p><pre><code>{
  &quot;type&quot;: &quot;object&quot;,
  &quot;properties&quot;: {
    &quot;name&quot;: {
      &quot;type&quot;: &quot;string&quot;,
      &quot;description&quot;: &quot;Name of the user&quot;
    },
    &quot;surname&quot;: {
      &quot;type&quot;: &quot;string&quot;,
      &quot;description&quot;: &quot;Surname of the user&quot;
    },
    &quot;commtype&quot;: {
      &quot;type&quot;: &quot;string&quot;,
      &quot;enum&quot;: [&quot;email&quot;, &quot;phone&quot;, &quot;other&quot;],
      &quot;description&quot;: &quot;Method of communication&quot;
    },
    &quot;contacts&quot;: {
      &quot;type&quot;: &quot;string&quot;,
      &quot;description&quot;: &quot;Contact details. ONLY IF PROVIDED&quot;
    },
    &quot;timestamp&quot;: {
      &quot;type&quot;: &quot;string&quot;,
      &quot;format&quot;: &quot;date-time&quot;,
      &quot;description&quot;: &quot;When the communication occurred&quot;
    },
    &quot;subject&quot;: {
      &quot;type&quot;: &quot;string&quot;,
      &quot;description&quot;: &quot;Brief description of the communication topic&quot;
    }
  },
  &quot;required&quot;: [&quot;name&quot;, &quot;communicationType&quot;]
}

</code></pre><p>This JSON schema defines several JSON keys to collect various data like name, surname, communication method, user contacts, topic and the timestamp. However, only the name and the communication method are mandatory parameters. You can adjust the schema according to your needs.</p><h3 id="step-5-process-the-output">Step 5: Process the output</h3><figure class="kg-card kg-image-card kg-width-wide kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfyOgsB5H6zjCeBegEW54Q00X8atspKeS7AEDxNtxIVTqLOFzKHGqChQ3O6qROpyTEswefxFXBAz-mGhmr8tpx-IGXIz5OGiWJrHdnTPvVSByBp6oEtIk-he8aFN3vjMEdUGxTPRQ?key=INQ3nGlG9V9oPWqw4SkZT1dt" class="kg-image" alt="The 11 best open-source LLMs for 2025" loading="lazy" width="624" height="171"><figcaption><span style="white-space: pre-wrap;">As an optional step, transform the Basic LLM Chain output</span></figcaption></figure><p>After the Basic LLM Chain node processes the request, it will produce a JSON with an output key. Transform this output using a Set node:</p><p>Set the Mode to <code>JSON</code><br>
Use the following expression: <code>{{ $json.output }}</code></p>
<p>Adding a Set node is optional, which we did just for convenience.</p><h3 id="step-6-handle-errors">Step 6: Handle errors</h3><p>Add a <a href="https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.noop/?ref=blog.n8n.io"><u>No Operation node</u></a> after the Error output from the Basic LLM Chain node. This serves as an intermediary step before further error processing.</p><p>That&#x2019;s it! Now you&#x2019;re done and can test the workflow. Press the Chat button in the bottom middle part of your instance and provide a text message. For example:</p><p><code>Hi, my name is John. I&apos;d like to be contacted via E-mail at john.smith@example.com regarding my recent order #12345.</code></p>
<p>You can easily adapt this template to various enterprise use cases by modifying the input source, output schema or post-processing steps.</p><p>If you have a specific storage system where you&#x2019;d like to save the result, consider switching the Basic LLM Chain node to a <a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.agent/tools-agent/?ref=blog.n8n.io"><u>Tools Agent node</u></a>. Modern LLMs have <a href="https://docs.mistral.ai/capabilities/function_calling/?ref=blog.n8n.io"><u>built-in capabilities for function calling</u></a>, so you can define the desired output format which can immediately connect to a database and upload the parsed information.</p><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text">Additionally, special <a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.code?ref=blog.n8n.io"><u>LangChain Code</u></a> and <a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.toolcode?ref=blog.n8n.io"><u>Code Tool</u></a> nodes allow you to create completely custom chains. You can build whatever is supported by the LangChainJS library, even if a ready-made node is not yet available.</div></div><h2 id="faqs">FAQs&#xA0;</h2><div class="kg-card kg-toggle-card" data-kg-toggle-state="close">
            <div class="kg-toggle-heading">
                <h4 class="kg-toggle-heading-text"><span style="white-space: pre-wrap;">Which types of open-source LLMs are there?</span></h4>
                <button class="kg-toggle-card-icon" aria-label="Expand toggle to read content">
                    <svg id="Regular" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                        <path class="cls-1" d="M23.25,7.311,12.53,18.03a.749.749,0,0,1-1.06,0L.75,7.311"/>
                    </svg>
                </button>
            </div>
            <div class="kg-toggle-content"><p><span style="white-space: pre-wrap;">Open-source models fall into two main categories:</span></p><ul><li value="1"><b><strong style="white-space: pre-wrap;">Pre-trained LLMs </strong></b><span style="white-space: pre-wrap;">are created using vast amounts of text data. These models excel at understanding broad contexts and generating coherent text. While valuable for research and general language tasks, they may struggle with specific instructions or specialized applications.</span></li><li value="2"><b><strong style="white-space: pre-wrap;">Fine-tuned LLMs </strong></b><span style="white-space: pre-wrap;">are adapted from pre-trained models. They undergo additional training on targeted datasets, making them more effective for particular use cases like classification, summarization, or question-answering. Fine-tuned models are essential for modern applications such as turn-based chat messaging and function calling.</span></li></ul><p><span style="white-space: pre-wrap;">Note that some authors distinguish fine-tuning from</span><a href="https://medium.com/@eordaxd/fine-tuning-vs-pre-training-651d05186faf?ref=blog.n8n.io"> <u><span class="underline" style="white-space: pre-wrap;">continuous pre-training</span></u></a><span style="white-space: pre-wrap;">. The latter involves further pre-training a model with domain-specific data, such as medical or financial reports, to adapt it to a particular field.</span></p></div>
        </div><div class="kg-card kg-toggle-card" data-kg-toggle-state="close">
            <div class="kg-toggle-heading">
                <h4 class="kg-toggle-heading-text"><span style="white-space: pre-wrap;">How to get started with an open-source LLM?</span></h4>
                <button class="kg-toggle-card-icon" aria-label="Expand toggle to read content">
                    <svg id="Regular" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                        <path class="cls-1" d="M23.25,7.311,12.53,18.03a.749.749,0,0,1-1.06,0L.75,7.311"/>
                    </svg>
                </button>
            </div>
            <div class="kg-toggle-content"><p><span style="white-space: pre-wrap;">There are two main approaches to setting up and using open-source LLMs:</span></p><ol><li value="1"><b><strong style="white-space: pre-wrap;">Install locally</strong></b><span style="white-space: pre-wrap;">. Helper tools such as Ollama simplify the process. However, the larger the model, the more difficult it is to meet the hardware requirements. The largest models require industrial-level equipment.</span></li><li value="2"><span style="white-space: pre-wrap;">Instead of hosting everything locally, it&#x2019;s also possible to </span><b><strong style="white-space: pre-wrap;">rent a virtual server. </strong></b></li></ol><p><b><strong style="white-space: pre-wrap;">VPS with a GPU</strong></b><span style="white-space: pre-wrap;"> allows for faster inference, but is more expensive. Several hosting providers have automated the process of model installation and deployment, so the entire setup requires just a few clicks and some waiting time.</span></p><p><b><strong style="white-space: pre-wrap;">Traditional CPU-only virtual servers</strong></b><span style="white-space: pre-wrap;"> could be a more cost-efficient alternative, especially when deploying smaller language models without strict requirements on response time.</span></p></div>
        </div><div class="kg-card kg-toggle-card" data-kg-toggle-state="close">
            <div class="kg-toggle-heading">
                <h4 class="kg-toggle-heading-text"><span style="white-space: pre-wrap;">How to run open-source LLM locally?</span></h4>
                <button class="kg-toggle-card-icon" aria-label="Expand toggle to read content">
                    <svg id="Regular" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                        <path class="cls-1" d="M23.25,7.311,12.53,18.03a.749.749,0,0,1-1.06,0L.75,7.311"/>
                    </svg>
                </button>
            </div>
            <div class="kg-toggle-content"><p><span style="white-space: pre-wrap;">There are several ways to run LLMs locally. The easiest approach is to use one of the available frameworks, which can get you up and running in just a few clicks:</span></p><ul><li value="1"><b><strong style="white-space: pre-wrap;">Ollama + OpenWebUI</strong></b><span style="white-space: pre-wrap;">: Ollama as a backend for quick LLM deployment, OpenWebUI as a user-friendly frontend</span></li><li value="2"><b><strong style="white-space: pre-wrap;">GPT4All</strong></b><span style="white-space: pre-wrap;">: General-purpose AI applications and document chat</span></li><li value="3"><b><strong style="white-space: pre-wrap;">LM Studio</strong></b><span style="white-space: pre-wrap;">: LLM customization and fine-tuning</span></li><li value="4"><b><strong style="white-space: pre-wrap;">Jan</strong></b><span style="white-space: pre-wrap;">: Privacy-focused LLM interactions with flexible server options</span></li><li value="5"><b><strong style="white-space: pre-wrap;">NextChat</strong></b><span style="white-space: pre-wrap;">: Building conversational AI with support for various LLMs</span></li></ul></div>
        </div><div class="kg-card kg-toggle-card" data-kg-toggle-state="close">
            <div class="kg-toggle-heading">
                <h4 class="kg-toggle-heading-text"><span style="white-space: pre-wrap;">How much RAM do I need to run an LLM?</span></h4>
                <button class="kg-toggle-card-icon" aria-label="Expand toggle to read content">
                    <svg id="Regular" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                        <path class="cls-1" d="M23.25,7.311,12.53,18.03a.749.749,0,0,1-1.06,0L.75,7.311"/>
                    </svg>
                </button>
            </div>
            <div class="kg-toggle-content"><p><span style="white-space: pre-wrap;">To work, most LLMs have to be loaded into memory (RAM or GPU VRAM). How much memory you need depends on multiple factors (model size, quantization, etc.) as well as specific use-cases (for example, simple inference vs fine-tuning).</span></p><p><span style="white-space: pre-wrap;">Thanks to recent advances, some efficient small language models (SLMs) can run simple tasks on systems with just 4 GB of free RAM. During fine-tuning, however, the requirements increase, because you need to store intermediate steps while model parameter values are updated.</span></p><p><span style="white-space: pre-wrap;">To check specific hardware requirements for an open-source LLM, look up its model card on Hugging Face, GitHub, or the developer&apos;s website. For quick estimates, you can use the</span><a href="https://huggingface.co/spaces/Vokturz/can-it-run-llm?ref=blog.n8n.io"> <u><span class="underline" style="white-space: pre-wrap;">&quot;Can you run it?&quot; tool for LLMs</span></u></a><span style="white-space: pre-wrap;">.</span></p></div>
        </div><div class="kg-card kg-toggle-card" data-kg-toggle-state="close">
            <div class="kg-toggle-heading">
                <h4 class="kg-toggle-heading-text"><span style="white-space: pre-wrap;">How much does it cost to run an open-source LLM?</span></h4>
                <button class="kg-toggle-card-icon" aria-label="Expand toggle to read content">
                    <svg id="Regular" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                        <path class="cls-1" d="M23.25,7.311,12.53,18.03a.749.749,0,0,1-1.06,0L.75,7.311"/>
                    </svg>
                </button>
            </div>
            <div class="kg-toggle-content"><p><span style="white-space: pre-wrap;">While open-source models are free to use, the deployment and infrastructure costs vary. The main cost when running open-source LLMs is hardware. Here&#x2019;s a concise breakdown of costs depending on different deployment options:</span></p><ul><li value="1"><span style="white-space: pre-wrap;">Locally: free if your computer meets system requirements</span></li><li value="2"><span style="white-space: pre-wrap;">Managed API providers: free limited options or fees comparable to popular services like OpenAI / Anthropic</span></li><li value="3"><span style="white-space: pre-wrap;">Simple VPS: starting from $20/mo for CPU-only servers; GPU server prices are higher, up to dozens of dollars per hour</span></li><li value="4"><span style="white-space: pre-wrap;">Managed options with one-click install on GPU servers: premium pricing</span></li></ul></div>
        </div><div class="kg-card kg-toggle-card" data-kg-toggle-state="close">
            <div class="kg-toggle-heading">
                <h4 class="kg-toggle-heading-text"><span style="white-space: pre-wrap;">Are open-source LLMs secure?</span></h4>
                <button class="kg-toggle-card-icon" aria-label="Expand toggle to read content">
                    <svg id="Regular" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                        <path class="cls-1" d="M23.25,7.311,12.53,18.03a.749.749,0,0,1-1.06,0L.75,7.311"/>
                    </svg>
                </button>
            </div>
            <div class="kg-toggle-content"><p><span style="white-space: pre-wrap;">Open-source LLMs offer transparency but also present certain security challenges:</span></p><ol><li value="1"><span style="white-space: pre-wrap;">Potential vulnerabilities: the publicly available model weights and architecture can attract both collaborators and potential attackers.</span></li><li value="2"><span style="white-space: pre-wrap;">Adversarial attacks: methods like data poisoning, prompt injection, and model evasion can alter input data to produce incorrect or unintended results.</span></li><li value="3"><span style="white-space: pre-wrap;">Wider attack surface: as open-source LLMs are integrated into more applications and platforms, the potential for attacks increases.</span></li></ol><p><span style="white-space: pre-wrap;">While the open-source community actively works on improving LLM security, users should implement additional safeguards. We recommend gating open-source LLMs during prototyping and rollout, making them accessible only through internal services (e.g. via n8n rather than directly by users).</span></p></div>
        </div><div class="kg-card kg-toggle-card" data-kg-toggle-state="close">
            <div class="kg-toggle-heading">
                <h4 class="kg-toggle-heading-text"><span style="white-space: pre-wrap;">Why to use open-source LLMs commercially?</span></h4>
                <button class="kg-toggle-card-icon" aria-label="Expand toggle to read content">
                    <svg id="Regular" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                        <path class="cls-1" d="M23.25,7.311,12.53,18.03a.749.749,0,0,1-1.06,0L.75,7.311"/>
                    </svg>
                </button>
            </div>
            <div class="kg-toggle-content"><p><span style="white-space: pre-wrap;">We&#x2019;ve gathered insights from real-world users on </span><a href="https://www.reddit.com/r/LocalLLaMA/comments/1cub6sg/who_is_using_opensource_llms_commercially/?ref=blog.n8n.io"><u><span class="underline" style="white-space: pre-wrap;">Reddit</span></u></a><span style="white-space: pre-wrap;"> to understand why businesses choose open-source LLMs. Here are the key reasons:</span></p><ol><li value="1"><b><strong style="white-space: pre-wrap;">Efficient for simple tasks</strong></b><span style="white-space: pre-wrap;">: smaller open-source models can handle basic text generation, classification, and function calling effectively.</span></li><li value="2"><b><strong style="white-space: pre-wrap;">Data privacy</strong></b><span style="white-space: pre-wrap;">: ideal for processing sensitive documents without relying on external cloud services.</span></li><li value="3"><b><strong style="white-space: pre-wrap;">Integration with existing infrastructure</strong></b><span style="white-space: pre-wrap;">: easy to incorporate if you&#x2019;re already running ML models on your own GPUs.</span></li><li value="4"><b><strong style="white-space: pre-wrap;">Cost-effective for high volumes</strong></b><span style="white-space: pre-wrap;">: fine-tuning smaller open-source models can offer a better price-performance ratio for large-scale operations.</span></li><li value="5"><b><strong style="white-space: pre-wrap;">Customization</strong></b><span style="white-space: pre-wrap;">: allows setting your own guidelines to align with company policies and ethical standards.</span></li><li value="6"><b><strong style="white-space: pre-wrap;">Transparency</strong></b><span style="white-space: pre-wrap;">: offers the ability to review training data and understand the model&#x2019;s architecture.</span></li><li value="7"><b><strong style="white-space: pre-wrap;">Control over costs</strong></b><span style="white-space: pre-wrap;">: prototyping with open-source models helps manage expenses before committing to specific providers.ntv </span></li></ol></div>
        </div><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text">For a detailed guide on these frameworks and how to use them, check out a <a href="https://blog.n8n.io/local-llm/"><u>comprehensive guide on running local LLMs</u></a>.</div></div><h2 id="wrap-up">Wrap Up</h2><p>In this article, we&apos;ve highlighted that the best open-source LLM depends on your specific use case, as models like Llama3, Mistral, and Falcon 3 excel in different areas such as speed, accuracy, or resource efficiency. We emphasized evaluating models based on factors like task requirements, deployment setup, and available resources.</p><p>Additionally, we explained how <a href="https://n8n.io/ai/?ref=blog.n8n.io" rel="noreferrer">tools like n8n</a> and LangChain simplify integrating these LLMs into workflows, making it easier to experiment and find the right fit.</p>
<!--kg-card-begin: html-->
<div class="content-banner">
  <div>
    <h3>Create your own LLM workflows</h3>
    <p>Build complex automations 10x faster, without fighting APIs</p>
  </div>
  <a href="https://app.n8n.cloud/register?ref=blog.n8n.io" class="global-button blog-banner-signup">Try n8n now</a>
</div>
<!--kg-card-end: html-->
<h2 id="what%E2%80%99s-next">What&#x2019;s next?</h2><p>Now that you&#x2019;ve got a grasp on using open-source LLMs with n8n, you can explore more advanced AI-powered automation scenarios. Many of the concepts we&#x2019;ve covered in our other AI-related articles can be applied to local models as well.</p><p>Here are some resources to continue your journey:</p><ul><li>Learn about <a href="https://blog.n8n.io/ai-workflow-automation/"><u>AI workflow automation trends</u></a>;</li><li>Create intelligent workflows with <a href="https://blog.n8n.io/ai-agentic-workflows/"><u>AI agents in n8n automation</u></a>;</li></ul><p>Build your own <a href="https://blog.n8n.io/telegram-bots/"><u>AI chatbot using n8n and Telegram</u></a>.</p>
<!--kg-card-begin: html-->
<script>
  workflowBanner([2729, 2384, 1980], document.currentScript);
</script>
<!--kg-card-end: html-->
]]></content:encoded></item><item><title><![CDATA[2024 in Review]]></title><description><![CDATA[As we dive into 2025, we're taking a moment to reflect on our achievements throughout 2024. We've grown a lot as a team, as a global community, and as a product, and we've done more than we can possibly share in one blogpost. Weâ€™ll try though! Here's an overview of our highlights.]]></description><link>https://blog.n8n.io/2024-in-review/</link><guid isPermaLink="false">678e6e792174c200018c30ff</guid><category><![CDATA[News]]></category><dc:creator><![CDATA[Bart Veldhuizen]]></dc:creator><pubDate>Tue, 21 Jan 2025 12:32:38 GMT</pubDate><media:content url="https://blog.n8n.io/content/images/2025/01/2024-review-v2.png" medium="image"/><content:encoded><![CDATA[<h3 id="building-an-amazing-team">Building an amazing team</h3><figure class="kg-card kg-image-card"><img src="https://blog.n8n.io/content/images/2025/01/n8n-Tuscany-IRL.png" class="kg-image" alt="2024 in Review" loading="lazy" width="1280" height="1280" srcset="https://blog.n8n.io/content/images/size/w600/2025/01/n8n-Tuscany-IRL.png 600w, https://blog.n8n.io/content/images/size/w1000/2025/01/n8n-Tuscany-IRL.png 1000w, https://blog.n8n.io/content/images/2025/01/n8n-Tuscany-IRL.png 1280w" sizes="(min-width: 720px) 720px"></figure><img src="https://blog.n8n.io/content/images/2025/01/2024-review-v2.png" alt="2024 in Review"><p>At n8n we put a <strong>lot</strong> of effort into building a great team with a great culture. And as we grew from 37 to 71 team members, the team spirit and the love for n8n remained intact. One of the &#x2018;team culture&#x2019; things we love doing is getting the entire company together twice a year. This year, we met in Berlin and Tuscany for three days of strategising and team building.</p><figure class="kg-card kg-image-card"><img src="https://blog.n8n.io/content/images/2025/01/Team-growth.jpg" class="kg-image" alt="2024 in Review" loading="lazy" width="701" height="145" srcset="https://blog.n8n.io/content/images/size/w600/2025/01/Team-growth.jpg 600w, https://blog.n8n.io/content/images/2025/01/Team-growth.jpg 701w"></figure><p>2025 will be another year of strong team growth. Do you think n8n is the right place for you? Join us &#x2013; <a href="https://n8n.io/careers?ref=blog.n8n.io">We&#x2019;re hiring</a>!</p><h3 id="empowering-automation-with-ai">Empowering automation with AI</h3><p>AI took center stage in our 2024 product development. The marriage of n8n&apos;s &apos;traditional&apos; workflow automation tools with LLMs, Vector Stores, Agents, and Tools has proven to be extremely successful, unlocking powerful automations with relative ease.</p><p>We rolled out a wide range of new AI features that make workflows smarter, faster, and more efficient:</p><ul><li><strong>Chat Trigger</strong>: Improved canvas chat and far better logging, allowing for more insight into the information flow between components.</li><li><strong>New AI Models</strong>: Expanded support to include Claude, Gemini, Groq, and Vertex models, giving users greater flexibility.</li><li><strong>External Vector Stores</strong>: Integration with more external vector stores opened new possibilities for working with large datasets.</li><li><strong>AI Nodes</strong>: New tools like the AI Transform Node and AI App Tools made it easier to process, generate, and analyze data.</li><li><strong>AI Agents</strong>: AI Agents enabled workflows to operate autonomously, taking automation to the next level.</li></ul><p>We also launched the <a href="https://docs.n8n.io/hosting/starter-kits/ai-starter-kit/?ref=blog.n8n.io">Self-Hosted AI Starter Kit</a>, allowing teams to run their AI workflows and LLMs on their own infrastructure and to keep their data private.</p><p>Curious to learn more? <a href="https://www.youtube.com/watch?v=yzvLfHb0nqE&amp;ref=blog.n8n.io">Check out this new video series by our DevRel Max</a> where he dives into every aspect of AI in n8n.</p><figure class="kg-card kg-image-card"><img src="https://blog.n8n.io/content/images/2025/01/YouTube---Building-AI-Agents-with-Max.png" class="kg-image" alt="2024 in Review" loading="lazy" width="1280" height="720" srcset="https://blog.n8n.io/content/images/size/w600/2025/01/YouTube---Building-AI-Agents-with-Max.png 600w, https://blog.n8n.io/content/images/size/w1000/2025/01/YouTube---Building-AI-Agents-with-Max.png 1000w, https://blog.n8n.io/content/images/2025/01/YouTube---Building-AI-Agents-with-Max.png 1280w" sizes="(min-width: 720px) 720px"></figure><h3 id="creating-a-smoother-more-powerful-platform">Creating a smoother, more powerful platform</h3><p>We made many improvements to the n8n platform. Some are obvious, but others are harder to spot, and ensure n8n remains a powerful and performant tool in 2025 and beyond:</p><ul><li><strong>Overhauled Expression Editor</strong>: The revamped editor, paired with new <a href="https://docs.n8n.io/release-notes/?ref=blog.n8n.io#new-data-transformation-functions">data transformation functions</a>, simplifies complex data manipulations. We added context-aware code completion to make it much easier to get started with expressions.</li><li><strong>Dark Mode + Dark Nodes</strong>: A long-awaited visual update that removes the need for wearing sunglasses during your nightly n8n sessions.</li><li><strong>New Canvas:</strong> Our new, more performant canvas is almost out of beta! We redid the entire implementation to make it easier to work with large workflows and large datasets (stay tuned for more!).</li><li><strong>Task Runners for Code Node:</strong> Also still in beta, Task Runners will add up to a 6x performance boost to your Javascript Code Nodes!</li></ul><figure class="kg-card kg-image-card"><img src="https://blog.n8n.io/content/images/2025/01/Pull-request-2.jpg" class="kg-image" alt="2024 in Review" loading="lazy" width="700" height="145" srcset="https://blog.n8n.io/content/images/size/w600/2025/01/Pull-request-2.jpg 600w, https://blog.n8n.io/content/images/2025/01/Pull-request-2.jpg 700w"></figure><h3 id="adding-more-power-with-more-nodes">Adding more power with more nodes</h3><p>2024 also saw the addition of <strong>tons of new nodes</strong> to extend n8n&#x2019;s capabilities and integrate with even more tools.</p><p>One stand-out addition is the new <a href="https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.formtrigger/?ref=blog.n8n.io">Form Trigger Node</a> that allows for building interactive workflows with multi-step forms that collect data seamlessly. We also added nodes for popular applications like MS OneDrive, Google Business, Okta and Gong. And what&#x2019;s a workflow without a trigger? We now also have triggers for MS OutLook, Salesforce, Slack, Whatsapp, Twilio and more!</p><p>You can find all our nodes on our <a href="https://n8n.io/integrations/?ref=blog.n8n.io">integrations page</a>.</p><figure class="kg-card kg-image-card"><img src="https://blog.n8n.io/content/images/2025/01/Versions.jpg" class="kg-image" alt="2024 in Review" loading="lazy" width="701" height="145" srcset="https://blog.n8n.io/content/images/size/w600/2025/01/Versions.jpg 600w, https://blog.n8n.io/content/images/2025/01/Versions.jpg 701w"></figure><h3 id="a-growing-vibrant-community">A growing, vibrant community</h3><p>2024 was also the year that we were able to invest a lot of time into you, our amazing community! Here are some of the things we achieved together:</p><ul><li>We restructured our <a href="https://community.n8n.io/?ref=blog.n8n.io">community forum</a> &#x2013; still the best place to get help with n8n.</li><li>Stepped up our activity on <a href="https://www.youtube.com/n8n-io?ref=blog.n8n.io">YouTube</a>, including Max&#x2019; amazing <a href="https://www.youtube.com/watch?v=Jgouaas1fUE&amp;list=PLlET0GsrLUL7Ja8Hv6Ra6bdBHENj-ODwF&amp;ref=blog.n8n.io">30 days of AI</a> and his new series, <a href="https://www.youtube.com/watch?v=OSVZfSDyaYM&amp;list=PLlET0GsrLUL7LWMf4Q3gHNu5mk-hur7QV&amp;ref=blog.n8n.io">the Studio</a>. Also, Angel has started a new series for Enterprise and IT users called <a href="https://www.youtube.com/watch?v=WneT4gliSbY&amp;ref=blog.n8n.io">n8n at Scale</a>. Check it out!</li><li>We restarted our monthly Community Hangouts - livestreams where we talk about what&#x2019;s going on at n8n, and where we invite speakers from our community. In December, we also interviewed our founder Jan Oberhauser and we celebrated the 2024 Community Awards! <a href="https://www.youtube.com/watch?v=64bCy3vVSxw&amp;t=2454s&amp;ref=blog.n8n.io">You can see the episode here.</a></li><li>We launched our <a href="https://n8n.io/newsletter?ref=blog.n8n.io">Community Newsletter</a> &#x2013; a monthly summary of product updates, featured templates and community activities.</li><li>We started an Ambassador program. We welcomed 19 Ambassadors, who already <a href="https://community.n8n.io/tag/meetup-report?ref=blog.n8n.io">hosted 14 events</a> around the world.</li><li>Finally, our social media is more active than ever! Follow us on <a href="https://www.linkedin.com/company/n8n/?ref=blog.n8n.io">LinkedIn</a>, <a href="https://x.com/n8n_io?ref=blog.n8n.io">X</a>, <a href="https://www.facebook.com/n8nio/">Facebook</a> or <a href="https://bsky.app/profile/n8n.io?ref=blog.n8n.io">Bluesky</a> to stay up to date on feature updates, community events, great educational videos and more!</li></ul><figure class="kg-card kg-image-card"><img src="https://blog.n8n.io/content/images/2025/01/community-collage.png" class="kg-image" alt="2024 in Review" loading="lazy" width="1860" height="1342" srcset="https://blog.n8n.io/content/images/size/w600/2025/01/community-collage.png 600w, https://blog.n8n.io/content/images/size/w1000/2025/01/community-collage.png 1000w, https://blog.n8n.io/content/images/size/w1600/2025/01/community-collage.png 1600w, https://blog.n8n.io/content/images/2025/01/community-collage.png 1860w" sizes="(min-width: 720px) 720px"></figure><figure class="kg-card kg-image-card"><img src="https://blog.n8n.io/content/images/2025/01/Community-authored-2.jpg" class="kg-image" alt="2024 in Review" loading="lazy" width="700" height="145" srcset="https://blog.n8n.io/content/images/size/w600/2025/01/Community-authored-2.jpg 600w, https://blog.n8n.io/content/images/2025/01/Community-authored-2.jpg 700w"></figure><h3 id="onward-to-2025">Onward to 2025</h3><p>We&#x2019;re all excited for the future of n8n! Whether it&#x2019;s advancing AI, improving workflows, or growing alongside our community, we&#x2019;re committed to making automation more accessible, powerful, and user-friendly.</p><p>To learn more about our plans, <a href="https://lu.ma/n8n-january-2025?ref=blog.n8n.io">join our next Community Livestream on January 30</a>, where our Product Managers will unfold their plans.</p><p>Thank you for being part of this journey &#x2013; here&#x2019;s to an even more exciting year ahead!</p>]]></content:encoded></item><item><title><![CDATA[Build a custom knowledge RAG chatbot using n8n]]></title><description><![CDATA[Learn how to build powerful RAG chatbots with n8n's visual workflow automation. This step-by-step guide demonstrates how to connect to any knowledge source, index it in a vector database, and create an AI-powered chatbot that provides accurate, context-aware answers.]]></description><link>https://blog.n8n.io/rag-chatbot/</link><guid isPermaLink="false">6788cfc02174c200018c2f68</guid><category><![CDATA[AI]]></category><category><![CDATA[Tutorial]]></category><dc:creator><![CDATA[Mihai Farcas]]></dc:creator><pubDate>Tue, 21 Jan 2025 11:11:38 GMT</pubDate><media:content url="https://blog.n8n.io/content/images/2025/01/Slide-16_9---86--1-.png" medium="image"/><content:encoded><![CDATA[<img src="https://blog.n8n.io/content/images/2025/01/Slide-16_9---86--1-.png" alt="Build a custom knowledge RAG chatbot using n8n"><p>Ever wished for a chatbot that could answer specific questions about your data or documentation, instead of just hallucinating generic responses? Build one that actually knows your data with Retrieval Augmented Generation (RAG)!</p><p>In this blog post, we&apos;ll examine how Retrieval Augmented Generation (RAG) allows you to build specialized chatbots that go beyond the limitations of typical chatbot interactions. Instead of relying on generic responses, RAG chatbots utilize external knowledge sources to deliver precise and informative answers to complex queries.</p><p>We&apos;ll break down the core concepts of RAG and look at some practical RAG workflow examples. Plus, this isn&apos;t just theory - we&apos;ll demonstrate how to implement RAG using <a href="https://n8n.io/ai/?ref=blog.n8n.io"><u>n8n, a workflow automation tool</u></a>.</p><p>By the end of this article, you&apos;ll have the knowledge and tools to construct your own RAG chatbots!</p><h2 id="how-is-rag-used-in-chatbots">How is RAG used in chatbots?</h2><p>Retrieval Augmented Generation (RAG) in chatbots is a powerful technique that combines the strengths of large language models (LLMs) with external knowledge sources to generate more relevant, and most importantly, accurate responses.</p><h3 id="what-is-the-rag-in-the-chatbot">What is the RAG in the chatbot?</h3><p>RAG is particularly useful in scenarios where LLMs need to access and utilize information that was not included in their initial training data, such as when answering questions about specific domains, internal documents, or data that is not publicly available.</p><p><a href="https://blog.n8n.io/best-ai-chatbot/"><u>AI chatbots</u></a> can use RAG to access and process information from a variety of sources, including unstructured data like text documents, web pages, and social media posts, as well as structured data like databases and knowledge graphs. This allows them to:</p><ul><li>provide more comprehensive and informative responses;</li><li>personalize the user experience;</li><li>stay up-to-date with the latest information;</li><li>provide responses based on internal documents.</li></ul><h3 id="what-is-the-difference-between-semantic-search-and-rag">What is the difference between semantic search and RAG?</h3><p>While both semantic search and RAG aim to improve information retrieval, they differ in their approach and capabilities.</p><p>Semantic search focuses on understanding the intent and context of a user&apos;s query to retrieve relevant information. It uses techniques like natural language processing (NLP) to analyze the meaning behind the words and identify related concepts. Think of it as a smarter search engine that goes beyond keyword matching.</p><p>RAG builds upon semantic search by incorporating a generative component. It not only retrieves relevant information but also uses an LLM to synthesize and generate a comprehensive answer based on the retrieved information. This allows RAG to provide more concise and human-like responses, compared to simply presenting a list of search results.</p><p>Imagine you need to find information about a specific error code in a large technical manual. Semantic search would help you locate the relevant sections in the manual. RAG would then take those sections, synthesize the information, and provide you with a concise explanation of the error and potential solutions.</p><h2 id="rag-chatbot-examples">RAG chatbot examples</h2><p>Now that we&#x2019;ve explored the fundamentals of RAG, let&#x2019;s dive into some examples to inspire your creativity.</p><p>We&#x2019;ll demonstrate how to bring these ideas to life with <strong>n8n</strong>, a powerful workflow automation tool that streamlines the integration of external knowledge sources into RAG workflows. Plus, we&#x2019;ll highlight why n8n is the ideal platform for building efficient, scalable, and customizable RAG chatbots.</p><p>The following scenarios are just a glimpse of what&apos;s possible when you combine the retrieval power of semantic search with the generative capabilities of LLMs.</p><h3 id="internal-knowledge-base-chatbot">Internal knowledge base chatbot</h3><p>A workflow that connects to internal company resources, with a focus on documents stored in Google Drive. It leverages a mechanism to automatically update a Pinecone vector database whenever new documents are added or existing ones are modified in designated Google Drive folders. When a user asks a question, the workflow uses a combination of nodes (including semantic search with Pinecone and an LLM) to retrieve relevant information from the indexed documents and generate a response.</p><p>An employee asks the chatbot, &quot;What is the company&apos;s policy on remote work?&quot;. The chatbot accesses the vector store, retrieves relevant documents and generates a summary of the policy.</p>
<!--kg-card-begin: html-->
<script>
  workflowBanner(2753, document.currentScript);
</script>
<!--kg-card-end: html-->
<h3 id="api-documentation-chatbot">API documentation chatbot</h3><p>This workflow connects to API documentation, code examples, and developer documentation. It uses a &quot;Function node&quot; to parse API specifications and extract relevant information. When a developer asks a question about the API, the workflow retrieves relevant documentation and code examples. An LLM is used to generate concise explanations, provide usage examples tailored to the developer&apos;s programming language, and even generate code snippets for common API calls.</p><p>A developer asks the chatbot, &quot;How do I authenticate a user with the OAuth 2.0 protocol in my Node.js application?&quot; The chatbot retrieves the relevant API documentation and code examples, then generates a Node.js code snippet demonstrating the authentication process, along with explanations and security considerations.</p><p>Later in this article, we will walk through the steps of creating this API Documentation Chatbot workflow in detail, demonstrating how to connect to a real-world API specification, integrate with a vector database, and build a chat interface using n8n&apos;s powerful features!</p>
<!--kg-card-begin: html-->
<script>
  workflowBanner(2705, document.currentScript);
</script>
<!--kg-card-end: html-->
<h3 id="financial-analyst-chatbot">Financial analyst chatbot</h3><p>This workflow integrates with financial data providers (e.g., Bloomberg, Refinitiv). It uses &quot;HTTP Request&quot; nodes to fetch real-time market data, historical stock prices, and company financial reports. When a user asks a financial question, the workflow retrieves relevant data and uses an LLM to generate insightful analyses, risk assessments, or investment recommendations.</p><p>An analyst asks the chatbot, &quot;What is the current market sentiment towards renewable energy companies, and how does it compare to the previous quarter?&quot; The chatbot analyzes news articles, social media sentiment, and market data to provide a comprehensive answer, potentially including charts and graphs generated with other n8n nodes.</p>
<!--kg-card-begin: html-->
<script>
  workflowBanner(2741, document.currentScript);
</script>
<!--kg-card-end: html-->
<h2 id="how-to-build-a-rag-chatbot-with-n8n">How to build a RAG chatbot with n8n?</h2><p>Let&apos;s turn theory into practice by building an RAG chatbot with n8n&apos;s powerful visual workflow automation. We&apos;ll be creating an API documentation chatbot for the GitHub API, demonstrating how n8n simplifies the process of connecting to data sources, vector databases, and LLMs. This hands-on example will guide you through each step, from data extraction and indexing to creating a user-friendly chat interface.</p><h3 id="prerequisites">Prerequisites</h3><p>Before we start building, make sure you have the following set up:</p><ol><li><strong>n8n account:</strong> You&apos;ll need an n8n account to create and run workflows. If you don&apos;t have one already, you can <a href="https://app.n8n.cloud/register?ref=blog.n8n.io"><u>sign up for an n8n cloud account</u></a> or<a href="https://docs.n8n.io/hosting/?ref=blog.n8n.io"> <u>self-host n8n</u></a>.</li><li><strong>OpenAI account and API key:</strong> We&apos;ll be using OpenAI&apos;s models for generating embeddings and responses. You&apos;ll need an OpenAI account and an API key. You can find this documentation page about <a href="https://docs.n8n.io/integrations/builtin/credentials/openai/?ref=blog.n8n.io"><u>setting up OpenAI credentials in n8n</u></a>.</li><li><strong>Pinecone account and API key:</strong> We&apos;ll use Pinecone as our vector database to store and retrieve API documentation embeddings. You can create a free account on the Pinecone website and check out the documentation page on <a href="https://docs.n8n.io/integrations/builtin/credentials/pinecone/?ref=blog.n8n.io"><u>how to set up Pinecone credentials in n8n</u></a>.</li></ol><p><strong>Basic familiarity with vector databases:</strong> While not strictly required, understanding the basic concepts of vector databases will be helpful. You can check out this n8n documentation for a primer:<a href="https://docs.n8n.io/advanced-ai/examples/understand-vector-databases/?ref=blog.n8n.io"> u<u>sing Vector Databases in n8n</u></a>.</p><p>Once you have these prerequisites in place, you&apos;re ready to start building your RAG chatbot! You can follow along by importing the workflow:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-08-100219.webp" class="kg-image" alt="Build a custom knowledge RAG chatbot using n8n" loading="lazy" width="966" height="752" srcset="https://blog.n8n.io/content/images/size/w600/2025/01/Screenshot-2025-01-08-100219.webp 600w, https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-08-100219.webp 966w" sizes="(min-width: 720px) 720px"><figcaption><span style="white-space: pre-wrap;">RAG chatbot n8n workflow</span></figcaption></figure>
<!--kg-card-begin: html-->
<script>
  workflowBanner(2705, document.currentScript);
</script>
<!--kg-card-end: html-->
<h3 id="step-1-set-up-data-source-and-content-extraction">Step 1: Set up data source and content extraction</h3><p>This workflow consists of two parts. The first part handles grabbing the data and indexing it into Pinecone vector DB and the second part will handle the AI chatbot.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-08-100035.webp" class="kg-image" alt="Build a custom knowledge RAG chatbot using n8n" loading="lazy" width="922" height="506" srcset="https://blog.n8n.io/content/images/size/w600/2025/01/Screenshot-2025-01-08-100035.webp 600w, https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-08-100035.webp 922w" sizes="(min-width: 720px) 720px"><figcaption><span style="white-space: pre-wrap;">Loading data into the vector store</span></figcaption></figure><p>Using the <a href="https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.httprequest/?utm_source=n8n_app&amp;utm_medium=node_settings_modal-credential_link&amp;utm_campaign=n8n-nodes-base.httpRequest"><strong><u>HTTP Request node</u></strong></a> we are fetching the OpenAPI 3.0 specification from GitHub. We simply use this <a href="https://raw.githubusercontent.com/github/rest-api-description/refs/heads/main/descriptions/api.github.com/api.github.com.json?ref=blog.n8n.io"><u>GitHub raw URL</u></a> to get the JSON file for the repository. Leave all other options at their default settings.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220725.webp" class="kg-image" alt="Build a custom knowledge RAG chatbot using n8n" loading="lazy" width="886" height="1121" srcset="https://blog.n8n.io/content/images/size/w600/2025/01/Screenshot-2025-01-07-220725.webp 600w, https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220725.webp 886w" sizes="(min-width: 720px) 720px"><figcaption><span style="white-space: pre-wrap;">Retrieve the GitHub OpenAPI spec</span></figcaption></figure><p>This node makes a GET request to the specified URL, which points to the raw JSON representation of the GitHub API specification. The response is the entire OpenAPI specification file. The file will be used in the next step.</p><h3 id="step-2-generate-embeddings">Step 2: Generate embeddings</h3><p>In this important step, we transform the text chunks from the API documentation into numerical vector representations known as embeddings. These embeddings capture the semantic meaning of each text chunk, allowing us to perform similarity searches later on. We can do this using the <a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.vectorstorepinecone/?utm_source=n8n_app&amp;utm_medium=node_settings_modal-credential_link&amp;utm_campaign=%40n8n%2Fn8n-nodes-langchain.vectorStorePinecone"><strong><u>Pinecone Vector Store node</u></strong></a>.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220732.webp" class="kg-image" alt="Build a custom knowledge RAG chatbot using n8n" loading="lazy" width="896" height="697" srcset="https://blog.n8n.io/content/images/size/w600/2025/01/Screenshot-2025-01-07-220732.webp 600w, https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220732.webp 896w" sizes="(min-width: 720px) 720px"><figcaption><span style="white-space: pre-wrap;">Set up saving document chunks in Pinecone vector store</span></figcaption></figure><p>Then we need to connect an <a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.embeddingsopenai/?utm_source=n8n_app&amp;utm_medium=node_settings_modal-credential_link&amp;utm_campaign=%40n8n%2Fn8n-nodes-langchain.embeddingsOpenAi"><u>Embeddings OpenAI node</u></a> to the Pinecone Vector Store node.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220741.webp" class="kg-image" alt="Build a custom knowledge RAG chatbot using n8n" loading="lazy" width="891" height="523" srcset="https://blog.n8n.io/content/images/size/w600/2025/01/Screenshot-2025-01-07-220741.webp 600w, https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220741.webp 891w" sizes="(min-width: 720px) 720px"><figcaption><span style="white-space: pre-wrap;">Generate document embeddings</span></figcaption></figure><p>This node takes the text chunks and generates their corresponding vector embeddings using OpenAI&apos;s embedding model. Use your OpenAI credentials and choose <em>text-embedding-3-small</em> as the <strong>Model</strong>.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220748.webp" class="kg-image" alt="Build a custom knowledge RAG chatbot using n8n" loading="lazy" width="891" height="608" srcset="https://blog.n8n.io/content/images/size/w600/2025/01/Screenshot-2025-01-07-220748.webp 600w, https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220748.webp 891w" sizes="(min-width: 720px) 720px"><figcaption><span style="white-space: pre-wrap;">Set up default data loader for RAG</span></figcaption></figure><p>We also need to connect the <a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.documentdefaultdataloader/?utm_source=n8n_app&amp;utm_medium=node_settings_modal-credential_link&amp;utm_campaign=%40n8n%2Fn8n-nodes-langchain.documentDefaultDataLoader"><u>Default Data Loader node</u></a> and connect the <a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.textsplitterrecursivecharactertextsplitter/?utm_source=n8n_app&amp;utm_medium=node_settings_modal-credential_link&amp;utm_campaign=%40n8n%2Fn8n-nodes-langchain.textSplitterRecursiveCharacterTextSplitter"><u>Recursive Character Text Splitter node</u></a> to that. You can leave everything as default.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220756.webp" class="kg-image" alt="Build a custom knowledge RAG chatbot using n8n" loading="lazy" width="888" height="533" srcset="https://blog.n8n.io/content/images/size/w600/2025/01/Screenshot-2025-01-07-220756.webp 600w, https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220756.webp 888w" sizes="(min-width: 720px) 720px"><figcaption><span style="white-space: pre-wrap;">Set up recursive character splitter</span></figcaption></figure><h3 id="step-3-save-documents-and-embeddings-to-the-pinecone-vector-store">Step 3: Save documents and embeddings to the Pinecone vector store</h3><p>You can now run this part of the workflow. It might take a while to generate all the embeddings and save them to Pinecone, especially if the API specification file is large. After that is done, your Pinecone dashboard should show some data in that vector store:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-221159.webp" class="kg-image" alt="Build a custom knowledge RAG chatbot using n8n" loading="lazy" width="2000" height="662" srcset="https://blog.n8n.io/content/images/size/w600/2025/01/Screenshot-2025-01-07-221159.webp 600w, https://blog.n8n.io/content/images/size/w1000/2025/01/Screenshot-2025-01-07-221159.webp 1000w, https://blog.n8n.io/content/images/size/w1600/2025/01/Screenshot-2025-01-07-221159.webp 1600w, https://blog.n8n.io/content/images/size/w2400/2025/01/Screenshot-2025-01-07-221159.webp 2400w" sizes="(min-width: 720px) 720px"><figcaption><span style="white-space: pre-wrap;">Pinecone vector store index</span></figcaption></figure><h3 id="step-4-build-the-core-chatbot-logic">Step 4: Build the core chatbot logic</h3><p>With our API specification indexed in the vector database, we can now set up the querying and response generation part of the workflow. This involves receiving the user&apos;s query, finding relevant documents in the vector store, and crafting a response using an LLM.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-08-100219-1.webp" class="kg-image" alt="Build a custom knowledge RAG chatbot using n8n" loading="lazy" width="966" height="752" srcset="https://blog.n8n.io/content/images/size/w600/2025/01/Screenshot-2025-01-08-100219-1.webp 600w, https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-08-100219-1.webp 966w" sizes="(min-width: 720px) 720px"><figcaption><span style="white-space: pre-wrap;">RAG chatbot n8n workflow</span></figcaption></figure><p>Use the <a href="https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-langchain.chattrigger/?utm_source=n8n_app&amp;utm_medium=node_settings_modal-credential_link&amp;utm_campaign=%40n8n%2Fn8n-nodes-langchain.chatTrigger"><strong><u>Chat Trigger</u></strong></a> node to receive user input. This node acts as the entry point for user interaction, triggering the workflow when a new chat message is received. Leave all settings as default for now.</p><p>We then connect the Chat Trigger node to an <a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.agent/?utm_source=n8n_app&amp;utm_medium=node_settings_modal-credential_link&amp;utm_campaign=%40n8n%2Fn8n-nodes-langchain.agent"><u>AI Agent node</u></a>. This node orchestrates the retrieval and generation steps. It receives the user&#x2019;s question and the relevant documents, and calls upon the LLM to produce an answer.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220811.webp" class="kg-image" alt="Build a custom knowledge RAG chatbot using n8n" loading="lazy" width="904" height="978" srcset="https://blog.n8n.io/content/images/size/w600/2025/01/Screenshot-2025-01-07-220811.webp 600w, https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220811.webp 904w" sizes="(min-width: 720px) 720px"><figcaption><span style="white-space: pre-wrap;">Set up n8n AI agent node</span></figcaption></figure><p>We can select the <strong>Agent </strong>type as <em>Tools Agent</em>. We can also set a <em>System Message</em>,which will be combined with the user&apos;s input to create a prompt for the LLM. Here&apos;s a simple example of a system message prompt:</p><pre><code>You are a helpful assistant providing information about the GitHub API and how to use it based on the OpenAPI V3 specifications.
</code></pre>
<p>Next, connect the AI Agent node to the <a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatopenai/?utm_source=n8n_app&amp;utm_medium=node_settings_modal-credential_link&amp;utm_campaign=%40n8n%2Fn8n-nodes-langchain.lmChatOpenAi"><u>OpenAI Chat Model node</u></a>. This node is responsible for taking the user&apos;s query, along with the retrieved text chunks, and using an OpenAI LLM to generate a final, comprehensive answer.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220820.webp" class="kg-image" alt="Build a custom knowledge RAG chatbot using n8n" loading="lazy" width="891" height="525" srcset="https://blog.n8n.io/content/images/size/w600/2025/01/Screenshot-2025-01-07-220820.webp 600w, https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220820.webp 891w" sizes="(min-width: 720px) 720px"><figcaption><span style="white-space: pre-wrap;">Set up OpenAI GPT-4o-mini as the main chat model</span></figcaption></figure><p>Select your OpenAI credentials, and from the Model dropdown, choose the efficient gpt-4o-mini model.</p><p>Connect the <a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.memorybufferwindow/?utm_source=n8n_app&amp;utm_medium=node_settings_modal-credential_link&amp;utm_campaign=%40n8n%2Fn8n-nodes-langchain.memoryBufferWindow"><u>Window Buffer Memory node</u></a> to the AI Agent node. This node provides short-term memory for the conversation, enabling the LLM to answer follow-up questions and use previous prompts and answers to improve its responses. You can leave all settings as default here.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220826.webp" class="kg-image" alt="Build a custom knowledge RAG chatbot using n8n" loading="lazy" width="885" height="546" srcset="https://blog.n8n.io/content/images/size/w600/2025/01/Screenshot-2025-01-07-220826.webp 600w, https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220826.webp 885w" sizes="(min-width: 720px) 720px"><figcaption><span style="white-space: pre-wrap;">Implement chat memory using window buffer memory</span></figcaption></figure><h3 id="step-5-retrieve-information-using-the-vector-store-tool">Step 5: Retrieve information using the vector store tool</h3><p>Now comes the crucial part that transforms this into a RAG chatbot instead of a regular AI chatbot!</p><p>Connect a <a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.toolvectorstore/?utm_source=n8n_app&amp;utm_medium=node_settings_modal-credential_link&amp;utm_campaign=%40n8n%2Fn8n-nodes-langchain.toolVectorStore"><u>Vector Store Tool node</u></a> to the <strong>AI Agent</strong> node. The node uses the embedding of the user&#x2019;s query to perform a similarity search against embeddings of the indexed API specification chunks.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220832.webp" class="kg-image" alt="Build a custom knowledge RAG chatbot using n8n" loading="lazy" width="890" height="599" srcset="https://blog.n8n.io/content/images/size/w600/2025/01/Screenshot-2025-01-07-220832.webp 600w, https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220832.webp 890w" sizes="(min-width: 720px) 720px"><figcaption><span style="white-space: pre-wrap;">Vector store tool set up</span></figcaption></figure><p>Give this tool a descriptive name and a description so the LLM understands when to use it. For this example, you can use the following description:</p><pre><code>Use this tool to get information about the GitHub API. This database contains OpenAPI v3 specifications.
</code></pre>
<p>We can also limit the number of results that we retrieve from the vector store to the 4 most relevant for the user&#x2019;s query.</p><p>Then, connect the <a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.vectorstorepinecone/?utm_source=n8n_app&amp;utm_medium=node_settings_modal-credential_link&amp;utm_campaign=%40n8n%2Fn8n-nodes-langchain.vectorStorePinecone"><u>Pinecone Vector Store node</u></a>, this time set the <strong>Operation Mode </strong>as <em>Retrieve Documents (For Agent/Chain)</em> and connect the same <a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.embeddingsopenai/?utm_source=n8n_app&amp;utm_medium=node_settings_modal-credential_link&amp;utm_campaign=%40n8n%2Fn8n-nodes-langchain.embeddingsOpenAi"><u>Embeddings OpenAI node</u></a><strong> </strong>that we used earlier, ensuring the same text-embedding-3-large model is selected. This setup will generate embeddings for the user&apos;s query, allowing for a comparison against all the embeddings in your vector store.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220843.webp" class="kg-image" alt="Build a custom knowledge RAG chatbot using n8n" loading="lazy" width="893" height="673" srcset="https://blog.n8n.io/content/images/size/w600/2025/01/Screenshot-2025-01-07-220843.webp 600w, https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220843.webp 893w" sizes="(min-width: 720px) 720px"><figcaption><span style="white-space: pre-wrap;">Retrieve documents from Pinecone vector store</span></figcaption></figure><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220850.webp" class="kg-image" alt="Build a custom knowledge RAG chatbot using n8n" loading="lazy" width="886" height="609" srcset="https://blog.n8n.io/content/images/size/w600/2025/01/Screenshot-2025-01-07-220850.webp 600w, https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220850.webp 886w" sizes="(min-width: 720px) 720px"><figcaption><span style="white-space: pre-wrap;">Generate user query embeddings</span></figcaption></figure><p>Finally, connect another <a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatopenai/?utm_source=n8n_app&amp;utm_medium=node_settings_modal-credential_link&amp;utm_campaign=%40n8n%2Fn8n-nodes-langchain.lmChatOpenAi"><u>OpenAI Chat Model node</u></a>. This node will summarize the retrieved chunks from the database, providing context for the final response.</p><p>You can use the same gpt-4o-mini model here as well.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220900.webp" class="kg-image" alt="Build a custom knowledge RAG chatbot using n8n" loading="lazy" width="888" height="547" srcset="https://blog.n8n.io/content/images/size/w600/2025/01/Screenshot-2025-01-07-220900.webp 600w, https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220900.webp 888w" sizes="(min-width: 720px) 720px"><figcaption><span style="white-space: pre-wrap;">Set up OpenAI gpt-4o-mini chat model</span></figcaption></figure><h3 id="step-6-test-your-rag-chatbot">Step 6: Test your RAG chatbot</h3><p>And there you have it!</p><p>You&apos;ve now configured the core components of your RAG-powered GitHub API chatbot.</p><p>To test it out, simply click the Chat button located at the bottom of the n8n editor. This will open the chat interface where you can start interacting with your bot. As a test question, try asking: &quot;How do I create a GitHub App from a manifest?&quot;. You&apos;ll be amazed to see how the chatbot retrieves relevant information from the GitHub API specification and provides you with a detailed, step-by-step solution using the API. This demonstrates the power of RAG and how n8n makes it easy to build sophisticated AI-powered applications.</p><figure class="kg-card kg-image-card"><img src="https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-08-111319.webp" class="kg-image" alt="Build a custom knowledge RAG chatbot using n8n" loading="lazy" width="1211" height="919" srcset="https://blog.n8n.io/content/images/size/w600/2025/01/Screenshot-2025-01-08-111319.webp 600w, https://blog.n8n.io/content/images/size/w1000/2025/01/Screenshot-2025-01-08-111319.webp 1000w, https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-08-111319.webp 1211w" sizes="(min-width: 720px) 720px"></figure><h2 id="wrap-up">Wrap up</h2><p>In this article, we covered Retrieval Augmented Generation (RAG) and how it enables you to build specialized chatbots that can tap into specific knowledge sources, providing more accurate and relevant answers than traditional chatbots.</p><p>You&apos;ve seen how n8n&#x2019;s intuitive, visual interface and <a href="https://n8n.io/integrations/?ref=blog.n8n.io"><u>pre-built integrations</u></a> with various LLMs and databases make it an ideal platform for building and deploying RAG workflows. You can easily connect all the necessary components, experiment with different configurations, and scale your chatbot as your needs grow.</p>
<!--kg-card-begin: html-->
<div class="content-banner">
  <div>
    <h3>Ready to create your own custom RAG chatbot?</h3>
    <p>Integrate AI &amp; Automation to your business data, APIs, and entire stack</p>
  </div>
  <a href="https://app.n8n.cloud/register?ref=blog.n8n.io" class="global-button blog-banner-signup">Explore n8n with a free trial</a>
</div>
<!--kg-card-end: html-->
<h2 id="what%E2%80%99s-next">What&#x2019;s next?</h2><p>Okay, so you understand RAG and you&apos;ve seen how n8n can put it all together. Now it&apos;s time to get practical. Here&apos;s what you should focus on next:</p><ul><li>Once you have the basic chatbot working, start experimenting. Try different embedding models, fine-tune your prompts, or test different retrieval strategies to improve performance.</li><li>n8n isn&apos;t tied to a single LLM. You can use nodes for OpenAI, Ollama, or integrate with LangChain. Each LLM has its strengths and weaknesses, so test them out to find the best fit. Check out this article to <a href="https://blog.n8n.io/local-llm/"><u>learn more about integrating local Ollama models into your workflows</u></a>.</li><li>Check out YouTube tutorials from the community to deepen your understanding and see n8n in action:<ul><li><a href="https://www.youtube.com/watch?v=iT9xpiUwVbI&amp;ref=blog.n8n.io" rel="noreferrer">Step-by-step RAG Agent with Pinecone and n8n</a></li><li><a href="https://www.youtube.com/watch?v=PEI_ePNNfJQ&amp;ref=blog.n8n.io" rel="noreferrer">RAG agent with n8n and Supabase</a></li></ul></li><li>Get inspired by other <a href="https://n8n.io/workflows/categories/ai/?ref=blog.n8n.io"><u>AI workflows created by the n8n community</u></a>.</li></ul>]]></content:encoded></item><item><title><![CDATA[Your Practical Guide to LLM Agents in 2025 (+ 5 Ready-to-Use Automation Templates)]]></title><description><![CDATA[Learn how LLM agents are transforming enterprise automation in 2025. Discover core components, use cases, and how to build intelligent workflows with n8n for IT, security, and DevOps.]]></description><link>https://blog.n8n.io/llm-agents/</link><guid isPermaLink="false">677d8e859c91de00016923d6</guid><category><![CDATA[AI]]></category><category><![CDATA[Guide]]></category><dc:creator><![CDATA[Bela Wiertz]]></dc:creator><pubDate>Thu, 09 Jan 2025 14:26:02 GMT</pubDate><media:content url="https://blog.n8n.io/content/images/2025/01/Slide-16_9---26--1-.png" medium="image"/><content:encoded><![CDATA[<img src="https://blog.n8n.io/content/images/2025/01/Slide-16_9---26--1-.png" alt="Your Practical Guide to LLM Agents in 2025 (+ 5 Ready-to-Use Automation Templates)"><p>In today&apos;s enterprise landscape, while most organizations are just beginning to explore basic AI implementations, a quiet revolution is taking place. Large Language Model (LLM) agents are emerging as game-changers, combining advanced reasoning capabilities with practical automation. These sophisticated systems can plan multi-step operations, maintain context across complex tasks, and even learn from their interactions &#x2014; capabilities that go far beyond traditional AI implementations.</p><p>In this article, you will learn what makes LLM agents different from legacy AI systems, discover their core components, and see how you can create and deploy them using <a href="https://n8n.io/ai/?ref=blog.n8n.io"><u>n8n &#x2014; a powerful workflow automation platform</u></a>.</p><p>Whether you&apos;re a security professional looking to enhance threat detection, an IT manager aiming to streamline operations, or a DevOps engineer interested in automating complex workflows, this guide will show you everything you need to know about leveraging LLM agents in your enterprise environment.</p><h2 id="what-is-an-llm-agent">What is an LLM Agent?</h2><p>At its core, an LLM agent is an advanced AI system that combines the language understanding capabilities of large language models with strategic planning and tool integration. Unlike simple AI models that respond to prompts, LLM agents can break down complex tasks, plan their execution, and use various tools to accomplish their goals&#x2014;much like a skilled professional approaching a multi-faceted project.</p><p>Think of an LLM agent as a digital team member with three key capabilities:</p><ol><li><strong>Strategic planning</strong>: An LLM agent can analyze complex requests and break them down into logical, sequential steps. For instance, when tasked with investigating a security incident, it can automatically plan the investigation stages, from initial log analysis to impact assessment.</li><li><strong>Memory and context management</strong>: Unlike standard chatbots, LLM agents maintain context across interactions and tasks. They can reference previous decisions, learn from past actions, and apply this knowledge to current situations&#x2014;crucial for maintaining consistency in enterprise operations.</li><li><strong>Tool integration</strong>: Perhaps most importantly, LLM agents can interact with various enterprise tools and APIs. Whether it&apos;s querying security logs, updating ticketing systems, or analyzing performance metrics, they can leverage existing infrastructure to complete tasks.</li></ol><h3 id="legacy-ai-systems-vs-modern-llm-powered-agents">Legacy AI systems vs. modern LLM-powered agents</h3><p>The evolution from legacy AI systems to modern LLM-powered agents represents a fundamental shift in <a href="https://n8n.io/enterprise/?ref=blog.n8n.io"><u>enterprise automation</u></a> capabilities:</p>
<!--kg-card-begin: html-->
<table style="border:none;border-collapse:collapse;table-layout:fixed;width:451.27559055118115pt"><colgroup><col><col></colgroup><tbody><tr style="height:0pt"><td style="border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.38;margin-top:12pt;margin-bottom:12pt;"><span style="font-size:11pt;font-family:Arial,sans-serif;color:#000000;background-color:transparent;font-weight:700;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Legacy AI Systems:</span></p></td><td style="border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.38;margin-top:12pt;margin-bottom:12pt;"><span style="font-size:11pt;font-family:Arial,sans-serif;color:#000000;background-color:transparent;font-weight:700;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Modern LLM-Powered Agents:</span></p></td></tr><tr style="height:0pt"><td style="border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><ul style="margin-top:0;margin-bottom:0;padding-inline-start:48px;"><li dir="ltr" style="list-style-type:disc;font-size:11pt;font-family:Arial,sans-serif;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;" aria-level="1"><p dir="ltr" style="line-height:1.38;margin-top:0pt;margin-bottom:0pt;" role="presentation"><span style="font-size:11pt;font-family:Arial,sans-serif;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Operate on predefined rules and decision trees</span></p></li></ul></td><td style="border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><ul style="margin-top:0;margin-bottom:0;padding-inline-start:48px;"><li dir="ltr" style="list-style-type:disc;font-size:11pt;font-family:Arial,sans-serif;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;" aria-level="1"><p dir="ltr" style="line-height:1.38;margin-top:0pt;margin-bottom:0pt;" role="presentation"><span style="font-size:11pt;font-family:Arial,sans-serif;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Understand natural language instructions and context</span></p></li></ul></td></tr><tr style="height:0pt"><td style="border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><ul style="margin-top:0;margin-bottom:0;padding-inline-start:48px;"><li dir="ltr" style="list-style-type:disc;font-size:11pt;font-family:Arial,sans-serif;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;" aria-level="1"><p dir="ltr" style="line-height:1.38;margin-top:0pt;margin-bottom:0pt;" role="presentation"><span style="font-size:11pt;font-family:Arial,sans-serif;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Require extensive programming for each specific task</span></p></li></ul></td><td style="border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><ul style="margin-top:0;margin-bottom:0;padding-inline-start:48px;"><li dir="ltr" style="list-style-type:disc;font-size:11pt;font-family:Arial,sans-serif;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;" aria-level="1"><p dir="ltr" style="line-height:1.38;margin-top:0pt;margin-bottom:0pt;" role="presentation"><span style="font-size:11pt;font-family:Arial,sans-serif;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Can dynamically adapt to new tasks through simple prompting</span></p></li></ul></td></tr><tr style="height:0pt"><td style="border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><ul style="margin-top:0;margin-bottom:0;padding-inline-start:48px;"><li dir="ltr" style="list-style-type:disc;font-size:11pt;font-family:Arial,sans-serif;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;" aria-level="1"><p dir="ltr" style="line-height:1.38;margin-top:0pt;margin-bottom:0pt;" role="presentation"><span style="font-size:11pt;font-family:Arial,sans-serif;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Can only handle structured data in predetermined formats</span></p></li></ul></td><td style="border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><ul style="margin-top:0;margin-bottom:0;padding-inline-start:48px;"><li dir="ltr" style="list-style-type:disc;font-size:11pt;font-family:Arial,sans-serif;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;" aria-level="1"><p dir="ltr" style="line-height:1.38;margin-top:0pt;margin-bottom:0pt;" role="presentation"><span style="font-size:11pt;font-family:Arial,sans-serif;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Process both structured and unstructured information</span></p></li></ul></td></tr><tr style="height:0pt"><td style="border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><ul style="margin-top:0;margin-bottom:0;padding-inline-start:48px;"><li dir="ltr" style="list-style-type:disc;font-size:11pt;font-family:Arial,sans-serif;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;" aria-level="1"><p dir="ltr" style="line-height:1.38;margin-top:0pt;margin-bottom:0pt;" role="presentation"><span style="font-size:11pt;font-family:Arial,sans-serif;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Limited to single-step, routine operations</span></p></li></ul></td><td style="border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><ul style="margin-top:0;margin-bottom:0;padding-inline-start:48px;"><li dir="ltr" style="list-style-type:disc;font-size:11pt;font-family:Arial,sans-serif;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;" aria-level="1"><p dir="ltr" style="line-height:1.38;margin-top:0pt;margin-bottom:0pt;" role="presentation"><span style="font-size:11pt;font-family:Arial,sans-serif;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Handle multi-step, complex workflows</span></p></li></ul></td></tr><tr style="height:0pt"><td style="border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><ul style="margin-top:0;margin-bottom:0;padding-inline-start:48px;"><li dir="ltr" style="list-style-type:disc;font-size:11pt;font-family:Arial,sans-serif;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;" aria-level="1"><p dir="ltr" style="line-height:1.38;margin-top:0pt;margin-bottom:0pt;" role="presentation"><span style="font-size:11pt;font-family:Arial,sans-serif;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Need complete reprogramming to adapt to new scenarios</span></p></li></ul></td><td style="border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><ul style="margin-top:0;margin-bottom:0;padding-inline-start:48px;"><li dir="ltr" style="list-style-type:disc;font-size:11pt;font-family:Arial,sans-serif;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;" aria-level="1"><p dir="ltr" style="line-height:1.38;margin-top:0pt;margin-bottom:12pt;" role="presentation"><span style="font-size:11pt;font-family:Arial,sans-serif;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Learn and adjust behavior based on feedback and new situations</span></p></li></ul></td></tr></tbody></table>
<!--kg-card-end: html-->
<p>This evolution enables enterprises to automate increasingly complex tasks that previously required significant human intervention. LLM-powered agents can handle nuanced situations, understand context, and even explain their reasoning&#x2014;capabilities that were impossible with legacy systems.</p><h2 id="what-are-the-core-components-of-llm-agents">What are the core components of LLM agents?</h2><p>An LLM agent consists of four essential components that work together to create a sophisticated automation system. Understanding these components is crucial for enterprise teams looking to implement and leverage LLM agents effectively.</p><h3 id="agentbrain">Agent/Brain</h3><p>The brain of an LLM agent is built on advanced language models that serve as its cognitive center. This core component:</p><ul><li><strong>Language model foundation</strong>: Uses state-of-the-art LLMs to understand and process natural language inputs, enabling communication with users in their own terms rather than requiring specialized commands.</li><li><strong>Processing capabilities</strong>: Analyzes complex information streams, from unstructured text to structured data, making it valuable for handling diverse enterprise data sources.</li><li><strong>Decision-making mechanisms</strong>: Employs sophisticated algorithms to evaluate options and select appropriate actions based on context, goals, and constraints.</li></ul><h3 id="memory-systems">Memory systems</h3><p>LLM agents utilize two types of memory systems that enable them to maintain context and learn from experience:</p><ul><li><strong>Short-term memory</strong>:<ul><li>Maintains context during ongoing interactions</li><li>Tracks current task progress and intermediate results</li><li>Holds temporary variables and state information</li></ul></li><li><strong>Long-term memory</strong>:<ul><li>Stores historical interactions and outcomes</li><li>Maintains knowledge bases of previous solutions</li><li>Preserves learned patterns and best practices</li></ul></li></ul><p>Enterprise applications of these memory systems include maintaining context across complex IT workflows, remembering previous incident resolutions, and building organizational knowledge bases over time.&#xA0;&#xA0;</p><h3 id="planning-capabilities">Planning capabilities</h3><p>The planning component enables LLM agents to approach complex tasks systematically:</p><ul><li><strong>Task decomposition</strong>:<ul><li>Breaks down complex requests into manageable subtasks</li><li>Identifies dependencies between different steps</li><li>Prioritizes actions based on urgency and importance</li></ul></li><li><strong>Plan formulation</strong>:<ul><li>Creates structured workflows for completing tasks</li><li>Sets checkpoints for monitoring progress</li><li>Establishes success criteria for each step</li></ul></li><li><strong>Adaptation and reflection</strong>:<ul><li>Adjusts plans based on new information or changing conditions</li><li>Learns from successful and unsuccessful approaches</li><li>Improves strategies through experience&#xA0;</li></ul></li></ul><h3 id="tool-integration">Tool integration</h3><p>The tool integration component allows LLM agents to interact with enterprise systems:</p><ul><li><strong>Available tools and APIs</strong>:<ul><li>Integration with common enterprise software</li><li>Access to databases and knowledge bases</li><li>Connection to monitoring and alerting systems</li></ul></li><li><strong>Integration capabilities</strong>:<ul><li>Seamless data exchange between systems</li><li>Standard protocol support (REST, GraphQL, etc.)</li><li>Real-time synchronization capabilities</li></ul></li><li><strong>Security considerations</strong>:<ul><li>Role-based access control</li><li>Audit logging of all actions</li><li>Secure credential management</li><li>Data encryption in transit and at rest</li></ul></li></ul><p>Together, these components create a flexible and powerful system capable of handling complex enterprise tasks. The effectiveness of an LLM agent depends on how well these components are implemented and integrated within your specific environment.</p><h2 id="how-can-n8n-powered-llm-agents-elevate-your-automation-workflows">How can n8n-powered LLM agents elevate your automation workflows?</h2><p>The rise of LLM agents has revolutionized how we approach automation. Unlike static automation systems that follow rigid rules, n8n-powered LLM agents can intelligently adapt to dynamic scenarios, analyze intricate datasets, and interact seamlessly with various tools and platforms. They act as smart assistants that not only save time but also enhance decision-making and streamline operations.</p><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text">n8n provides the ideal platform for creating and managing these intelligent LLM agents, offering a combination of flexibility, power, and ease of use.</div></div><ul><li><strong>Intuitive workflow design:</strong> n8n&#x2019;s visual builder makes it simple to create even the most complex AI agent workflows, without requiring deep coding knowledge.</li><li><strong>Comprehensive integrations:</strong> With an extensive library of integrations, n8n allows your AI agents to connect with diverse APIs and data sources effortlessly.</li><li><strong>Advanced AI integration:</strong> Leverage the power of leading AI tools like OpenAI, Google Cloud, and others to build intelligent and context-aware workflows.</li><li><strong>Event-driven execution:</strong> With support for real-time triggers and webhooks, your AI agents can respond immediately to external inputs.</li><li><strong>Data processing and analysis:</strong> n8n provides robust tools for transforming, analyzing, and contextualizing data, enabling AI agents to make well-informed decisions.</li></ul><p>Let&#x2019;s explore some of the ready-to-use <a href="https://n8n.io/workflows/categories/ai/?ref=blog.n8n.io" rel="noreferrer">workflows with LLM agents available in n8n&#x2019;s template library</a>. These examples illustrate how AI agents can revolutionize processes like virtual assistance, real-time monitoring, and data-driven decision-making.</p><h3 id="workflow-example-1-chat-with-files">Workflow example 1. Chat with files&#xA0;</h3><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXenesB0H4-d8_NIvfExw-lTKl68QsE8568dN6S29ny18fDnD1hY1IGapglYOK31Dcd-jc-Rdp1RO_qzSpNdOm9ORRmTX3h_2hmgg5XnqHgJJ74_xoYQKvH5BfcDvgAh_f0_b_hhGw?key=2z7b64YH6GAzQghqTDTt31KV" class="kg-image" alt="Your Practical Guide to LLM Agents in 2025 (+ 5 Ready-to-Use Automation Templates)" loading="lazy" width="272" height="233"><figcaption><span style="white-space: pre-wrap;">Workflow example 1. Chat with files</span></figcaption></figure>
<!--kg-card-begin: html-->
<script>
  workflowBanner(2621, document.currentScript);
</script>
<!--kg-card-end: html-->
<p>If you&#x2019;re juggling a mountain of documents and need a faster way to find what you&#x2019;re looking for, the AI-Powered Document Querying Workflow is here to help. This clever tool takes the hassle out of managing and searching through files by automating the hard parts:</p><ul><li><strong>File retrieval:</strong> It grabs files from your Supabase bucket and skips over duplicates or placeholders.</li><li><strong>Content extraction:</strong> It processes PDFs and text files, pulling out all the important content.</li><li><strong>Text chunking:</strong> It breaks down large chunks of text into smaller, manageable pieces, keeping the context intact.</li><li><strong>Vector embedding:</strong> It uses OpenAI to create vector embeddings, making your documents searchable in a smarter way.</li><li><strong>Data storage:</strong> And finally, it stores everything neatly in Supabase, ready for a chatbot to answer your questions.</li></ul><p>This workflow is perfect for researchers, business owners, or anyone who works with big collections of text-heavy files. Instead of spending hours digging for information, you can just ask a question and get the answer, all thanks to the chatbot integration.</p><h3 id="workflow-example-2-youtube-trend-finder">Workflow example 2. YouTube trend finder</h3><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfPl3IW8n6ZeXQu4MT9u276TsdJnmQuax16mBS_T3E0llGr79hgI6p8n_owKsu85_vnFLNmO0CpH_AqQaRT_799Fs7bgkLKfsuBiyi9MGf_iUFZcu6jTytHus2J3IdKMGGtvv0b?key=2z7b64YH6GAzQghqTDTt31KV" class="kg-image" alt="Your Practical Guide to LLM Agents in 2025 (+ 5 Ready-to-Use Automation Templates)" loading="lazy" width="349" height="187"><figcaption><span style="white-space: pre-wrap;">Workflow example 2. YouTube trend finder</span></figcaption></figure>
<!--kg-card-begin: html-->
<script>
  workflowBanner(2606, document.currentScript);
</script>
<!--kg-card-end: html-->
<p>If you&#x2019;re curious about what&#x2019;s trending in a specific niche, this workflow is your go-to tool. By tapping into YouTube&#x2019;s search and data APIs, it analyzes the performance of recently published videos to uncover emerging trends and patterns. Here&#x2019;s what it does:</p><ul><li><strong>Start with a question:</strong> The workflow kicks off when you provide a niche or topic through a chatbot. If you&#x2019;re unsure, the AI can help refine or suggest search terms to get you started.</li><li><strong>AI-driven insights:</strong> A GPT-powered AI processes your input, generates targeted search terms, and dives into the data to identify common themes, audience interests, and engagement metrics.</li><li><strong>Real-time search:</strong> It scans YouTube for videos uploaded in the last two days, retrieving relevant details like video titles, tags, and publication dates.</li><li><strong>Data analysis:</strong> The workflow organizes the data, cleans it up, and analyzes trends across the content, such as recurring themes, popular tags, and engagement patterns.</li><li><strong>Actionable results:</strong> It presents a concise summary of what&#x2019;s trending, complete with URLs to top-performing videos and key stats like views, likes, and comment ratios.</li></ul><p>For example, in the niche of &#x201C;digital marketing,&#x201D; it might highlight topics like &#x201C;psychological marketing&#x201D; and tags such as &#x201C;SEO&#x201D; or &#x201C;Conversion Rates,&#x201D; along with links to high-performing content.</p><h3 id="workflow-example-3vision-based-scraper">Workflow example 3.Vision-based scraper</h3><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfLtYiVZ53idwvqr4fevLSe9k5h1V5NK9w410YPL4IbAQezK8vEhNm5sP-C4n-m73VXC4xztAlcfCmSGAO-L_h4lBVMELPdpEfk3wDROLhyEnGauBkN2PCy7B6vulSF1LizWZ_KsQ?key=2z7b64YH6GAzQghqTDTt31KV" class="kg-image" alt="Your Practical Guide to LLM Agents in 2025 (+ 5 Ready-to-Use Automation Templates)" loading="lazy" width="398" height="439"><figcaption><span style="white-space: pre-wrap;">Workflow example 3.Vision-based scraper</span></figcaption></figure>
<!--kg-card-begin: html-->
<script>
  workflowBanner(2563, document.currentScript);
</script>
<!--kg-card-end: html-->
<p>If you&#x2019;re tired of wrestling with XPath, CSS selectors, or the intricacies of DOM structures when scraping, this workflow is your new best friend. It&#x2019;s powered by a vision-based AI agent that makes data extraction feel effortless, whether from screenshots or HTML.</p><p>Here&#x2019;s what makes this workflow so effective:</p><ul><li><strong>Smart AI data extraction:</strong> Using the Gemini-1.5-Pro model, the workflow processes screenshots to grab structured data. If needed, it switches to HTML scraping, so you always get accurate results.</li><li><strong>Seamless Google Sheets integration:</strong> You can manage the list of URLs to scrape and store the results directly in Google Sheets for easy access and organization.</li><li><strong>ScrapingBee magic:</strong> This tool handles full-page screenshots and HTML retrieval, ensuring every detail is captured.</li><li><strong>Cost-saving optimization:</strong> By converting HTML to Markdown, the workflow minimizes token usage, keeping processing efficient and affordable.</li></ul><p>Originally designed for e-commerce, this workflow can be adapted to fit a variety of use cases, whether you&#x2019;re extracting product details, research data, or anything in between.</p><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text"><b><strong style="white-space: pre-wrap;">A word of caution: </strong></b>Scraping laws vary by region, so make sure you&#x2019;re in compliance before getting started. It&#x2019;s always better to double-check than face any surprises later.</div></div><h3 id="workflow-example-4-suggest-meeting-slots">Workflow example 4. Suggest meeting slots</h3><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXeBlWfYbbnkyEftxcoxZWUJVViYxWX2MMCs0PDbNkn08zI_TUI-wt38_dSm9hiDNKKuoytYduc6IIgsL89_p-laOxTWYukh1vKw-FLVbQMNEkLxwMDDBoxjU89Fs1ElJdozsEez2w?key=2z7b64YH6GAzQghqTDTt31KV" class="kg-image" alt="Your Practical Guide to LLM Agents in 2025 (+ 5 Ready-to-Use Automation Templates)" loading="lazy" width="327" height="187"><figcaption><span style="white-space: pre-wrap;">Workflow example 4. Suggest meeting slots</span></figcaption></figure>
<!--kg-card-begin: html-->
<script>
  workflowBanner(1953, document.currentScript);
</script>
<!--kg-card-end: html-->
<p>Managing appointment requests in your inbox can be a hassle, but this workflow takes care of it all for you. It&#x2019;s designed to automatically identify emails asking for an appointment, check your availability, and send a thoughtful response&#x2014;all without you lifting a finger.</p><p>Here&#x2019;s how it works:</p><ul><li><strong>Smart email detection:</strong> The workflow scans your Gmail inbox for emails requesting appointments. It evaluates the content to understand the request and extract relevant details.</li><li><strong>Calendar integration:</strong> It checks your calendar for available slots, ensuring you don&#x2019;t accidentally double-book or overcommit.</li><li><strong>Automated replies:</strong> Once availability is confirmed, the workflow drafts and sends a polished response email with your proposed time.</li></ul><p>This workflow is perfect for busy professionals, freelancers, or anyone who deals with frequent appointment scheduling. It saves time, reduces back-and-forth, and ensures no request slips through the cracks.</p><h3 id="workflow-example-5-sales-researcher">Workflow example 5. Sales researcher</h3><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfT_5LpRKyCTnXibMfJvv6ojNqb1kB0Nq9MwjOLVf-EigCF417UTBICC183HC3r3jmEQr-4bKM8EHyr2ynr--ItAyl3BWCg2lAY-nAhS9xRRi669IWNCKDe27Bl-lD6A5psPS8gXw?key=2z7b64YH6GAzQghqTDTt31KV" class="kg-image" alt="Your Practical Guide to LLM Agents in 2025 (+ 5 Ready-to-Use Automation Templates)" loading="lazy" width="602" height="195"><figcaption><span style="white-space: pre-wrap;">Workflow example 5. Sales researcher</span></figcaption></figure>
<!--kg-card-begin: html-->
<script>
  workflowBanner(2324, document.currentScript);
</script>
<!--kg-card-end: html-->
<p>For sales reps and lead generation managers, preparing for prospecting can often feel like a time-consuming grind. This workflow is here to streamline that process, helping you gather the essential information you need to personalize your outreach and make meaningful connections.</p><p>Here&#x2019;s what it does:</p><ul><li><strong>AI-powered account research:</strong> Using advanced AI tools, this workflow searches Google with SerpAPI and visits websites to extract key information&#x2014;all from just a company name or domain.</li><li><strong>Comprehensive insights:</strong> The workflow gathers details like:<ul><li>The company&#x2019;s LinkedIn URL</li><li>Pricing information (cheapest plan, free trial availability, enterprise options)</li><li>Whether the company offers an API</li><li>Their target market (B2B or B2C)</li></ul></li></ul><p>The real magic? You can tweak this workflow to gather whatever information you need. By simply adjusting the AI prompts and output structure, it can be tailored to suit your exact research goals.</p><p>It replaces the hours of manual research sales teams typically spend preparing for prospecting activities, letting you focus on connecting with leads instead of hunting for data.</p><h2 id="how-to-create-an-llm-agent-workflow-with-n8n">How to create an LLM agent workflow with n8n?</h2><p>Now that we&#x2019;ve explored various n8n workflows, let&#x2019;s dive in and build one together!</p><p>This time, we&#x2019;ll create <a href="https://n8n.io/workflows/1959-ai-chatbot-that-can-search-the-web/?ref=blog.n8n.io"><u>a powerful AI-driven chatbot that connects to the internet and Wikipedia</u></a>, making it an incredible tool for quick information retrieval and answering complex questions. Whether you&#x2019;re a researcher, a customer support agent, or just someone who loves having an all-knowing assistant at their fingertips, this workflow is a game-changer.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXcgFRFw-y_cRxl17jBxi9YxqtVqvNeffsUWAtRVAVZHssJP4X00GcELdx3zIbZT2VB4ZzlcDDEoLy-taNeU-3PMuw0EyL6mnK7oiYfUogozfYEK5Di8IYQrtLPra_Bk4BdJrCOVvg?key=2z7b64YH6GAzQghqTDTt31KV" class="kg-image" alt="Your Practical Guide to LLM Agents in 2025 (+ 5 Ready-to-Use Automation Templates)" loading="lazy" width="602" height="396"><figcaption><span style="white-space: pre-wrap;">AI chatbot that can search the web powered by n8n</span></figcaption></figure>
<!--kg-card-begin: html-->
<script>
  workflowBanner(1959, document.currentScript);
</script>
<!--kg-card-end: html-->
<p>What makes this chatbot special is its ability to pull live information from the web and Wikipedia, ensuring you always get up-to-date and accurate answers. It&#x2019;s like having a personal researcher working for you around the clock!</p><p>In just a few simple steps, you&#x2019;ll set up a conversational agent that can handle a variety of queries, retrieve relevant data, and respond in a human-like way. And once you have the basics in place, you can customize it further&#x2014;maybe by connecting it to other databases, adding filters for specific types of content, or even integrating it into your favorite messaging app.</p><p>Ready to build your own intelligent assistant? Let&#x2019;s get started!</p><h3 id="step-1-chat-trigger-listens-to-incoming-messages">Step 1: Chat trigger listens to incoming messages</h3><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXdstwks-GLZ9kY-iqrtHc0crIKyIh47pOAb1kZAF-LGQHa2fITeShToqH7-bKHLv1PX5sGvVVBWYmtCkiACYEnp7SRHiRpQccUq5HfSn4QvCtF5v7wZjn4YjxVoUsBZkht4OWYI?key=2z7b64YH6GAzQghqTDTt31KV" class="kg-image" alt="Your Practical Guide to LLM Agents in 2025 (+ 5 Ready-to-Use Automation Templates)" loading="lazy" width="602" height="144"><figcaption><span style="white-space: pre-wrap;">Step 1: Chat trigger listens to incoming messages</span></figcaption></figure><p>For Chatbots we use a chat trigger to start it. In this case, for experimentation purposes, a manual trigger. Later you can then test the workflow by clicking chat on the bottom of your canvas.</p><h3 id="step-2-ai-agent-node-processes-incoming-messages-and-decides-which-tools-to-use">Step 2: AI Agent node processes incoming messages and decides which tools to use</h3><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXcUr-709Ku4JjU3x9XiV-b73uYP0l4NbZPhKQfmOFwh2MsN6N-4cvaRK8oeXK9cqhInIU3Jbx_sdB51j8Uoctm337w6vT1ksRu-zjI0_2a8hJF-CEBb_JjuEbc6BxmTW4y49ewM0Q?key=2z7b64YH6GAzQghqTDTt31KV" class="kg-image" alt="Your Practical Guide to LLM Agents in 2025 (+ 5 Ready-to-Use Automation Templates)" loading="lazy" width="441" height="451"><figcaption><span style="white-space: pre-wrap;">Step 2: AI Agent node processes incoming messages and decides which tools to use</span></figcaption></figure><p>You need to connect a main AI Agent node to the trigger. This is the central node for this workflow and you can define the &#x201C;Agent Type&#x201D;, &#x201C;Prompt Source&#x201D; &amp; &#x201C;Text&#x201D;. In this case we use the input from the trigger &#x201C;{{ $json.input }} as the input text for the Agent.</p><h3 id="step-3-openai-powers-our-llm-agent">Step 3: OpenAI powers our LLM Agent</h3><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfTROw0We7LKATBcCYDBWgaovLRqluj6fVihVBlf9T_-o3LJCnxaZh5ZuaXGBdWXoe8GKzfvXew1j8lF_wz-tQJ4oQ75xK3TqQ5MUKD2lRbdvnPF_oZGHCIlf7XvdTQjyHdPTcdIQ?key=2z7b64YH6GAzQghqTDTt31KV" class="kg-image" alt="Your Practical Guide to LLM Agents in 2025 (+ 5 Ready-to-Use Automation Templates)" loading="lazy" width="602" height="248"><figcaption><span style="white-space: pre-wrap;">Step 3: OpenAI powers our LLM Agent</span></figcaption></figure><p>You need to connect a chat model to your AI Agent node. For this purpose we use OpenAI as a model provider, but technically you can use whichever provider you prefer (from the supported ones). The only parameter you can manually change here is the &#x201C;Sampling Temperature&#x201D;. It controls the randomness/creativity of the model. It affects how likely the model is to pick words with lower probabilities from its prediction distribution. Our recommended temperature of 0.3 leads to more conservative &amp; predictable outcomes.</p><h3 id="step-4-the-last-20-messages-should-be-remembered">Step 4: The last 20 messages should be remembered</h3><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXdsbCFIXMDz9jkXU15c2t5mgUqe3SYJWV05tYQwpKlxmuNcZZw70_lDBXTQt1LeLQCNhIWcOfSd_Qy30uZDHCuo3Kr4rvqU9_If7hoeg_sik64J4gGZHc9Xt6dbIW1x0ph_G-jleQ?key=2z7b64YH6GAzQghqTDTt31KV" class="kg-image" alt="Your Practical Guide to LLM Agents in 2025 (+ 5 Ready-to-Use Automation Templates)" loading="lazy" width="602" height="219"><figcaption><span style="white-space: pre-wrap;">Step 4: The last 20 messages should be remembered</span></figcaption></figure><p>We also need to connect a kind of memory storage, for the chat history to be stored inside the workflow. We use Window Buffer Memory, as it is the simplest and beginner-friendliest way to do so and select 20 as the number of past interactions that should be saved in this memory storage.</p><h3 id="step-5-serpapi-wikipedia-as-tools-to-use">Step 5: SerpAPI &amp; Wikipedia as tools to use</h3><figure class="kg-card kg-image-card"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfOVH04IPJeJPcYEJZv55WlVUkzvU3e3Zp-JrgWBnfaEr7Mw5wlPYFI0chB5z4qA0hCU5AjQJW1Pq0lQU088akaQd9j3eILlwAoNsaJqD8IHj9x1TGLfy1lOAm4QaMHAB1SvOEpsA?key=2z7b64YH6GAzQghqTDTt31KV" class="kg-image" alt="Your Practical Guide to LLM Agents in 2025 (+ 5 Ready-to-Use Automation Templates)" loading="lazy" width="602" height="153"></figure><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfWqgUGU45hFiuWRHT_FjqjqCjvIUFGJR6rbyAoIBZruUKkuSD1Lz_rJiQT_gKUDx9doNJ5PgoQuARiu7v6PwX3YX1S7vJX0P32chdcWLH_oozfXOIGlkPPN2WoVCVm8IuvvO2XKQ?key=2z7b64YH6GAzQghqTDTt31KV" class="kg-image" alt="Your Practical Guide to LLM Agents in 2025 (+ 5 Ready-to-Use Automation Templates)" loading="lazy" width="602" height="112"><figcaption><span style="white-space: pre-wrap;">Step 5: SerpAPI &amp; Wikipedia as tools to use</span></figcaption></figure><p>In n8n we can select multiple tools that then can be used by the AI Agent during execution. You don&#x2019;t need to configure anything here, as n8n handles the heavy lifting. For this example, we use SerpAPI &amp; Wikipedia to make our chat agent smarter with up-to-date information.</p><p>By following these steps, you&apos;ll create your first LLM Agent powered by n8n, OpenAI, Wikipedia and SerpAPI.</p><h2 id="best-practices-and-considerations-when-building-llm-agents">Best practices and considerations when building LLM agents</h2><p>As you dive into building and deploying your workflows, there are a few important aspects to keep in mind to ensure a smooth, secure, and efficient experience. Let&#x2019;s break it down into two key areas: security and performance optimization.</p><h3 id="security-implications">Security implications</h3><ul><li><strong>Data privacy: </strong>When handling sensitive or personal data, always prioritize privacy. Ensure that your workflows comply with local data protection laws (like GDPR or CCPA). Be mindful of how you collect, store, and share information to avoid unauthorized access or breaches.</li><li><strong>Access control: </strong>Implement robust access control mechanisms to restrict who can view, modify, or trigger workflows. Whether it&apos;s through API keys, OAuth, or other authentication methods, controlling access ensures that only authorized users can interact with your workflows.</li><li><strong>Compliance considerations: </strong>If you&apos;re dealing with regulated industries, it&apos;s essential to understand the compliance requirements (e.g., healthcare, finance). Make sure your workflow adheres to these standards to prevent legal or financial complications down the line. This could include keeping logs of actions, using secure data transmission, or encrypting sensitive information.</li></ul><h3 id="performance-optimization">Performance optimization</h3><ul><li><strong>Resource management: </strong>To avoid inefficiencies and potential bottlenecks, manage resources effectively. This includes limiting the number of operations or API calls to prevent overloading the system. Set up error handling and retry mechanisms to maintain reliability even when resources are stretched thin.</li><li><strong>Scaling strategies: </strong>As your workflows grow in complexity or volume, scalability becomes crucial. Design your workflows with scalability in mind by breaking them into smaller, modular components. Use cloud services that allow for auto-scaling to accommodate spikes in traffic or data processing needs.</li></ul><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text">By using worker instances and running in queue mode, you can <a href="https://docs.n8n.io/hosting/scaling/queue-mode/?ref=blog.n8n.io">scale n8n up</a> (by adding workers) and down (by removing workers)&#xA0;as needed to handle the workload.&#xA0;</div></div><ul><li><strong>Cost considerations: </strong>Keep an eye on the costs associated with running automated workflows, especially if you&#x2019;re using third-party services like APIs or cloud storage. Optimize your workflows to minimize unnecessary operations and data transfers. Regularly review your usage patterns and adjust workflows to keep them cost-efficient without sacrificing performance.</li></ul><p>By focusing on these best practices, you&#x2019;ll be able to build workflows that are not only efficient and effective but also secure, scalable, and cost-conscious. Always keep these considerations in mind as you iterate and expand your automation projects.</p><h2 id="wrap-up">Wrap up</h2><p>In this guide, we&#x2019;ve explored the transformative potential of Large Language Model (LLM) agents, diving into their core components and capabilities.</p><p>LLM agents combine advanced reasoning with practical automation, offering enterprises the ability to streamline complex workflows, adapt dynamically to new tasks, and interact intelligently with various tools and systems.</p><p>Using n8n as the platform, we&#x2019;ve demonstrated how LLM agents can be integrated into workflows to handle tasks ranging from real-time data retrieval to complex decision-making. With n8n&#x2019;s visual workflow builder, powerful integrations, and advanced AI tools, creating an intelligent agent becomes accessible, even for those without extensive coding experience.&#xA0;</p>
<!--kg-card-begin: html-->
<div class="content-banner">
  <div>
    <h3>Create your own workflows with LLM agents</h3>
    <p>Build complex automations 10x faster, without fighting APIs</p>
  </div>
  <a href="https://app.n8n.cloud/register?ref=blog.n8n.io" class="global-button blog-banner-signup">Try n8n now</a>
</div>
<!--kg-card-end: html-->
<h2 id="whats-next">What&apos;s next?</h2><p>Ready to take your LLM agents to the next level? Whether you want to fine-tune your workflows, integrate additional tools, or scale your solutions for enterprise use, the next steps are just as exciting as the first.</p><p>There&#x2019;s always more to explore when it comes to building smarter, more efficient automation systems:</p><ul><li><a href="https://www.camel-ai.org/post/mission-at-camel-ai-org-finding-the-scaling-laws-of-agents?ref=blog.n8n.io">Finding the scaling Laws of Agents</a>: dive into multi-agent systems;</li><li><a href="https://n8n.io/workflows/categories/ai/?ref=blog.n8n.io" rel="noreferrer">n8n templates with LLM Agents</a>: discover more use-cases;</li><li><a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.agent/?ref=blog.n8n.io">AI Agent n8n documentation</a>: go beyond the n8n capabilities we have shown in this blog by reading through the documentation.</li></ul>]]></content:encoded></item></channel></rss>